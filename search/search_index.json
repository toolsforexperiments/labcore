{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"about/","title":"About page","text":"<p>Labcore and the whole Tools For Experiments are the sofware efforts of Pfaff-lab at the University of Illinois at Urbana-Champaign.</p> <p>We are an experimental physics research group at UIUC, where we are a part of the Physics department, IQUIST and MRL. Our work falls broadly into quantum optics and quantum information, with a lot of influences from AMO and condensed matter physics. </p>"},{"location":"data/data_formats/","title":"Data Formats","text":""},{"location":"data/data_formats/#in-memory-data","title":"In-memory Data","text":""},{"location":"data/data_formats/#basic-concepts","title":"Basic Concepts","text":"<p>The main format we're using within plottr is the <code>DataDict</code>. While most of the actual numeric data will typically live in numpy arrays (or lists, or similar), they don't typically capture easily arbitrary metadata and relationships between arrays. Say, for example, we have some data <code>z</code> that depends on two other variables, <code>x</code> and <code>y</code>. This information has be stored somewhere, and numpy doesn't offer readily a solution here. There are various extensions, for example xarray or the MetaArray class. Those however typically have a grid format in mind, which we do not want to impose. Instead, we use a wrapper around the python dictionary that contains all the required meta information to infer the relevant relationships, and that uses numpy arrays internally to store the numeric data. Additionally we can store any other arbitrary meta data.</p> <p>A DataDict container (a <code>dataset</code>) can contain multiple <code>data fields</code> (or variables), that have values and can contain their own meta information. Importantly, we distinct between independent fields (the <code>axes</code>) and dependent fields (the <code>data</code>).</p> <p>Despite the naming, <code>axes</code> is not meant to imply that the <code>data</code> have to have a certain shape (but the degree to which this is true depends on the class used). A list of classes for different shapes of data can be found below.</p> <p>The basic structure of data conceptually looks like this (we inherit from <code>dict</code>):</p> <pre><code>{\n    'data_1' : {\n        'axes' : ['ax1', 'ax2'],\n        'unit' : 'some unit',\n        'values' : [ ... ],\n        '__meta__' : 'This is very important data',\n        ...\n    },\n    'ax1' : {\n        'axes' : [],\n        'unit' : 'some other unit',\n        'values' : [ ... ],\n        ...,\n    },\n    'ax2' : {\n        'axes' : [],\n        'unit' : 'a third unit',\n        'values' : [ ... ],\n        ...,\n    },\n    '__globalmeta__' : 'some information about this data set',\n    '__moremeta__' : 1234,\n    ...\n}\n</code></pre> <p>In this case we have one dependent variable, <code>data_1</code>, that depends on two axes, <code>ax1</code> and <code>ax2</code>. This concept is restricted only in the following way:</p> <ul> <li>A dependent can depend on any number of independents.</li> <li>An independent cannot depend on other fields itself.</li> <li>Any field that does not depend on another, is treated as an axis.</li> </ul> <p>Note that meta information is contained in entries whose keys start and end with double underscores. Both the DataDict itself, as well as each field can contain meta information.</p> <p>In the most basic implementation, the only restriction on the data values is that they need to be contained in a sequence (typically as list, or numpy array), and that the length of all values in the data set (the number of <code>records</code>) must be equal. Note that this does not preclude nested sequences!</p>"},{"location":"data/data_formats/#relevant-data-classes","title":"Relevant Data Classes","text":"<p>DataDictBase:  The main base class. Only checks for correct dependencies. Any requirements on data structure is left to the inheriting classes. The class contains methods for easy access to data and metadata.</p> <p>DataDict: The only requirement for valid data is that the number of records is the same for all data fields. Contains some tools for expansion of data.</p> <p>MeshgridDataDict: For data that lives on a grid (not necessarily regular).</p>"},{"location":"data/data_formats/#datadict","title":"Datadict","text":"<p>Note</p> <p>Because DataDicts are python dictionaries , we highly recommend becoming familiar with them before utilizing DataDicts.</p>"},{"location":"data/data_formats/#basic-use","title":"Basic Use","text":"<p>We can start by creating an empty DataDict like any other python object:</p> <pre><code>&gt;&gt;&gt; data_dict = DataDict()\n&gt;&gt;&gt; data_dict\n{}\n</code></pre> <p>We can create the structure of the data_dict by creating dictionary items and populating them like a normal python dictionary:</p> <pre><code>&gt;&gt;&gt; data_dict['x'] = dict(unit='m')\n&gt;&gt;&gt; data_dict\n{'x': {'unit': 'm'}}\n</code></pre> <p>We can also start by creating a DataDict that has the structure of the data we are going to record:</p> <pre><code>&gt;&gt;&gt; data_dict = DataDict(x=dict(unit='m'), y = dict(unit='m'), z = dict(axes=['x', 'y']))\n&gt;&gt;&gt; data_dict\n{'x': {'unit': 'm'}, 'y': {'unit': 'm'}, 'z': {'axes': ['x', 'y']}}\n</code></pre> <p>The DataDict that we just created contains no data yet, only the structure and relationship of the data fields. We have also specified the unit of <code>x</code> and <code>y</code> and which variables are independent variables (<code>x</code>, <code>y</code>), or how we will call them from now on, <code>axes</code> and dependent variables (<code>z</code>), or, <code>dependents</code>.</p>"},{"location":"data/data_formats/#structure","title":"Structure","text":"<p>From the basic and empty DataDict we can already start to inspect its structure. To see the entire structure of a DataDict we can use the <code>structure()</code> method:</p> <pre><code>&gt;&gt;&gt; data_dict = DataDict(x=dict(unit='m'), y = dict(unit='m'), z = dict(axes=['x', 'y']))\n&gt;&gt;&gt; data_dict.structure()\n{'x': {'unit': 'm', 'axes': [], 'label': ''},\n 'y': {'unit': 'm', 'axes': [], 'label': ''},\n 'z': {'axes': ['x', 'y'], 'unit': '', 'label': ''}}\n</code></pre> <p>We can check for specific things inside the DataDict. We can look at the axes:</p> <pre><code>&gt;&gt;&gt; data_dict.axes()\n['x', 'y']\n</code></pre> <p>We can look at all the dependents:</p> <pre><code>&gt;&gt;&gt; data_dict.dependents()\n['z']\n</code></pre> <p>We can also see the shape of a DataDict by using the <code>shapes()</code> method:</p> <pre><code>&gt;&gt;&gt; data_dict.shapes()\n{'x': (0,), 'y': (0,), 'z': (0,)}\n</code></pre>"},{"location":"data/data_formats/#populating-the-datadict","title":"Populating the DataDict","text":"<p>One of the only \"restrictions\" that DataDict implements is that every data field must have the same number of records (items). However, restrictions is in quotes because there is nothing that is stopping you from having different data fields have different number of records, this will only make the DataDict invalid. We will explore what his means later.</p> <p>There are 2 different ways of safely populating a DataDict, adding data to it or appending 2 different DataDict to each other.</p> <p>Note</p> <p>You can always manually update the item <code>values</code> any data field like any other item of a python dictionary, however, populating the DataDict this way can result in an invalid DataDict if you are not being careful. Both population methods presented below contains checks to make sure that the new data being added will not create an invalid DataDict.</p> <p>We can add data to an existing DataDict with the [<code>add_data()</code>(#labcore.data.datadict.DataDict.add_data) method:</p> <pre><code>&gt;&gt;&gt; data_dict = DataDict(x=dict(unit='m'), y = dict(unit='m'), z = dict(axes=['x', 'y']))\n&gt;&gt;&gt; data_dict.add_data(x=[0,1,2], y=[0,1,2], z=[0,1,4])\n&gt;&gt;&gt; data_dict\n{'x': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2])},\n 'y': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2])},\n 'z': {'axes': ['x', 'y'],  'unit': '',  'label': '',  'values': array([0, 1, 4])}}\n</code></pre> <p>We now have a populated DataDict. It is important to notice that this method will also add any of the missing special keys that a data field doesn't have (<code>values</code>, <code>axes</code>, <code>unit</code>, and <code>label</code>). Populating the DataDict with this method will also ensure that every item has the same number of records and the correct shape, either by adding <code>nan</code> to the other data fields or by nesting the data arrays so that the outer most dimension of every data field has the same number of records.</p> <p>We can see this in action if we add a single record to a data field with items but no the rest:</p> <pre><code>&gt;&gt;&gt; data_dict.add_data(x=[9])\n&gt;&gt;&gt; data_dict\n{'x': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2, 9])},\n 'y': {'unit': 'm', 'axes': [], 'label': '', 'values': array([ 0.,  1.,  2., nan])},\n 'z': {'axes': ['x', 'y'], 'unit': '', 'label': '', 'values': array([ 0.,  1.,  4., nan])}}\n</code></pre> <p>As we can see, both <code>y</code> and <code>z</code> have an extra <code>nan</code> record in them. We can observe the change of dimension if we do not add the same number of records to all data fields:</p> <pre><code>&gt;&gt;&gt; data_dict = DataDict(x=dict(unit='m'), y = dict(unit='m'), z = dict(axes=['x', 'y']))\n&gt;&gt;&gt; data_dict.add_data(x=[0,1,2], y=[0,1,2],z=[0])\n&gt;&gt;&gt; data_dict\n{'x': {'unit': 'm', 'axes': [], 'label': '', 'values': array([[0, 1, 2]])},\n 'y': {'unit': 'm', 'axes': [], 'label': '', 'values': array([[0, 1, 2]])},\n 'z': {'axes': ['x', 'y'], 'unit': '', 'label': '', 'values': array([0])}}\n</code></pre> <p>If we want to expand our DataDict by appending another one, we need to make sure that both of our DataDicts have the same inner structure. We can check that by utilizing the static method <code>same_structure()</code>:</p> <pre><code>&gt;&gt;&gt; data_dict_1 = DataDict(x=dict(unit='m'), y=dict(unit='m'), z=dict(axes=['x','y']))\n&gt;&gt;&gt; data_dict_2 = DataDict(x=dict(unit='m'), y=dict(unit='m'), z=dict(axes=['x','y']))\n&gt;&gt;&gt; data_dict_1.add_data(x=[0,1,2], y=[0,1,2], z=[0,1,4])\n&gt;&gt;&gt; data_dict_2.add_data(x=[3,4], y=[3,4], z=[9,16])\n&gt;&gt;&gt; DataDict.same_structure(data_dict_1, data_dict_2)\nTrue\n</code></pre> <p>Note</p> <p>Make sure that both DataDicts have the exact same structure. This means that every item of every data field that appears when using the method <code>same_structure()</code> (<code>unit</code>, <code>axes</code>, and <code>label</code>) are identical to one another, except for <code>values</code>. Any slight difference will make this method fail due to conflicting structures.    </p> <p>The <code>append()</code> method will do this check before appending the 2 DataDict, and will only append them if the check returns <code>True</code>. Once we know that the structure is the same we can append them:</p> <pre><code>&gt;&gt;&gt; data_dict_1.append(data_dict_2)\n&gt;&gt;&gt; data_dict_1\n{'x': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2, 3, 4])},\n 'y': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2, 3, 4])},\n 'z': {'axes': ['x', 'y'], 'unit': '', 'label': '', 'values': array([ 0,  1,  4,  9, 16])}}\n</code></pre>"},{"location":"data/data_formats/#meta-data","title":"Meta Data","text":"<p>One of the advantages DataDicts have over regular python dictionaries is their ability to contain meta data. Meta data can be added to the entire DataDict or to individual data fields. Any object inside a <code>DataDict</code> whose key starts and ends with two underscores is considered meta data.</p> <p>We can simply add meta data manually by adding an item with the proper notation:</p> <pre><code>&gt;&gt;&gt; data_dict['__metadata__'] = 'important meta data'\n</code></pre> <p>Or we can use the <code>add_meta()</code> method:</p> <pre><code>&gt;&gt;&gt; data_dict.add_meta('sample_temperature', '10mK')\n&gt;&gt;&gt; data_dict\n{'x': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2])},\n 'y': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2])},\n 'z': {'axes': ['x', 'y'], 'unit': '', 'label': '', 'values': array([0, 1, 4])},\n '__metadata__': 'important meta data',\n '__sample_temperature__': '10mK'}\n</code></pre> <p>We can also add meta data to a specific data field by passing its name as the last argument:</p> <pre><code>&gt;&gt;&gt; data_dict.has_meta('sample_temperature')\nTrue\n</code></pre> <p>We can retrieve the meta data with the <code>meta_val()</code> method:</p> <pre><code>&gt;&gt;&gt; data_dict.meta_val('sample_temperature')\n'10mK'\n</code></pre> <p>We can also ask for a meta value from a specific data field by passing the data field as the second argument:</p> <pre><code>&gt;&gt;&gt; data_dict.meta_val('extra_metadata','x')\n'important meta data'\n</code></pre> <p>We can delete a specific meta field by using the <code>delete_meta()</code> method:</p> <pre><code>&gt;&gt;&gt; data_dict.delete_meta('metadata')\n&gt;&gt;&gt; data_dict.has_meta('metadata')\nFalse\n</code></pre> <p>This also work for meta data in data fields by passing the data field as the last argument:</p> <pre><code>&gt;&gt;&gt; data_dict.delete_meta('extra_metadata', 'x')\n&gt;&gt;&gt; data_dict['x']\n{'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2])}\n</code></pre> <p>We can delete all the meta data present in the DataDict with the <code>clear_meta()</code> method:</p> <pre><code>&gt;&gt;&gt; data_dict.add_meta('metadata', 'important meta data')\n&gt;&gt;&gt; data_dict.add_meta('extra_metadata', 'important meta data', 'x')\n&gt;&gt;&gt; data_dict.clear_meta()\n&gt;&gt;&gt; data_dict\n{'x': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2])},\n 'y': {'unit': 'm', 'axes': [], 'label': '', 'values': array([0, 1, 2])},\n 'z': {'axes': ['x', 'y'], 'unit': '', 'label': '', 'values': array([0, 1, 4])}}\n</code></pre> <p>Note</p> <p>There are 3 helper functions in the datadict module that help converting from meta data name to key. These are: </p> <ul> <li><code>is_meta_key()</code>,</li> <li><code>meta_key_to_name()</code></li> <li><code>meta_name_to_key()</code></li> </ul>"},{"location":"data/data_formats/#meshgrid-datadict","title":"Meshgrid DataDict","text":"<p>A dataset where the axes form a grid on which the dependent values reside.</p> <p>This is a more special case than DataDict, but a very common scenario. To support flexible grids, this class requires that all axes specify values for each datapoint, rather than a single row/column/dimension.</p> <p>For example, if we want to specify a 3-dimensional grid with axes <code>x</code>, <code>y</code>, <code>z</code>, the values of <code>x</code>, <code>y</code>, <code>z</code> all need to be 3-dimensional arrays; the same goes for all dependents that live on that grid. Then, say, <code>x[i,j,k]</code> is the x-coordinate of point <code>i</code>,<code>j</code>,<code>k</code> of the grid.</p> <p>This implies that a MeshgridDataDict can only have a single shape, i.e., all data values share the exact same nesting structure.</p> <p>For grids where the axes do not depend on each other, the correct values for the axes can be obtained from np.meshgrid (hence the name of the class).</p> <p>Example: a simple uniform 3x2 grid might look like this; x and y are the coordinates of the grid, and z is a function of the two:</p> <pre><code>    x = [[0, 0],\n         [1, 1],\n         [2, 2]]\n\n    y = [[0, 1],\n         [0, 1],\n         [0, 1]]\n\n    z = x * y =\n        [[0, 0],\n         [0, 1],\n         [0, 2]]\n</code></pre> <p>Note</p> <p>Internally we will typically assume that the nested axes are ordered from slow to fast, i.e., dimension 1 is the most outer axis, and dimension N of an N-dimensional array the most inner (i.e., the fastest changing one). This guarantees, for example, that the default implementation of <code>np.reshape</code> has the expected outcome. If, for some reason, the specified axes are not in that order (e.g., we might have <code>z</code> with <code>axes = ['x', 'y']</code>, but <code>x</code> is the fast axis in the data). In such a case, the guideline is that at creation of the meshgrid, the data should be transposed such that it conforms correctly to the order as given in the <code>axis = [...]</code> specification of the data. The function <code>datadict_to_meshgrid()</code> provides options for that.</p> <p>This implementation of <code>DataDictBase</code> consists only of three extra methods:</p> <ul> <li><code>MeshgridDataDict.shape</code></li> <li><code>MeshgridDataDict.validate</code></li> <li><code>MeshgridDataDict.reorder_axis</code></li> </ul> <p>So the only way of populating it is by manually modifying the <code>values</code> object of each data field since the tools for populating the DataDict are specific to the <code>DataDict</code> implementation.</p>"},{"location":"data/data_formats/#datadict-storage","title":"DataDict Storage","text":"<p>The datadict_storage.py module offers tools to help with saving DataDicts into disk by storing them in DDH5 files (HDF5 files that contains DataDicts inside).</p>"},{"location":"data/data_formats/#description-of-the-hdf5-storage-format","title":"Description of the HDF5 Storage Format","text":"<p>We use a simple mapping from DataDict to the HDF5 file. Within the file, a single DataDict is stored in a (top-level) group of the file. The data fields are datasets within that group.</p> <p>Global meta data of the DataDict are attributes of the group; field meta data are attributes of the dataset (incl., the <code>unit</code> and <code>axes</code> values). The meta data keys are given exactly like in the DataDict, i.e., includes the double underscore pre- and suffix.</p> <p>For more specific information on how HDF5 works please read the following documentation</p>"},{"location":"data/data_formats/#working-with-ddh5-files","title":"Working With DDH5 Files","text":"<p>When we are working with data, the first thing we usually want to do is to save it in disk. We can directly save an already existing DataDict into disk by calling the function <code>datadict_to_hdf5()</code>.</p> <pre><code>&gt;&gt;&gt; data_dict = DataDict(x=dict(values=np.array([0,1,2]), axes=[], __unit__='cm'), y=dict(values=np.array([3,4,5]), axes=['x']))\n&gt;&gt;&gt; data_dict\n{'x': {'values': array([0, 1, 2]), 'axes': [], '__unit__': 'cm'},\n 'y': {'values': array([3, 4, 5]), 'axes': ['x']}}\n&gt;&gt;&gt; datadict_to_hdf5(data_dict, 'folder\\data.ddh5')\n</code></pre> <p><code>datadict_to_hdf5()</code> will save data_dict in a file named 'data.ddh5' in whatever directory is passed to it, creating new folders if they don't already exists. The file will contain all of the data fields as well as all the metadata, with some more metadata generated to specify when the DataDict was created.</p> <p>Note</p> <p>Meta data is only written during initial writing of the dataset. If we're appending to existing datasets, we're not setting meta data anymore.</p> <p>Warning</p> <p>For this method to properly work the objects that are being saved in the <code>values</code> key of a data field must by a numpy array, or numpy array like.</p> <p>Data saved on disk is useless however if we do not have a way of accessing it. To do this we use the <code>datadict_from_hdf5()</code>:</p> <pre><code>&gt;&gt;&gt; loaded_data_dict = datadict_from_hdf5('folder\\data.ddh5')\n&gt;&gt;&gt; loaded_data_dict\n{'__creation_time_sec__': 1651159636.0,\n '__creation_time_str__': '2022-04-28 10:27:16',\n 'x': {'values': array([0, 1, 2]),\n  'axes': [],\n  '__shape__': (3,),\n  '__creation_time_sec__': 1651159636.0,\n  '__creation_time_str__': '2022-04-28 10:27:16',\n  '__unit__': 'cm',\n  'unit': '',\n  'label': ''},\n 'y': {'values': array([3, 4, 5]),\n  'axes': ['x'],\n  '__shape__': (3,),\n  '__creation_time_sec__': 1651159636.0,\n  '__creation_time_str__': '2022-04-28 10:27:16',\n  'unit': '',\n  'label': ''}}\n</code></pre> <p>We can see that the DataDict is the same one we saved earlier with the added metadata that indicates the time it was created.</p> <p>By default both <code>datadict_to_hdf5()</code> and <code>datadict_from_hdf5()</code> save and load the datadict in the 'data' group of the DDH5. Both of these can by changed by passing another group to the argument 'groupname'. We can see this if we manually create a second group and save a new DataDict there:</p> <pre><code>&gt;&gt;&gt; data_dict2 = DataDict(a=dict(values=np.array([0,1,2]), axes=[], __unit__='cm'), b=dict(values=np.array([3,4,5]), axes=['a']))\n&gt;&gt;&gt; with h5py.File('folder\\data.ddh5', 'a') as file:\n&gt;&gt;&gt;    file.create_group('other_data')\n&gt;&gt;&gt; datadict_to_hdf5(data_dict2, 'folder\\data.ddh5', groupname='other_data')\n</code></pre> <p>If we then load the DDH5 file like before we only see the first DataDict:</p> <pre><code>&gt;&gt;&gt; loaded_data_dict = datadict_from_hdf5('folder\\data.ddh5', 'data')\n&gt;&gt;&gt; loaded_data_dict\n{'__creation_time_sec__': 1651159636.0,\n '__creation_time_str__': '2022-04-28 10:27:16',\n 'x': {'values': array([0, 1, 2]),\n  'axes': [],\n  '__shape__': (3,),\n  '__creation_time_sec__': 1651159636.0,\n  '__creation_time_str__': '2022-04-28 10:27:16',\n  '__unit__': 'cm',\n  'unit': '',\n  'label': ''},\n 'y': {'values': array([3, 4, 5]),\n  'axes': ['x'],\n  '__shape__': (3,),\n  '__creation_time_sec__': 1651159636.0,\n  '__creation_time_str__': '2022-04-28 10:27:16',\n  'unit': '',\n  'label': ''}}\n</code></pre> <p>To see the other DataDict we can specify the group in the argument 'groupname':</p> <pre><code>&gt;&gt;&gt; loaded_data_dict = datadict_from_hdf5('folder\\data.ddh5', 'other_data')\n&gt;&gt;&gt; loaded_data_dict\n{'a': {'values': array([0, 1, 2]),\n  'axes': [],\n  '__shape__': (3,),\n  '__creation_time_sec__': 1651159636.0,\n  '__creation_time_str__': '2022-04-28 10:27:16',\n  '__unit__': 'cm',\n  'unit': '',\n  'label': ''},\n 'b': {'values': array([3, 4, 5]),\n  'axes': ['a'],\n  '__shape__': (3,),\n  '__creation_time_sec__': 1651159636.0,\n  '__creation_time_str__': '2022-04-28 10:27:16',\n  'unit': '',\n  'label': ''}}\n</code></pre> <p>We can also use <code>all_datadicts_from_hdf5()</code> to get a dictionary with all DataDicts in every group inside:</p> <pre><code>&gt;&gt;&gt; all_datadicts = all_datadicts_from_hdf5('folder\\data.ddh5')\n&gt;&gt;&gt; all_datadicts\n{'data': {'__creation_time_sec__': 1651159636.0,\n  '__creation_time_str__': '2022-04-28 10:27:16',\n  'x': {'values': array([0, 1, 2]),\n   'axes': [],\n   '__shape__': (3,),\n   '__creation_time_sec__': 1651159636.0,\n   '__creation_time_str__': '2022-04-28 10:27:16',\n   '__unit__': 'cm',\n   'unit': '',\n   'label': ''},\n  'y': {'values': array([3, 4, 5]),\n   'axes': ['x'],\n   '__shape__': (3,),\n   '__creation_time_sec__': 1651159636.0,\n   '__creation_time_str__': '2022-04-28 10:27:16',\n   'unit': '',\n   'label': ''}},\n 'other_data': {'a': {'values': array([0, 1, 2]),\n   'axes': [],\n   '__shape__': (3,),\n   '__creation_time_sec__': 1651159636.0,\n   '__creation_time_str__': '2022-04-28 10:27:16',\n   '__unit__': 'cm',\n   'unit': '',\n   'label': ''},\n  'b': {'values': array([3, 4, 5]),\n   'axes': ['a'],\n   '__shape__': (3,),\n   '__creation_time_sec__': 1651159636.0,\n   '__creation_time_str__': '2022-04-28 10:27:16',\n   'unit': '',\n   'label': ''}}}\n</code></pre>"},{"location":"data/data_formats/#ddh5-writer","title":"DDH5 Writer","text":"<p>Most times we want to be saving data to disk as soon as it is generated by an experiment (or iteration), instead of waiting to have a complete DataDict. To do this, Datadict_storage also offers a context manager with which we can safely save our incoming data.</p> <p>To use it we first need to create an empty DataDict that contains the structure of how the data is going to look like:</p> <pre><code>&gt;&gt;&gt; data_dict = DataDict(\n&gt;&gt;&gt; x = dict(unit='x_unit'),\n&gt;&gt;&gt; y = dict(unit='y_unit', axes=['x']))\n</code></pre> <p>With our created DataDict, we can start the <code>DDH5Writer</code> context manager and add data to our DataDict utilizing the <code>add_data()</code></p> <pre><code>&gt;&gt;&gt; with DDH5Writer(datadict=data_dict, basedir='./data/', name='Test') as writer:\n&gt;&gt;&gt;    for x in range(10):\n&gt;&gt;&gt;        writer.add_data(x=x, y=x**2)\nData location:  data\\2022-04-27\\2022-04-27T145308_a986867c-Test\\data.ddh5\n</code></pre> <p>The writer created the folder 'data' (because it did not exist before) and inside that folder, created another new folder for the current day and another new folder inside of it day folder for the the DataDict that we saved with the naming structure of <code>YYYY-mm-dd_THHMMSS_&lt;ID&gt;-&lt;name&gt;/&lt;filename&gt;.ddh5</code>, where name is the name parameter passed to the writer. The writer creates this structure such that when we run the writer again with new data, it will create another folder following the naming structure inside the current date folder. This way each new DataDict will be saved in the date it was generated with a time stamp in the name of the folder containing it.</p>"},{"location":"data/data_formats/#change-file-extension-and-time-format","title":"Change File Extension and Time Format","text":"<p>Finally, datadict_storage contains 2 module variables, 'DATAFILEXT' and 'TIMESTRFORMAT'.</p> <p>'DATAFILEXT' by default is 'ddh5', and it is used to specify the extension file of all of the module saving functions. Change this variable if you want your HDF5 to have a different extension by default, instead of passing it everytime.</p> <p>'TIMESTRFORMAT' specifies how the time is formated in the new metadata created when saving a DataDict. The default is: <code>\"%Y-%m-%d %H:%M:%S\"</code>, and it follows the structure of strftime.</p>"},{"location":"data/data_formats/#reference","title":"Reference","text":""},{"location":"data/data_formats/#datadict_1","title":"Datadict","text":"<p>datadict.py :</p> <p>Data classes we use throughout the plottr package, and tools to work on them.</p>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict","title":"<code>DataDict</code>","text":"<p>             Bases: <code>DataDictBase</code></p> <p>The most basic implementation of the DataDict class.</p> <p>It only enforces that the number of <code>records</code> per data field must be equal for all fields. This refers to the most outer dimension in case of nested arrays.</p> <p>The class further implements simple appending of datadicts through the <code>DataDict.append</code> method, as well as allowing addition of DataDict instances.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>class DataDict(DataDictBase):\n    \"\"\"\n    The most basic implementation of the DataDict class.\n\n    It only enforces that the number of `records` per data field must be\n    equal for all fields. This refers to the most outer dimension in case\n    of nested arrays.\n\n    The class further implements simple appending of datadicts through the\n    ``DataDict.append`` method, as well as allowing addition of DataDict\n    instances.\n    \"\"\"\n\n    def __add__(self, newdata: 'DataDict') -&gt; 'DataDict':\n        \"\"\"\n        Adding two datadicts by appending each data array.\n\n        Requires that the datadicts have the same structure.\n        Retains the meta information of the first array.\n\n        :param newdata: DataDict to be added.\n        :returns: combined DataDict.\n        :raises: ``ValueError`` if the structures are incompatible.\n        \"\"\"\n\n        # FIXME: remove shape\n        s = misc.unwrap_optional(self.structure(add_shape=False))\n        if DataDictBase.same_structure(self, newdata):\n            for k, v in self.data_items():\n                val0 = self[k]['values']\n                val1 = newdata[k]['values']\n                s[k]['values'] = np.append(\n                    self[k]['values'],\n                    newdata[k]['values'],\n                    axis=0\n                )\n            return s\n        else:\n            raise ValueError('Incompatible data structures.')\n\n    def append(self, newdata: \"DataDict\") -&gt; None:\n        \"\"\"\n        Append a datadict to this one by appending data values.\n\n        :param newdata: DataDict to append.\n        :raises: ``ValueError``, if the structures are incompatible.\n        \"\"\"\n        if not DataDictBase.same_structure(self, newdata):\n            raise ValueError('Incompatible data structures.')\n\n        newvals = {}\n        for k, v in newdata.data_items():\n            if isinstance(self[k]['values'], list) and isinstance(\n                    v['values'], list):\n                newvals[k] = self[k]['values'] + v['values']\n            else:\n                newvals[k] = np.append(\n                    self[k]['values'],\n                    v['values'],\n                    axis=0\n                )\n\n        # only actually\n        for k, v in newvals.items():\n            self[k]['values'] = v\n\n    def add_data(self, **kw: Any) -&gt; None:\n        # TODO: fill non-given data with nan or none\n        \"\"\"\n        Add data to all values. new data must be valid in itself.\n\n        This method is useful to easily add data without needing to specify\n        meta data or dependencies, etc.\n\n        :param kw: one array per data field (none can be omitted).\n        \"\"\"\n        dd = misc.unwrap_optional(self.structure(same_type=True))\n        for name, _ in dd.data_items():\n            if name not in kw:\n                kw[name] = None\n\n        records = self.to_records(**kw)\n        for name, datavals in records.items():\n            dd[name]['values'] = datavals\n\n        if dd.validate():\n            nrecords = self.nrecords()\n            if nrecords is not None and nrecords &gt; 0:\n                self.append(dd)\n            else:\n                for key, val in dd.data_items():\n                    self[key]['values'] = val['values']\n            self.validate()\n\n    # shape information and expansion\n\n    def nrecords(self) -&gt; Optional[int]:\n        \"\"\"\n        Gets the number of records in the dataset.\n\n        :return: The number of records in the dataset.\n        \"\"\"\n        self.validate()\n        for _, v in self.data_items():\n            return len(v['values'])\n        return None\n\n    def _inner_shapes(self) -&gt; Dict[str, Tuple[int, ...]]:\n        shapes = self.shapes()\n        return {k: v[1:] for k, v in shapes.items()}\n\n    def is_expanded(self) -&gt; bool:\n        \"\"\"\n        Determine if the DataDict is expanded.\n\n        :return: ``True`` if expanded. ``False`` if not.\n        \"\"\"\n        ishp = self._inner_shapes()\n        if set(ishp.values()) == {tuple()}:\n            return True\n        else:\n            return False\n\n    def is_expandable(self) -&gt; bool:\n        \"\"\"\n        Determine if the DataDict can be expanded.\n\n        Expansion flattens all nested data values to a 1D array. For doing so,\n        we require that all data fields that have nested/inner dimensions (i.e,\n        inside the `records` level) shape the inner shape.\n        In other words, all data fields must be of shape (N,) or (N, (shape)),\n        where shape is common to all that have a shape not equal to (N,).\n\n        :return: ``True`` if expandable. ``False`` otherwise.\n        \"\"\"\n        shp = self._inner_shapes()\n        if len(set(shp.values())) == 1:\n            return True\n        elif len(set(shp.values())) == 2 and tuple() in set(shp.values()):\n            return True\n        else:\n            return False\n\n    def expand(self) -&gt; 'DataDict':\n        \"\"\"\n        Expand nested values in the data fields.\n\n        Flattens all value arrays. If nested dimensions\n        are present, all data with non-nested dims will be repeated\n        accordingly -- each record is repeated to match the size of\n        the nested dims.\n\n        :return: The flattened dataset.\n        :raises: ``ValueError`` if data is not expandable.\n        \"\"\"\n        self.validate()\n        if not self.is_expandable():\n            raise ValueError('Data cannot be expanded.')\n        struct = misc.unwrap_optional(self.structure(add_shape=False))\n        ret = DataDict(**struct)\n\n        if self.is_expanded():\n            return self\n\n        ishp = self._inner_shapes()\n        size = max([int(np.prod(s)) for s in ishp.values()])\n\n        for k, v in self.data_items():\n            reps = size // np.prod(ishp[k])\n            if reps &gt; 1:\n                ret[k]['values'] = \\\n                    self[k]['values'].repeat(reps, axis=0).reshape(-1)\n            else:\n                ret[k]['values'] = self[k]['values'].reshape(-1)\n\n        return ret\n\n    # validation and sanitizing\n\n    def validate(self) -&gt; bool:\n        \"\"\"\n        Check dataset validity.\n\n        Beyond the checks performed in the base class ``DataDictBase``,\n        check whether the number of records is the same for all data fields.\n\n        :return: ``True`` if valid.\n        :raises: ``ValueError`` if invalid.\n        \"\"\"\n        if super().validate():\n            nvals = None\n            nvalsrc = None\n            msg = '\\n'\n\n            for n, v in self.data_items():\n                if type(v['values']) not in [np.ndarray,\n                                             np.ma.core.MaskedArray]:\n                    self[n]['values'] = np.array(v['values'])\n\n                if nvals is None:\n                    nvals = len(v['values'])\n                    nvalsrc = n\n                else:\n                    if len(v['values']) != nvals:\n                        msg += \" * '{}' has length {}, but have found {} in \" \\\n                               \"'{}'\\n\".format(\n                            n, len(v['values']), nvals, nvalsrc)\n\n            if msg != '\\n':\n                raise ValueError(msg)\n\n        return True\n\n    def sanitize(self) -&gt; \"DataDict\":\n        \"\"\"\n        Clean-up.\n\n        Beyond the tasks of the base class ``DataDictBase``:\n            * remove invalid entries as far as reasonable.\n\n        :return: sanitized DataDict.\n        \"\"\"\n        ret = super().sanitize()\n        return ret.remove_invalid_entries()\n\n    def remove_invalid_entries(self) -&gt; 'DataDict':\n        \"\"\"\n        Remove all rows that are ``None`` or ``np.nan`` in *all* dependents.\n\n        :return: The cleaned DataDict.\n        \"\"\"\n        ishp = self._inner_shapes()\n        idxs = []\n\n        # collect rows that are completely invalid\n        for d in self.dependents():\n\n            #  need to discriminate whether there are nested dims or not\n            if len(ishp[d]) == 0:\n                rows = self.data_vals(d)\n            else:\n                datavals = self.data_vals(d)\n                rows = datavals.reshape(-1, int(np.prod(ishp[d])))\n\n            _idxs: np.ndarray = np.array([])\n\n            # get indices of all rows that are fully None\n            if len(ishp[d]) == 0:\n                _newidxs = np.atleast_1d(np.asarray(rows is None)).nonzero()[0]\n            else:\n                _newidxs = np.atleast_1d(np.asarray(np.all(rows is None, axis=-1))).nonzero()[0]\n            _idxs = np.append(_idxs, _newidxs)\n\n            # get indices for all rows that are fully NaN. works only\n            # for some dtypes, so except TypeErrors.\n            try:\n                if len(ishp[d]) == 0:\n                    _newidxs = np.where(np.isnan(rows))[0]\n                else:\n                    _newidxs = np.where(np.all(np.isnan(rows), axis=-1))[0]\n                _idxs = np.append(_idxs, _newidxs)\n            except TypeError:\n                pass\n\n            idxs.append(_idxs)\n\n        if len(idxs) &gt; 0:\n            remove_idxs = reduce(np.intersect1d,\n                                 tuple(np.array(idxs).astype(int)))\n            for k, v in self.data_items():\n                v['values'] = np.delete(v['values'], remove_idxs, axis=0)\n\n        return self\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.__add__","title":"<code>__add__(newdata)</code>","text":"<p>Adding two datadicts by appending each data array.</p> <p>Requires that the datadicts have the same structure. Retains the meta information of the first array.</p> <p>Parameters:</p> Name Type Description Default <code>newdata</code> <code>DataDict</code> <p>DataDict to be added.</p> required <p>Returns:</p> Type Description <code>DataDict</code> <p>combined DataDict.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def __add__(self, newdata: 'DataDict') -&gt; 'DataDict':\n    \"\"\"\n    Adding two datadicts by appending each data array.\n\n    Requires that the datadicts have the same structure.\n    Retains the meta information of the first array.\n\n    :param newdata: DataDict to be added.\n    :returns: combined DataDict.\n    :raises: ``ValueError`` if the structures are incompatible.\n    \"\"\"\n\n    # FIXME: remove shape\n    s = misc.unwrap_optional(self.structure(add_shape=False))\n    if DataDictBase.same_structure(self, newdata):\n        for k, v in self.data_items():\n            val0 = self[k]['values']\n            val1 = newdata[k]['values']\n            s[k]['values'] = np.append(\n                self[k]['values'],\n                newdata[k]['values'],\n                axis=0\n            )\n        return s\n    else:\n        raise ValueError('Incompatible data structures.')\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.add_data","title":"<code>add_data(**kw)</code>","text":"<p>Add data to all values. new data must be valid in itself.</p> <p>This method is useful to easily add data without needing to specify meta data or dependencies, etc.</p> <p>Parameters:</p> Name Type Description Default <code>kw</code> <code>Any</code> <p>one array per data field (none can be omitted).</p> <code>{}</code> Source code in <code>labcore/data/datadict.py</code> <pre><code>def add_data(self, **kw: Any) -&gt; None:\n    # TODO: fill non-given data with nan or none\n    \"\"\"\n    Add data to all values. new data must be valid in itself.\n\n    This method is useful to easily add data without needing to specify\n    meta data or dependencies, etc.\n\n    :param kw: one array per data field (none can be omitted).\n    \"\"\"\n    dd = misc.unwrap_optional(self.structure(same_type=True))\n    for name, _ in dd.data_items():\n        if name not in kw:\n            kw[name] = None\n\n    records = self.to_records(**kw)\n    for name, datavals in records.items():\n        dd[name]['values'] = datavals\n\n    if dd.validate():\n        nrecords = self.nrecords()\n        if nrecords is not None and nrecords &gt; 0:\n            self.append(dd)\n        else:\n            for key, val in dd.data_items():\n                self[key]['values'] = val['values']\n        self.validate()\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.append","title":"<code>append(newdata)</code>","text":"<p>Append a datadict to this one by appending data values.</p> <p>Parameters:</p> Name Type Description Default <code>newdata</code> <code>DataDict</code> <p>DataDict to append.</p> required Source code in <code>labcore/data/datadict.py</code> <pre><code>def append(self, newdata: \"DataDict\") -&gt; None:\n    \"\"\"\n    Append a datadict to this one by appending data values.\n\n    :param newdata: DataDict to append.\n    :raises: ``ValueError``, if the structures are incompatible.\n    \"\"\"\n    if not DataDictBase.same_structure(self, newdata):\n        raise ValueError('Incompatible data structures.')\n\n    newvals = {}\n    for k, v in newdata.data_items():\n        if isinstance(self[k]['values'], list) and isinstance(\n                v['values'], list):\n            newvals[k] = self[k]['values'] + v['values']\n        else:\n            newvals[k] = np.append(\n                self[k]['values'],\n                v['values'],\n                axis=0\n            )\n\n    # only actually\n    for k, v in newvals.items():\n        self[k]['values'] = v\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.expand","title":"<code>expand()</code>","text":"<p>Expand nested values in the data fields.</p> <p>Flattens all value arrays. If nested dimensions are present, all data with non-nested dims will be repeated accordingly -- each record is repeated to match the size of the nested dims.</p> <p>Returns:</p> Type Description <code>DataDict</code> <p>The flattened dataset.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def expand(self) -&gt; 'DataDict':\n    \"\"\"\n    Expand nested values in the data fields.\n\n    Flattens all value arrays. If nested dimensions\n    are present, all data with non-nested dims will be repeated\n    accordingly -- each record is repeated to match the size of\n    the nested dims.\n\n    :return: The flattened dataset.\n    :raises: ``ValueError`` if data is not expandable.\n    \"\"\"\n    self.validate()\n    if not self.is_expandable():\n        raise ValueError('Data cannot be expanded.')\n    struct = misc.unwrap_optional(self.structure(add_shape=False))\n    ret = DataDict(**struct)\n\n    if self.is_expanded():\n        return self\n\n    ishp = self._inner_shapes()\n    size = max([int(np.prod(s)) for s in ishp.values()])\n\n    for k, v in self.data_items():\n        reps = size // np.prod(ishp[k])\n        if reps &gt; 1:\n            ret[k]['values'] = \\\n                self[k]['values'].repeat(reps, axis=0).reshape(-1)\n        else:\n            ret[k]['values'] = self[k]['values'].reshape(-1)\n\n    return ret\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.is_expandable","title":"<code>is_expandable()</code>","text":"<p>Determine if the DataDict can be expanded.</p> <p>Expansion flattens all nested data values to a 1D array. For doing so, we require that all data fields that have nested/inner dimensions (i.e, inside the <code>records</code> level) shape the inner shape. In other words, all data fields must be of shape (N,) or (N, (shape)), where shape is common to all that have a shape not equal to (N,).</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if expandable. <code>False</code> otherwise.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def is_expandable(self) -&gt; bool:\n    \"\"\"\n    Determine if the DataDict can be expanded.\n\n    Expansion flattens all nested data values to a 1D array. For doing so,\n    we require that all data fields that have nested/inner dimensions (i.e,\n    inside the `records` level) shape the inner shape.\n    In other words, all data fields must be of shape (N,) or (N, (shape)),\n    where shape is common to all that have a shape not equal to (N,).\n\n    :return: ``True`` if expandable. ``False`` otherwise.\n    \"\"\"\n    shp = self._inner_shapes()\n    if len(set(shp.values())) == 1:\n        return True\n    elif len(set(shp.values())) == 2 and tuple() in set(shp.values()):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.is_expanded","title":"<code>is_expanded()</code>","text":"<p>Determine if the DataDict is expanded.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if expanded. <code>False</code> if not.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def is_expanded(self) -&gt; bool:\n    \"\"\"\n    Determine if the DataDict is expanded.\n\n    :return: ``True`` if expanded. ``False`` if not.\n    \"\"\"\n    ishp = self._inner_shapes()\n    if set(ishp.values()) == {tuple()}:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.nrecords","title":"<code>nrecords()</code>","text":"<p>Gets the number of records in the dataset.</p> <p>Returns:</p> Type Description <code>Optional[int]</code> <p>The number of records in the dataset.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def nrecords(self) -&gt; Optional[int]:\n    \"\"\"\n    Gets the number of records in the dataset.\n\n    :return: The number of records in the dataset.\n    \"\"\"\n    self.validate()\n    for _, v in self.data_items():\n        return len(v['values'])\n    return None\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.remove_invalid_entries","title":"<code>remove_invalid_entries()</code>","text":"<p>Remove all rows that are <code>None</code> or <code>np.nan</code> in all dependents.</p> <p>Returns:</p> Type Description <code>DataDict</code> <p>The cleaned DataDict.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def remove_invalid_entries(self) -&gt; 'DataDict':\n    \"\"\"\n    Remove all rows that are ``None`` or ``np.nan`` in *all* dependents.\n\n    :return: The cleaned DataDict.\n    \"\"\"\n    ishp = self._inner_shapes()\n    idxs = []\n\n    # collect rows that are completely invalid\n    for d in self.dependents():\n\n        #  need to discriminate whether there are nested dims or not\n        if len(ishp[d]) == 0:\n            rows = self.data_vals(d)\n        else:\n            datavals = self.data_vals(d)\n            rows = datavals.reshape(-1, int(np.prod(ishp[d])))\n\n        _idxs: np.ndarray = np.array([])\n\n        # get indices of all rows that are fully None\n        if len(ishp[d]) == 0:\n            _newidxs = np.atleast_1d(np.asarray(rows is None)).nonzero()[0]\n        else:\n            _newidxs = np.atleast_1d(np.asarray(np.all(rows is None, axis=-1))).nonzero()[0]\n        _idxs = np.append(_idxs, _newidxs)\n\n        # get indices for all rows that are fully NaN. works only\n        # for some dtypes, so except TypeErrors.\n        try:\n            if len(ishp[d]) == 0:\n                _newidxs = np.where(np.isnan(rows))[0]\n            else:\n                _newidxs = np.where(np.all(np.isnan(rows), axis=-1))[0]\n            _idxs = np.append(_idxs, _newidxs)\n        except TypeError:\n            pass\n\n        idxs.append(_idxs)\n\n    if len(idxs) &gt; 0:\n        remove_idxs = reduce(np.intersect1d,\n                             tuple(np.array(idxs).astype(int)))\n        for k, v in self.data_items():\n            v['values'] = np.delete(v['values'], remove_idxs, axis=0)\n\n    return self\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.sanitize","title":"<code>sanitize()</code>","text":"<p>Clean-up.</p> <p>Beyond the tasks of the base class <code>DataDictBase</code>:     * remove invalid entries as far as reasonable.</p> <p>Returns:</p> Type Description <code>DataDict</code> <p>sanitized DataDict.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def sanitize(self) -&gt; \"DataDict\":\n    \"\"\"\n    Clean-up.\n\n    Beyond the tasks of the base class ``DataDictBase``:\n        * remove invalid entries as far as reasonable.\n\n    :return: sanitized DataDict.\n    \"\"\"\n    ret = super().sanitize()\n    return ret.remove_invalid_entries()\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDict.validate","title":"<code>validate()</code>","text":"<p>Check dataset validity.</p> <p>Beyond the checks performed in the base class <code>DataDictBase</code>, check whether the number of records is the same for all data fields.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if valid.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def validate(self) -&gt; bool:\n    \"\"\"\n    Check dataset validity.\n\n    Beyond the checks performed in the base class ``DataDictBase``,\n    check whether the number of records is the same for all data fields.\n\n    :return: ``True`` if valid.\n    :raises: ``ValueError`` if invalid.\n    \"\"\"\n    if super().validate():\n        nvals = None\n        nvalsrc = None\n        msg = '\\n'\n\n        for n, v in self.data_items():\n            if type(v['values']) not in [np.ndarray,\n                                         np.ma.core.MaskedArray]:\n                self[n]['values'] = np.array(v['values'])\n\n            if nvals is None:\n                nvals = len(v['values'])\n                nvalsrc = n\n            else:\n                if len(v['values']) != nvals:\n                    msg += \" * '{}' has length {}, but have found {} in \" \\\n                           \"'{}'\\n\".format(\n                        n, len(v['values']), nvals, nvalsrc)\n\n        if msg != '\\n':\n            raise ValueError(msg)\n\n    return True\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase","title":"<code>DataDictBase</code>","text":"<p>             Bases: <code>dict</code></p> <p>Simple data storage class that is based on a regular dictionary.</p> <p>This base class does not make assumptions about the structure of the values. This is implemented in inheriting classes.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>class DataDictBase(dict):\n    \"\"\"\n    Simple data storage class that is based on a regular dictionary.\n\n    This base class does not make assumptions about the structure of the\n    values. This is implemented in inheriting classes.\n    \"\"\"\n\n    def __init__(self, **kw: Any):\n        super().__init__(self, **kw)\n        self.d_ = DataDictBase._DataAccess(self) \n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Check for content equality of two datadicts.\"\"\"\n        if not isinstance(other, DataDictBase):\n            return False\n        else:\n            return datasets_are_equal(self, other)\n\n    def __repr__(self) -&gt; str:\n        ret = \"\"\n        for i, dn in enumerate(self.dependents()):\n            if i &gt; 0:\n                ret += \"\\n\"\n            ret += f\"{self.label(dn)}: {self[dn]['values'].shape}\"\n            for ax in self.axes(dn):\n                ret += f\"\\n  \\u2319 {self.label(ax)}: {self[ax]['values'].shape}\"\n        return ret\n\n    # Assignment and retrieval of data and meta data\n\n    @staticmethod\n    def _is_meta_key(key: str) -&gt; bool:\n        return is_meta_key(key)\n\n    @staticmethod\n    def _meta_key_to_name(key: str) -&gt; str:\n        return meta_key_to_name(key)\n\n    @staticmethod\n    def _meta_name_to_key(name: str) -&gt; str:\n        return meta_name_to_key(name)\n\n    @staticmethod\n    def to_records(**data: Any) -&gt; Dict[str, np.ndarray]:\n        \"\"\"Convert data to records that can be added to the ``DataDict``.\n        All data is converted to np.array, and reshaped such that the first dimension of all resulting\n        arrays have the same length (chosen to be the smallest possible number\n        that does not alter any shapes beyond adding a length-1 dimension as\n        first dimension, if necessary).\n\n        If a data field is given as ``None``, it will be converted to ``numpy.array([numpy.nan])``.\n\n        :param data: keyword arguments for each data field followed by data.\n        :returns: Dictionary with properly shaped data.\n        \"\"\"\n        records: Dict[str, np.ndarray] = {}\n\n        seqtypes = (np.ndarray, tuple, list)\n        nantypes = (type(None), )\n\n        for k, v in data.items():\n            if isinstance(v, seqtypes):\n                records[k] = np.array(v)\n            elif isinstance(v, nantypes):\n                records[k] = np.array([np.nan])\n            else:\n                records[k] = np.array([v])\n\n        possible_nrecords = {}\n        for k, v in records.items():\n            possible_nrecords[k] = [1, v.shape[0]]\n\n        commons = []\n        for k, v in possible_nrecords.items():\n            for n in v:\n                if n in commons:\n                    continue\n                is_common = True\n                for kk, vv in possible_nrecords.items():\n                    if n not in vv:\n                        is_common = False\n                if is_common:\n                    commons.append(n)\n\n        nrecs = max(commons)\n\n        for k, v in records.items():\n            shp = v.shape\n            if nrecs == 1 and shp[0] &gt; 1:\n                newshp = tuple([1] + list(shp))\n                records[k] = v.reshape(newshp)\n        return records\n\n    def data_items(self) -&gt; Iterator[Tuple[str, Dict[str, Any]]]:\n        \"\"\"\n        Generator for data field items.\n\n        Like dict.items(), but ignores meta data.\n\n        :return: Generator yielding first the key of the data field and second its value.\n        \"\"\"\n        for k, v in self.items():\n            if not self._is_meta_key(k):\n                yield k, v\n\n    def meta_items(self, data: Union[str, None] = None,\n                   clean_keys: bool = True) -&gt; Iterator[Tuple[str, Dict[str, Any]]]:\n        \"\"\"\n        Generator for meta items.\n\n        Like dict.items(), but yields `only` meta entries.\n        The keys returned do not contain the underscores used internally.\n\n        :param data: If ``None`` iterate over global meta data.\n                     If it's the name of a data field, iterate over the meta\n                     information of that field.\n        :param clean_keys: If `True`, remove the underscore pre/suffix.\n        :return: Generator yielding first the key of the data field and second its value.\n\n        \"\"\"\n        if data is None:\n            for k, v in self.items():\n                if self._is_meta_key(k):\n                    if clean_keys:\n                        n = self._meta_key_to_name(k)\n                    else:\n                        n = k\n                    yield n, v\n\n        else:\n            for k, v in self[data].items():\n                if self._is_meta_key(k):\n                    if clean_keys:\n                        n = self._meta_key_to_name(k)\n                    else:\n                        n = k\n                    yield n, v\n\n    def data_vals(self, key: str) -&gt; np.ndarray:\n        \"\"\"\n        Return the data values of field ``key``.\n\n        Equivalent to ``DataDict['key'].values``.\n\n        :param key: Name of the data field.\n        :return: Values of the data field.\n        \"\"\"\n        if self._is_meta_key(key):\n            raise ValueError(f\"{key} is a meta key.\")\n        return self[key].get('values', np.array([]))\n\n    def has_meta(self, key: str) -&gt; bool:\n        \"\"\"Check whether meta field exists in the dataset.\n\n        :return: ``True`` if it exists, ``False`` if it doesn't.\n        \"\"\"\n        k = self._meta_name_to_key(key)\n        if k in self:\n            return True\n        else:\n            for key, field_dict in self.data_items():\n                if k in field_dict:\n                    return True\n            return False\n\n    def meta_val(self, key: str, data: Union[str, None] = None) -&gt; Any:\n        \"\"\"\n        Return the value of meta field ``key`` (given without underscore).\n\n        :param key: Name of the meta field.\n        :param data: ``None`` for global meta; name of data field for data meta.\n        :return: The value of the meta information.\n        \"\"\"\n        k = self._meta_name_to_key(key)\n        if data is None:\n            return self[k]\n        else:\n            return self[data][k]\n\n    def add_meta(self, key: str, value: Any, data: Union[str, None] = None) -&gt; None:\n        \"\"\"\n        Add meta info to the dataset.\n\n        If the key already exists, meta info will be overwritten.\n\n        :param key: Name of the meta field (without underscores).\n        :param value: Value of the meta information.\n        :param data: If ``None``, meta will be global; otherwise assigned to\n                     data field ``data``.\n\n        \"\"\"\n        key = self._meta_name_to_key(key)\n        if data is None:\n            self[key] = value\n        else:\n            self[data][key] = value\n\n    set_meta = add_meta\n\n    def delete_meta(self, key: str, data: Union[str, None] = None) -&gt; None:\n        \"\"\"\n        Deletes specific meta data.\n\n        :param key: Name of the meta field to remove.\n        :param data: If ``None``, this affects global meta; otherwise remove\n                     from data field ``data``.\n\n        \"\"\"\n        key = self._meta_name_to_key(key)\n        if data is None:\n            del self[key]\n        else:\n            del self[data][key]\n\n    def clear_meta(self, data: Union[str, None] = None) -&gt; None:\n        \"\"\"\n        Deletes all meta data.\n\n        :param data: If not ``None``, delete all meta only from specified data field ``data``.\n                     Else, deletes all top-level meta, as well as meta for all data fields.\n\n        \"\"\"\n        if data is None:\n            meta_list = [k for k, _ in self.meta_items()]\n            for m in meta_list:\n                self.delete_meta(m)\n\n            for d, _ in self.data_items():\n                data_meta_list = [k for k, _ in self.meta_items(d)]\n                for m in data_meta_list:\n                    self.delete_meta(m, d)\n\n        else:\n            data_meta_list = [m for m, _ in self.meta_items(data)]\n            for m in data_meta_list:\n                self.delete_meta(m, data)\n\n    def extract(self: T, data: List[str], include_meta: bool = True,\n                copy: bool = True, sanitize: bool = True) -&gt; T:\n        \"\"\"\n        Extract data from a dataset.\n\n        Return a new datadict with all fields specified in ``data`` included.\n        Will also take any axes fields along that have not been explicitly\n        specified. Will return empty if ``data`` consists of only axes fields.\n\n        :param data: Data field or list of data fields to be extracted.\n        :param include_meta: If ``True``, include the global meta data.\n                             data meta will always be included.\n        :param copy: If ``True``, data fields will be `deep copies &lt;https://docs.python.org/3/library/copy.html&gt;`__\n                     of the original.\n        :param sanitize: If ``True``, will run DataDictBase.sanitize before\n                         returning.\n        :return: New DataDictBase containing only requested fields.\n        \"\"\"\n        if isinstance(data, str):\n            data = [data]\n        else:\n            data = data.copy()\n\n        # include all the axes used by the data.\n        for d in data:\n            for a in self.axes(d):\n                if a not in data:\n                    data.append(a)\n\n        ret = self.__class__()\n        for d in data:\n            if copy:\n                ret[d] = cp.deepcopy(self[d])\n            else:\n                ret[d] = self[d]\n\n        if include_meta:\n            for k, v in self.meta_items():\n                if copy:\n                    ret.add_meta(k, cp.deepcopy(v))\n                else:\n                    ret.add_meta(k, v)\n\n        if sanitize:\n            ret = ret.sanitize()\n\n        ret.validate()\n        return ret\n\n    # info about structure\n\n    @staticmethod\n    def same_structure(*data: T,\n                       check_shape: bool = False) -&gt; bool:\n        \"\"\"\n        Check if all supplied DataDicts share the same data structure\n        (i.e., dependents and axes).\n\n        Ignores meta data and values. Checks also for matching shapes if\n        `check_shape` is `True`.\n\n        :param data: The data sets to compare.\n        :param check_shape: Whether to include shape check in the comparison.\n        :return: ``True`` if the structure matches for all, else ``False``.\n        \"\"\"\n        if len(data) &lt; 2:\n            return True\n\n        def empty_structure(d: T) -&gt; T:\n            s = misc.unwrap_optional(d.structure(include_meta=False, add_shape=check_shape))\n            for k, v in s.data_items():\n                if 'values' in v:\n                    del s[k]['values']\n            return s\n\n        s0 = empty_structure(data[0])\n        for d in data[1:]:\n            if d is None:\n                return False\n            if s0 != empty_structure(d):\n                return False\n\n        return True\n\n    def structure(self: T, add_shape: bool = False,\n                  include_meta: bool = True,\n                  same_type: bool = False,\n                  remove_data: Optional[List[str]] = None) -&gt; Optional[T]:\n        \"\"\"\n        Get the structure of the DataDict.\n\n        Return the datadict without values (`value` omitted in the dict).\n\n        :param add_shape: Deprecated -- ignored.\n        :param include_meta: If `True`, include the meta information in\n                             the returned dict.\n        :param same_type: If `True`, return type will be the one of the\n                          object this is called on. Else, DataDictBase.\n        :param remove_data: any data fields listed will be removed from\n                            the result, also when listed in any axes.\n\n        :return: The DataDict containing the structure only. The exact type\n                     is the same as the type of ``self``.\n\n        \"\"\"\n        if add_shape:\n            warnings.warn(\"'add_shape' is deprecated and will be ignored\",\n                          DeprecationWarning)\n        add_shape = False\n\n        if remove_data is None:\n            remove_data = []\n\n        if self.validate():\n            s = self.__class__()\n            for n, v in self.data_items():\n                if n not in remove_data:\n                    v2 = v.copy()\n                    v2['values'] = []\n                    s[n] = cp.deepcopy(v2)\n                    if 'axes' in s[n]:\n                        for r in remove_data:\n                            if r in s[n]['axes']:\n                                i = s[n]['axes'].index(r)\n                                s[n]['axes'].pop(i)\n\n            if include_meta:\n                for n, v in self.meta_items():\n                    s.add_meta(n, v)\n            else:\n                s.clear_meta()\n\n            if same_type:\n                s = self.__class__(**s)\n\n            return s\n        return None\n\n\n    def nbytes(self, name: Optional[str]=None) -&gt; Optional[int]:\n        \"\"\"Get the size of data.\n\n        :param name: Name of the data field. if none, return size of \n            entire datadict.\n        :return: size in bytes.\n        \"\"\"\n        if self.validate():\n            if name is None:\n                return sum([v['values'].size * v['values'].itemsize \n                            for _, v in self.data_items()])\n            else:\n                return self.data_vals(name).size * self.data_vals(name).itemsize\n\n        return None\n\n\n    def label(self, name: str) -&gt; Optional[str]:\n        \"\"\"\n        Get the label for a data field. If no label is present returns the\n        name of the data field as the label. If a unit is present, it will\n        be appended at the end in brackets: \"label (unit)\".\n\n        :param name: Name of the data field.\n        :return: Labelled name.\n        \"\"\"\n        if self.validate():\n            if name not in self:\n                raise ValueError(\"No field '{}' present.\".format(name))\n\n            if self[name]['label'] != '':\n                n = self[name]['label']\n            else:\n                n = name\n\n            if self[name]['unit'] != '':\n                n += ' ({})'.format(self[name]['unit'])\n\n            return n\n        return None\n\n    def axes_are_compatible(self) -&gt; bool:\n        \"\"\"\n        Check if all dependent data fields have the same axes.\n\n        This includes axes order.\n\n        :return: ``True`` or ``False``.\n        \"\"\"\n        axes = []\n        for i, d in enumerate(self.dependents()):\n            if i == 0:\n                axes = self.axes(d)\n            else:\n                if self.axes(d) != axes:\n                    return False\n        return True\n\n    def axes(self, data: Union[Sequence[str], str, None] = None) -&gt; List[str]:\n        \"\"\"\n        Return a list of axes.\n\n        :param data: if ``None``, return all axes present in the dataset,\n                     otherwise only the axes of the dependent ``data``.\n        :return: The list of axes.\n        \"\"\"\n        lst = []\n        if data is None:\n            for k, v in self.data_items():\n                if 'axes' in v:\n                    for n in v['axes']:\n                        if n not in lst and self[n].get('axes', []) == []:\n                            lst.append(n)\n        else:\n            if isinstance(data, str):\n                dataseq: Sequence[str] = (data,)\n            else:\n                dataseq = data\n            for n in dataseq:\n                if 'axes' not in self[n]:\n                    continue\n                for m in self[n]['axes']:\n                    if m not in lst and self[m].get('axes', []) == []:\n                        lst.append(m)\n\n        return lst\n\n    def dependents(self) -&gt; List[str]:\n        \"\"\"\n        Get all dependents in the dataset.\n\n        :return: A list of the names of dependents.\n        \"\"\"\n        ret = []\n        for n, v in self.data_items():\n            if len(v.get('axes', [])) != 0:\n                ret.append(n)\n        return ret\n\n    def shapes(self) -&gt; Dict[str, Tuple[int, ...]]:\n        \"\"\"\n        Get the shapes of all data fields.\n\n        :return: A dictionary of the form ``{key : shape}``, where shape is the\n                 np.shape-tuple of the data with name ``key``.\n\n        \"\"\"\n        shapes = {}\n        for k, v in self.data_items():\n            shapes[k] = np.array(self.data_vals(k)).shape\n\n        return shapes\n\n    # validation and sanitizing\n\n    def validate(self) -&gt; bool:\n        \"\"\"\n        Check the validity of the dataset.\n\n        Checks performed:\n            * All axes specified with dependents must exist as data fields.\n\n        Other tasks performed:\n            * ``unit`` keys are created if omitted.\n            * ``label`` keys are created if omitted.\n            * ``shape`` meta information is updated with the correct values\n              (only if present already).\n\n        :return: ``True`` if valid, ``False`` if invalid.\n        :raises: ``ValueError`` if invalid.\n        \"\"\"\n        self._update_data_access()\n\n        msg = '\\n'\n        for n, v in self.data_items():\n\n            if 'axes' in v:\n                for na in v['axes']:\n                    if na not in self:\n                        msg += \" * '{}' has axis '{}', but no field \" \\\n                               \"with name '{}' registered.\\n\".format(\n                            n, na, na)\n                    elif na not in self.axes():\n                        msg += \" * '{}' has axis '{}', but no independent \" \\\n                               \"with name '{}' registered.\\n\".format(\n                            n, na, na)\n            else:\n                v['axes'] = []\n\n            if 'unit' not in v:\n                v['unit'] = ''\n\n            if 'label' not in v:\n                v['label'] = ''\n\n            vals = v.get('values', [])\n            if type(vals) not in [np.ndarray, np.ma.core.MaskedArray]:\n                vals = np.array(vals)\n            v['values'] = vals\n\n        if msg != '\\n':\n            raise ValueError(msg)\n\n        return True\n\n    def remove_unused_axes(self: T) -&gt; T:\n        \"\"\"\n        Removes axes not associated with dependents.\n\n        :return: Cleaned dataset.\n        \"\"\"\n        dependents = self.dependents()\n        unused = []\n\n        for n, v in self.data_items():\n            used = False\n            if n not in dependents:\n                for m in dependents:\n                    if n in self[m]['axes']:\n                        used = True\n            else:\n                used = True\n            if not used:\n                unused.append(n)\n\n        for u in unused:\n            del self[u]\n\n        return self\n\n    def sanitize(self: T) -&gt; T:\n        \"\"\"\n        Clean-up tasks:\n            * Removes unused axes.\n\n        :return: Sanitized dataset.\n        \"\"\"\n        return self.remove_unused_axes()\n\n    # axes order tools\n\n    def reorder_axes_indices(self, name: str,\n                             **pos: int) -&gt; Tuple[Tuple[int, ...], List[str]]:\n        \"\"\"\n        Get the indices that can reorder axes in a given way.\n\n        :param name: Name of the data field of which we want to reorder axes.\n        :param pos: New axes position in the form ``axis_name = new_position``.\n                    Non-specified axes positions are adjusted automatically.\n        :return: The tuple of new indices, and the list of axes names in the\n                 new order.\n\n        \"\"\"\n        axlist = self.axes(name)\n        order = misc.reorder_indices_from_new_positions(axlist, **pos)\n        return order, [axlist[i] for i in order]\n\n    def reorder_axes(self: T, data_names: Union[str, Sequence[str], None] = None,\n                     **pos: int) -&gt; T:\n        \"\"\"\n        Reorder data axes.\n\n        :param data_names: Data name(s) for which to reorder the axes.\n                           If None, apply to all dependents.\n        :param pos: New axes position in the form ``axis_name = new_position``.\n                    Non-specified axes positions are adjusted automatically.\n\n        :return: Dataset with re-ordered axes (not a copy)\n        \"\"\"\n        if data_names is None:\n            data_names = self.dependents()\n        if isinstance(data_names, str):\n            data_names = [data_names]\n\n        for n in data_names:\n            neworder, newaxes = self.reorder_axes_indices(n, **pos)\n            self[n]['axes'] = newaxes\n\n        self.validate()\n        return self\n\n    def copy(self: T) -&gt; T:\n        \"\"\"\n        Make a copy of the dataset.\n\n        :return: A copy of the dataset.\n        \"\"\"\n        logger.debug(f'copying a dataset with size {self.nbytes()}')\n        ret = self.structure()\n        assert ret is not None\n\n        for k, v in self.data_items():\n            ret[k]['values'] = self.data_vals(k).copy()\n        return ret\n\n    def astype(self: T, dtype: np.dtype) -&gt; T:\n        \"\"\"\n        Convert all data values to given dtype.\n\n        :param dtype: np dtype.\n        :return: Dataset, with values as given type (not a copy)\n        \"\"\"\n        for k, v in self.data_items():\n            vals = v['values']\n            if type(v['values']) not in [np.ndarray, np.ma.core.MaskedArray]:\n                vals = np.array(v['values'])\n            self[k]['values'] = vals.astype(dtype)\n\n        return self\n\n    def mask_invalid(self: T) -&gt; T:\n        \"\"\"\n        Mask all invalid data in all values.\n        :return: Copy of the dataset with invalid entries (nan/None) masked.\n        \"\"\"\n        for d, _ in self.data_items():\n            arr = self.data_vals(d)\n            vals = np.ma.masked_where(num.is_invalid(arr), arr, copy=True)\n            try:\n                vals.fill_value = np.nan\n            except TypeError:\n                vals.fill_value = -9999\n            self[d]['values'] = vals\n\n        return self\n\n    class _DataAccess:\n        def __init__(self, parent: \"DataDictBase\") -&gt; None:\n            self._parent = parent\n\n        def __getattribute__(self, __name: str) -&gt; Any:\n            parent = super(DataDictBase._DataAccess, self).__getattribute__('_parent')\n\n            if __name in [k for k, _ in parent.data_items()]:\n                return parent.data_vals(__name)\n            else:\n                return super(DataDictBase._DataAccess, self).__getattribute__(__name)\n\n        def __setattr__(self, __name: str, __value: Any) -&gt; None:\n            # this check: make sure that we can set the parent correctly in the\n            # constructor.\n            if hasattr(self, '_parent'):\n                if __name in [k for k, _ in self._parent.data_items()]:\n                    self._parent[__name]['values'] = __value\n\n                # still allow setting random things, essentially.\n                else:\n                    super(DataDictBase._DataAccess, self).__setattr__(__name, __value)\n            else:\n                super(DataDictBase._DataAccess, self).__setattr__(__name, __value)\n\n    def _update_data_access(self) -&gt; None:\n        for d, i in self.data_items():\n            self.d_.__dict__[d] = None\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Check for content equality of two datadicts.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Check for content equality of two datadicts.\"\"\"\n    if not isinstance(other, DataDictBase):\n        return False\n    else:\n        return datasets_are_equal(self, other)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.add_meta","title":"<code>add_meta(key, value, data=None)</code>","text":"<p>Add meta info to the dataset.</p> <p>If the key already exists, meta info will be overwritten.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the meta field (without underscores).</p> required <code>value</code> <code>Any</code> <p>Value of the meta information.</p> required <code>data</code> <code>Union[str, None]</code> <p>If <code>None</code>, meta will be global; otherwise assigned to data field <code>data</code>.</p> <code>None</code> Source code in <code>labcore/data/datadict.py</code> <pre><code>def add_meta(self, key: str, value: Any, data: Union[str, None] = None) -&gt; None:\n    \"\"\"\n    Add meta info to the dataset.\n\n    If the key already exists, meta info will be overwritten.\n\n    :param key: Name of the meta field (without underscores).\n    :param value: Value of the meta information.\n    :param data: If ``None``, meta will be global; otherwise assigned to\n                 data field ``data``.\n\n    \"\"\"\n    key = self._meta_name_to_key(key)\n    if data is None:\n        self[key] = value\n    else:\n        self[data][key] = value\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.astype","title":"<code>astype(dtype)</code>","text":"<p>Convert all data values to given dtype.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>dtype</code> <p>np dtype.</p> required <p>Returns:</p> Type Description <code>T</code> <p>Dataset, with values as given type (not a copy)</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def astype(self: T, dtype: np.dtype) -&gt; T:\n    \"\"\"\n    Convert all data values to given dtype.\n\n    :param dtype: np dtype.\n    :return: Dataset, with values as given type (not a copy)\n    \"\"\"\n    for k, v in self.data_items():\n        vals = v['values']\n        if type(v['values']) not in [np.ndarray, np.ma.core.MaskedArray]:\n            vals = np.array(v['values'])\n        self[k]['values'] = vals.astype(dtype)\n\n    return self\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.axes","title":"<code>axes(data=None)</code>","text":"<p>Return a list of axes.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[Sequence[str], str, None]</code> <p>if <code>None</code>, return all axes present in the dataset, otherwise only the axes of the dependent <code>data</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>The list of axes.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def axes(self, data: Union[Sequence[str], str, None] = None) -&gt; List[str]:\n    \"\"\"\n    Return a list of axes.\n\n    :param data: if ``None``, return all axes present in the dataset,\n                 otherwise only the axes of the dependent ``data``.\n    :return: The list of axes.\n    \"\"\"\n    lst = []\n    if data is None:\n        for k, v in self.data_items():\n            if 'axes' in v:\n                for n in v['axes']:\n                    if n not in lst and self[n].get('axes', []) == []:\n                        lst.append(n)\n    else:\n        if isinstance(data, str):\n            dataseq: Sequence[str] = (data,)\n        else:\n            dataseq = data\n        for n in dataseq:\n            if 'axes' not in self[n]:\n                continue\n            for m in self[n]['axes']:\n                if m not in lst and self[m].get('axes', []) == []:\n                    lst.append(m)\n\n    return lst\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.axes_are_compatible","title":"<code>axes_are_compatible()</code>","text":"<p>Check if all dependent data fields have the same axes.</p> <p>This includes axes order.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> or <code>False</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def axes_are_compatible(self) -&gt; bool:\n    \"\"\"\n    Check if all dependent data fields have the same axes.\n\n    This includes axes order.\n\n    :return: ``True`` or ``False``.\n    \"\"\"\n    axes = []\n    for i, d in enumerate(self.dependents()):\n        if i == 0:\n            axes = self.axes(d)\n        else:\n            if self.axes(d) != axes:\n                return False\n    return True\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.clear_meta","title":"<code>clear_meta(data=None)</code>","text":"<p>Deletes all meta data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, None]</code> <p>If not <code>None</code>, delete all meta only from specified data field <code>data</code>. Else, deletes all top-level meta, as well as meta for all data fields.</p> <code>None</code> Source code in <code>labcore/data/datadict.py</code> <pre><code>def clear_meta(self, data: Union[str, None] = None) -&gt; None:\n    \"\"\"\n    Deletes all meta data.\n\n    :param data: If not ``None``, delete all meta only from specified data field ``data``.\n                 Else, deletes all top-level meta, as well as meta for all data fields.\n\n    \"\"\"\n    if data is None:\n        meta_list = [k for k, _ in self.meta_items()]\n        for m in meta_list:\n            self.delete_meta(m)\n\n        for d, _ in self.data_items():\n            data_meta_list = [k for k, _ in self.meta_items(d)]\n            for m in data_meta_list:\n                self.delete_meta(m, d)\n\n    else:\n        data_meta_list = [m for m, _ in self.meta_items(data)]\n        for m in data_meta_list:\n            self.delete_meta(m, data)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.copy","title":"<code>copy()</code>","text":"<p>Make a copy of the dataset.</p> <p>Returns:</p> Type Description <code>T</code> <p>A copy of the dataset.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def copy(self: T) -&gt; T:\n    \"\"\"\n    Make a copy of the dataset.\n\n    :return: A copy of the dataset.\n    \"\"\"\n    logger.debug(f'copying a dataset with size {self.nbytes()}')\n    ret = self.structure()\n    assert ret is not None\n\n    for k, v in self.data_items():\n        ret[k]['values'] = self.data_vals(k).copy()\n    return ret\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.data_items","title":"<code>data_items()</code>","text":"<p>Generator for data field items.</p> <p>Like dict.items(), but ignores meta data.</p> <p>Returns:</p> Type Description <code>Iterator[Tuple[str, Dict[str, Any]]]</code> <p>Generator yielding first the key of the data field and second its value.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def data_items(self) -&gt; Iterator[Tuple[str, Dict[str, Any]]]:\n    \"\"\"\n    Generator for data field items.\n\n    Like dict.items(), but ignores meta data.\n\n    :return: Generator yielding first the key of the data field and second its value.\n    \"\"\"\n    for k, v in self.items():\n        if not self._is_meta_key(k):\n            yield k, v\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.data_vals","title":"<code>data_vals(key)</code>","text":"<p>Return the data values of field <code>key</code>.</p> <p>Equivalent to <code>DataDict['key'].values</code>.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the data field.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Values of the data field.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def data_vals(self, key: str) -&gt; np.ndarray:\n    \"\"\"\n    Return the data values of field ``key``.\n\n    Equivalent to ``DataDict['key'].values``.\n\n    :param key: Name of the data field.\n    :return: Values of the data field.\n    \"\"\"\n    if self._is_meta_key(key):\n        raise ValueError(f\"{key} is a meta key.\")\n    return self[key].get('values', np.array([]))\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.delete_meta","title":"<code>delete_meta(key, data=None)</code>","text":"<p>Deletes specific meta data.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the meta field to remove.</p> required <code>data</code> <code>Union[str, None]</code> <p>If <code>None</code>, this affects global meta; otherwise remove from data field <code>data</code>.</p> <code>None</code> Source code in <code>labcore/data/datadict.py</code> <pre><code>def delete_meta(self, key: str, data: Union[str, None] = None) -&gt; None:\n    \"\"\"\n    Deletes specific meta data.\n\n    :param key: Name of the meta field to remove.\n    :param data: If ``None``, this affects global meta; otherwise remove\n                 from data field ``data``.\n\n    \"\"\"\n    key = self._meta_name_to_key(key)\n    if data is None:\n        del self[key]\n    else:\n        del self[data][key]\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.dependents","title":"<code>dependents()</code>","text":"<p>Get all dependents in the dataset.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of the names of dependents.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def dependents(self) -&gt; List[str]:\n    \"\"\"\n    Get all dependents in the dataset.\n\n    :return: A list of the names of dependents.\n    \"\"\"\n    ret = []\n    for n, v in self.data_items():\n        if len(v.get('axes', [])) != 0:\n            ret.append(n)\n    return ret\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.extract","title":"<code>extract(data, include_meta=True, copy=True, sanitize=True)</code>","text":"<p>Extract data from a dataset.</p> <p>Return a new datadict with all fields specified in <code>data</code> included. Will also take any axes fields along that have not been explicitly specified. Will return empty if <code>data</code> consists of only axes fields.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[str]</code> <p>Data field or list of data fields to be extracted.</p> required <code>include_meta</code> <code>bool</code> <p>If <code>True</code>, include the global meta data. data meta will always be included.</p> <code>True</code> <code>copy</code> <code>bool</code> <p>If <code>True</code>, data fields will be <code>deep copies &lt;https://docs.python.org/3/library/copy.html&gt;</code>__ of the original.</p> <code>True</code> <code>sanitize</code> <code>bool</code> <p>If <code>True</code>, will run DataDictBase.sanitize before returning.</p> <code>True</code> <p>Returns:</p> Type Description <code>T</code> <p>New DataDictBase containing only requested fields.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def extract(self: T, data: List[str], include_meta: bool = True,\n            copy: bool = True, sanitize: bool = True) -&gt; T:\n    \"\"\"\n    Extract data from a dataset.\n\n    Return a new datadict with all fields specified in ``data`` included.\n    Will also take any axes fields along that have not been explicitly\n    specified. Will return empty if ``data`` consists of only axes fields.\n\n    :param data: Data field or list of data fields to be extracted.\n    :param include_meta: If ``True``, include the global meta data.\n                         data meta will always be included.\n    :param copy: If ``True``, data fields will be `deep copies &lt;https://docs.python.org/3/library/copy.html&gt;`__\n                 of the original.\n    :param sanitize: If ``True``, will run DataDictBase.sanitize before\n                     returning.\n    :return: New DataDictBase containing only requested fields.\n    \"\"\"\n    if isinstance(data, str):\n        data = [data]\n    else:\n        data = data.copy()\n\n    # include all the axes used by the data.\n    for d in data:\n        for a in self.axes(d):\n            if a not in data:\n                data.append(a)\n\n    ret = self.__class__()\n    for d in data:\n        if copy:\n            ret[d] = cp.deepcopy(self[d])\n        else:\n            ret[d] = self[d]\n\n    if include_meta:\n        for k, v in self.meta_items():\n            if copy:\n                ret.add_meta(k, cp.deepcopy(v))\n            else:\n                ret.add_meta(k, v)\n\n    if sanitize:\n        ret = ret.sanitize()\n\n    ret.validate()\n    return ret\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.has_meta","title":"<code>has_meta(key)</code>","text":"<p>Check whether meta field exists in the dataset.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if it exists, <code>False</code> if it doesn't.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def has_meta(self, key: str) -&gt; bool:\n    \"\"\"Check whether meta field exists in the dataset.\n\n    :return: ``True`` if it exists, ``False`` if it doesn't.\n    \"\"\"\n    k = self._meta_name_to_key(key)\n    if k in self:\n        return True\n    else:\n        for key, field_dict in self.data_items():\n            if k in field_dict:\n                return True\n        return False\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.label","title":"<code>label(name)</code>","text":"<p>Get the label for a data field. If no label is present returns the name of the data field as the label. If a unit is present, it will be appended at the end in brackets: \"label (unit)\".</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the data field.</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Labelled name.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def label(self, name: str) -&gt; Optional[str]:\n    \"\"\"\n    Get the label for a data field. If no label is present returns the\n    name of the data field as the label. If a unit is present, it will\n    be appended at the end in brackets: \"label (unit)\".\n\n    :param name: Name of the data field.\n    :return: Labelled name.\n    \"\"\"\n    if self.validate():\n        if name not in self:\n            raise ValueError(\"No field '{}' present.\".format(name))\n\n        if self[name]['label'] != '':\n            n = self[name]['label']\n        else:\n            n = name\n\n        if self[name]['unit'] != '':\n            n += ' ({})'.format(self[name]['unit'])\n\n        return n\n    return None\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.mask_invalid","title":"<code>mask_invalid()</code>","text":"<p>Mask all invalid data in all values.</p> <p>Returns:</p> Type Description <code>T</code> <p>Copy of the dataset with invalid entries (nan/None) masked.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def mask_invalid(self: T) -&gt; T:\n    \"\"\"\n    Mask all invalid data in all values.\n    :return: Copy of the dataset with invalid entries (nan/None) masked.\n    \"\"\"\n    for d, _ in self.data_items():\n        arr = self.data_vals(d)\n        vals = np.ma.masked_where(num.is_invalid(arr), arr, copy=True)\n        try:\n            vals.fill_value = np.nan\n        except TypeError:\n            vals.fill_value = -9999\n        self[d]['values'] = vals\n\n    return self\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.meta_items","title":"<code>meta_items(data=None, clean_keys=True)</code>","text":"<p>Generator for meta items.</p> <p>Like dict.items(), but yields <code>only</code> meta entries. The keys returned do not contain the underscores used internally.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, None]</code> <p>If <code>None</code> iterate over global meta data. If it's the name of a data field, iterate over the meta information of that field.</p> <code>None</code> <code>clean_keys</code> <code>bool</code> <p>If <code>True</code>, remove the underscore pre/suffix.</p> <code>True</code> <p>Returns:</p> Type Description <code>Iterator[Tuple[str, Dict[str, Any]]]</code> <p>Generator yielding first the key of the data field and second its value.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def meta_items(self, data: Union[str, None] = None,\n               clean_keys: bool = True) -&gt; Iterator[Tuple[str, Dict[str, Any]]]:\n    \"\"\"\n    Generator for meta items.\n\n    Like dict.items(), but yields `only` meta entries.\n    The keys returned do not contain the underscores used internally.\n\n    :param data: If ``None`` iterate over global meta data.\n                 If it's the name of a data field, iterate over the meta\n                 information of that field.\n    :param clean_keys: If `True`, remove the underscore pre/suffix.\n    :return: Generator yielding first the key of the data field and second its value.\n\n    \"\"\"\n    if data is None:\n        for k, v in self.items():\n            if self._is_meta_key(k):\n                if clean_keys:\n                    n = self._meta_key_to_name(k)\n                else:\n                    n = k\n                yield n, v\n\n    else:\n        for k, v in self[data].items():\n            if self._is_meta_key(k):\n                if clean_keys:\n                    n = self._meta_key_to_name(k)\n                else:\n                    n = k\n                yield n, v\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.meta_val","title":"<code>meta_val(key, data=None)</code>","text":"<p>Return the value of meta field <code>key</code> (given without underscore).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the meta field.</p> required <code>data</code> <code>Union[str, None]</code> <p><code>None</code> for global meta; name of data field for data meta.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The value of the meta information.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def meta_val(self, key: str, data: Union[str, None] = None) -&gt; Any:\n    \"\"\"\n    Return the value of meta field ``key`` (given without underscore).\n\n    :param key: Name of the meta field.\n    :param data: ``None`` for global meta; name of data field for data meta.\n    :return: The value of the meta information.\n    \"\"\"\n    k = self._meta_name_to_key(key)\n    if data is None:\n        return self[k]\n    else:\n        return self[data][k]\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.nbytes","title":"<code>nbytes(name=None)</code>","text":"<p>Get the size of data.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Name of the data field. if none, return size of  entire datadict.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[int]</code> <p>size in bytes.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def nbytes(self, name: Optional[str]=None) -&gt; Optional[int]:\n    \"\"\"Get the size of data.\n\n    :param name: Name of the data field. if none, return size of \n        entire datadict.\n    :return: size in bytes.\n    \"\"\"\n    if self.validate():\n        if name is None:\n            return sum([v['values'].size * v['values'].itemsize \n                        for _, v in self.data_items()])\n        else:\n            return self.data_vals(name).size * self.data_vals(name).itemsize\n\n    return None\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.remove_unused_axes","title":"<code>remove_unused_axes()</code>","text":"<p>Removes axes not associated with dependents.</p> <p>Returns:</p> Type Description <code>T</code> <p>Cleaned dataset.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def remove_unused_axes(self: T) -&gt; T:\n    \"\"\"\n    Removes axes not associated with dependents.\n\n    :return: Cleaned dataset.\n    \"\"\"\n    dependents = self.dependents()\n    unused = []\n\n    for n, v in self.data_items():\n        used = False\n        if n not in dependents:\n            for m in dependents:\n                if n in self[m]['axes']:\n                    used = True\n        else:\n            used = True\n        if not used:\n            unused.append(n)\n\n    for u in unused:\n        del self[u]\n\n    return self\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.reorder_axes","title":"<code>reorder_axes(data_names=None, **pos)</code>","text":"<p>Reorder data axes.</p> <p>Parameters:</p> Name Type Description Default <code>data_names</code> <code>Union[str, Sequence[str], None]</code> <p>Data name(s) for which to reorder the axes. If None, apply to all dependents.</p> <code>None</code> <code>pos</code> <code>int</code> <p>New axes position in the form <code>axis_name = new_position</code>. Non-specified axes positions are adjusted automatically.</p> <code>{}</code> <p>Returns:</p> Type Description <code>T</code> <p>Dataset with re-ordered axes (not a copy)</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def reorder_axes(self: T, data_names: Union[str, Sequence[str], None] = None,\n                 **pos: int) -&gt; T:\n    \"\"\"\n    Reorder data axes.\n\n    :param data_names: Data name(s) for which to reorder the axes.\n                       If None, apply to all dependents.\n    :param pos: New axes position in the form ``axis_name = new_position``.\n                Non-specified axes positions are adjusted automatically.\n\n    :return: Dataset with re-ordered axes (not a copy)\n    \"\"\"\n    if data_names is None:\n        data_names = self.dependents()\n    if isinstance(data_names, str):\n        data_names = [data_names]\n\n    for n in data_names:\n        neworder, newaxes = self.reorder_axes_indices(n, **pos)\n        self[n]['axes'] = newaxes\n\n    self.validate()\n    return self\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.reorder_axes_indices","title":"<code>reorder_axes_indices(name, **pos)</code>","text":"<p>Get the indices that can reorder axes in a given way.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the data field of which we want to reorder axes.</p> required <code>pos</code> <code>int</code> <p>New axes position in the form <code>axis_name = new_position</code>. Non-specified axes positions are adjusted automatically.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Tuple[int, ...], List[str]]</code> <p>The tuple of new indices, and the list of axes names in the new order.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def reorder_axes_indices(self, name: str,\n                         **pos: int) -&gt; Tuple[Tuple[int, ...], List[str]]:\n    \"\"\"\n    Get the indices that can reorder axes in a given way.\n\n    :param name: Name of the data field of which we want to reorder axes.\n    :param pos: New axes position in the form ``axis_name = new_position``.\n                Non-specified axes positions are adjusted automatically.\n    :return: The tuple of new indices, and the list of axes names in the\n             new order.\n\n    \"\"\"\n    axlist = self.axes(name)\n    order = misc.reorder_indices_from_new_positions(axlist, **pos)\n    return order, [axlist[i] for i in order]\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.same_structure","title":"<code>same_structure(*data, check_shape=False)</code>  <code>staticmethod</code>","text":"<p>Check if all supplied DataDicts share the same data structure (i.e., dependents and axes).</p> <p>Ignores meta data and values. Checks also for matching shapes if <code>check_shape</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>T</code> <p>The data sets to compare.</p> <code>()</code> <code>check_shape</code> <code>bool</code> <p>Whether to include shape check in the comparison.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the structure matches for all, else <code>False</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>@staticmethod\ndef same_structure(*data: T,\n                   check_shape: bool = False) -&gt; bool:\n    \"\"\"\n    Check if all supplied DataDicts share the same data structure\n    (i.e., dependents and axes).\n\n    Ignores meta data and values. Checks also for matching shapes if\n    `check_shape` is `True`.\n\n    :param data: The data sets to compare.\n    :param check_shape: Whether to include shape check in the comparison.\n    :return: ``True`` if the structure matches for all, else ``False``.\n    \"\"\"\n    if len(data) &lt; 2:\n        return True\n\n    def empty_structure(d: T) -&gt; T:\n        s = misc.unwrap_optional(d.structure(include_meta=False, add_shape=check_shape))\n        for k, v in s.data_items():\n            if 'values' in v:\n                del s[k]['values']\n        return s\n\n    s0 = empty_structure(data[0])\n    for d in data[1:]:\n        if d is None:\n            return False\n        if s0 != empty_structure(d):\n            return False\n\n    return True\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.sanitize","title":"<code>sanitize()</code>","text":"<p>Clean-up tasks:     * Removes unused axes.</p> <p>Returns:</p> Type Description <code>T</code> <p>Sanitized dataset.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def sanitize(self: T) -&gt; T:\n    \"\"\"\n    Clean-up tasks:\n        * Removes unused axes.\n\n    :return: Sanitized dataset.\n    \"\"\"\n    return self.remove_unused_axes()\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.shapes","title":"<code>shapes()</code>","text":"<p>Get the shapes of all data fields.</p> <p>Returns:</p> Type Description <code>Dict[str, Tuple[int, ...]]</code> <p>A dictionary of the form <code>{key : shape}</code>, where shape is the np.shape-tuple of the data with name <code>key</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def shapes(self) -&gt; Dict[str, Tuple[int, ...]]:\n    \"\"\"\n    Get the shapes of all data fields.\n\n    :return: A dictionary of the form ``{key : shape}``, where shape is the\n             np.shape-tuple of the data with name ``key``.\n\n    \"\"\"\n    shapes = {}\n    for k, v in self.data_items():\n        shapes[k] = np.array(self.data_vals(k)).shape\n\n    return shapes\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.structure","title":"<code>structure(add_shape=False, include_meta=True, same_type=False, remove_data=None)</code>","text":"<p>Get the structure of the DataDict.</p> <p>Return the datadict without values (<code>value</code> omitted in the dict).</p> <p>Parameters:</p> Name Type Description Default <code>add_shape</code> <code>bool</code> <p>Deprecated -- ignored.</p> <code>False</code> <code>include_meta</code> <code>bool</code> <p>If <code>True</code>, include the meta information in the returned dict.</p> <code>True</code> <code>same_type</code> <code>bool</code> <p>If <code>True</code>, return type will be the one of the object this is called on. Else, DataDictBase.</p> <code>False</code> <code>remove_data</code> <code>Optional[List[str]]</code> <p>any data fields listed will be removed from the result, also when listed in any axes.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[T]</code> <p>The DataDict containing the structure only. The exact type is the same as the type of <code>self</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def structure(self: T, add_shape: bool = False,\n              include_meta: bool = True,\n              same_type: bool = False,\n              remove_data: Optional[List[str]] = None) -&gt; Optional[T]:\n    \"\"\"\n    Get the structure of the DataDict.\n\n    Return the datadict without values (`value` omitted in the dict).\n\n    :param add_shape: Deprecated -- ignored.\n    :param include_meta: If `True`, include the meta information in\n                         the returned dict.\n    :param same_type: If `True`, return type will be the one of the\n                      object this is called on. Else, DataDictBase.\n    :param remove_data: any data fields listed will be removed from\n                        the result, also when listed in any axes.\n\n    :return: The DataDict containing the structure only. The exact type\n                 is the same as the type of ``self``.\n\n    \"\"\"\n    if add_shape:\n        warnings.warn(\"'add_shape' is deprecated and will be ignored\",\n                      DeprecationWarning)\n    add_shape = False\n\n    if remove_data is None:\n        remove_data = []\n\n    if self.validate():\n        s = self.__class__()\n        for n, v in self.data_items():\n            if n not in remove_data:\n                v2 = v.copy()\n                v2['values'] = []\n                s[n] = cp.deepcopy(v2)\n                if 'axes' in s[n]:\n                    for r in remove_data:\n                        if r in s[n]['axes']:\n                            i = s[n]['axes'].index(r)\n                            s[n]['axes'].pop(i)\n\n        if include_meta:\n            for n, v in self.meta_items():\n                s.add_meta(n, v)\n        else:\n            s.clear_meta()\n\n        if same_type:\n            s = self.__class__(**s)\n\n        return s\n    return None\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.to_records","title":"<code>to_records(**data)</code>  <code>staticmethod</code>","text":"<p>Convert data to records that can be added to the <code>DataDict</code>. All data is converted to np.array, and reshaped such that the first dimension of all resulting arrays have the same length (chosen to be the smallest possible number that does not alter any shapes beyond adding a length-1 dimension as first dimension, if necessary).</p> <p>If a data field is given as <code>None</code>, it will be converted to <code>numpy.array([numpy.nan])</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>keyword arguments for each data field followed by data.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, ndarray]</code> <p>Dictionary with properly shaped data.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>@staticmethod\ndef to_records(**data: Any) -&gt; Dict[str, np.ndarray]:\n    \"\"\"Convert data to records that can be added to the ``DataDict``.\n    All data is converted to np.array, and reshaped such that the first dimension of all resulting\n    arrays have the same length (chosen to be the smallest possible number\n    that does not alter any shapes beyond adding a length-1 dimension as\n    first dimension, if necessary).\n\n    If a data field is given as ``None``, it will be converted to ``numpy.array([numpy.nan])``.\n\n    :param data: keyword arguments for each data field followed by data.\n    :returns: Dictionary with properly shaped data.\n    \"\"\"\n    records: Dict[str, np.ndarray] = {}\n\n    seqtypes = (np.ndarray, tuple, list)\n    nantypes = (type(None), )\n\n    for k, v in data.items():\n        if isinstance(v, seqtypes):\n            records[k] = np.array(v)\n        elif isinstance(v, nantypes):\n            records[k] = np.array([np.nan])\n        else:\n            records[k] = np.array([v])\n\n    possible_nrecords = {}\n    for k, v in records.items():\n        possible_nrecords[k] = [1, v.shape[0]]\n\n    commons = []\n    for k, v in possible_nrecords.items():\n        for n in v:\n            if n in commons:\n                continue\n            is_common = True\n            for kk, vv in possible_nrecords.items():\n                if n not in vv:\n                    is_common = False\n            if is_common:\n                commons.append(n)\n\n    nrecs = max(commons)\n\n    for k, v in records.items():\n        shp = v.shape\n        if nrecs == 1 and shp[0] &gt; 1:\n            newshp = tuple([1] + list(shp))\n            records[k] = v.reshape(newshp)\n    return records\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.DataDictBase.validate","title":"<code>validate()</code>","text":"<p>Check the validity of the dataset.</p> <p>Checks performed:     * All axes specified with dependents must exist as data fields.</p> <p>Other tasks performed:     * <code>unit</code> keys are created if omitted.     * <code>label</code> keys are created if omitted.     * <code>shape</code> meta information is updated with the correct values       (only if present already).</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if valid, <code>False</code> if invalid.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def validate(self) -&gt; bool:\n    \"\"\"\n    Check the validity of the dataset.\n\n    Checks performed:\n        * All axes specified with dependents must exist as data fields.\n\n    Other tasks performed:\n        * ``unit`` keys are created if omitted.\n        * ``label`` keys are created if omitted.\n        * ``shape`` meta information is updated with the correct values\n          (only if present already).\n\n    :return: ``True`` if valid, ``False`` if invalid.\n    :raises: ``ValueError`` if invalid.\n    \"\"\"\n    self._update_data_access()\n\n    msg = '\\n'\n    for n, v in self.data_items():\n\n        if 'axes' in v:\n            for na in v['axes']:\n                if na not in self:\n                    msg += \" * '{}' has axis '{}', but no field \" \\\n                           \"with name '{}' registered.\\n\".format(\n                        n, na, na)\n                elif na not in self.axes():\n                    msg += \" * '{}' has axis '{}', but no independent \" \\\n                           \"with name '{}' registered.\\n\".format(\n                        n, na, na)\n        else:\n            v['axes'] = []\n\n        if 'unit' not in v:\n            v['unit'] = ''\n\n        if 'label' not in v:\n            v['label'] = ''\n\n        vals = v.get('values', [])\n        if type(vals) not in [np.ndarray, np.ma.core.MaskedArray]:\n            vals = np.array(vals)\n        v['values'] = vals\n\n    if msg != '\\n':\n        raise ValueError(msg)\n\n    return True\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.MeshgridDataDict","title":"<code>MeshgridDataDict</code>","text":"<p>             Bases: <code>DataDictBase</code></p> <p>Implementation of DataDictBase meant to be used for when the axes form a grid on which the dependent values reside.</p> <p>It enforces that all dependents have the same axes and all shapes need to be identical.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>class MeshgridDataDict(DataDictBase):\n    \"\"\"\n    Implementation of DataDictBase meant to be used for when the axes form\n    a grid on which the dependent values reside.\n\n    It enforces that all dependents have the same axes and all shapes need to be identical.\n    \"\"\"\n\n    def shape(self) -&gt; Union[None, Tuple[int, ...]]:\n        \"\"\"\n        Return the shape of the meshgrid.\n\n        :returns: The shape as tuple. ``None`` if no data in the set.\n        \"\"\"\n        for d, _ in self.data_items():\n            return np.array(self.data_vals(d)).shape\n        return None\n\n    def validate(self) -&gt; bool:\n        \"\"\"\n        Validation of the dataset.\n\n        Performs the following checks:\n        * All dependents must have the same axes.\n        * All shapes need to be identical.\n\n        :return: ``True`` if valid.\n        :raises: ``ValueError`` if invalid.\n        \"\"\"\n        if not super().validate():\n            return False\n\n        msg = '\\n'\n\n        axes = None\n        axessrc = ''\n        for d in self.dependents():\n            if axes is None:\n                axes = self.axes(d)\n            else:\n                if axes != self.axes(d):\n                    msg += f\" * All dependents must have the same axes, but \"\n                    msg += f\"{d} has {self.axes(d)} and {axessrc} has {axes}\\n\"\n\n        shp = None\n        shpsrc = ''\n\n        data_items = dict(self.data_items())\n\n        for n, v in data_items.items():\n            if type(v['values']) not in [np.ndarray, np.ma.core.MaskedArray]:\n                self[n]['values'] = np.array(v['values'])\n\n            if shp is None:\n                shp = v['values'].shape\n                shpsrc = n\n            else:\n                if v['values'].shape != shp:\n                    msg += f\" * shapes need to match, but '{n}' has\"\n                    msg += f\" {v['values'].shape}, \"\n                    msg += f\"and '{shpsrc}' has {shp}.\\n\"\n\n            if msg != '\\n':\n                raise ValueError(msg)\n\n            if 'axes' in v:\n                for axis_num, na in enumerate(v['axes']):\n                    # check that the data of the axes matches its use\n                    # if data present\n                    axis_data = data_items[na]['values']\n\n                    # for the data to be a valid meshgrid, we need to have an increase/decrease along each\n                    # axis that contains data.\n                    if axis_data.size &gt; 0:\n                        # if axis length is 1, then we cannot infer anything about grids yet\n\n                        try:\n                            if axis_data.shape[axis_num] &gt; 1:\n                                steps = np.unique(np.sign(np.diff(axis_data, axis=axis_num)))\n\n                                # for incomplete data, there maybe nan steps -- we need to remove those, \n                                # doesn't mean anything is wrong.\n                                steps = steps[~np.isnan(steps)]\n\n                                if 0 in steps:\n                                    msg += (f\"Malformed data: {na} is expected to be {axis_num}th \"\n                                            \"axis but has no variation along that axis.\\n\")\n                                if steps.size &gt; 1:\n                                    msg += (f\"Malformed data: axis {na} is not monotonous.\\n\")\n\n                        # can happen if we have bad shapes. but that should already have been caught.\n                        except IndexError:\n                            pass\n\n            if '__shape__' in v:\n                v['__shape__'] = shp\n\n            if msg != '\\n':\n                raise ValueError(msg)\n\n        return True\n\n    def reorder_axes(self, data_names: Union[str, Sequence[str], None] = None,\n                     **pos: int) -&gt; 'MeshgridDataDict':\n        \"\"\"\n        Reorder the axes for all data.\n\n        This includes transposing the data, since we're on a grid.\n\n        :param data_names: Which dependents to include. if None are given,\n                           all dependents are included.\n        :param pos: New axes position in the form ``axis_name = new_position``.\n                    non-specified axes positions are adjusted automatically.\n\n        :return: Dataset with re-ordered axes.\n        \"\"\"\n        if data_names is None:\n            data_names = self.dependents()\n        if isinstance(data_names, str):\n            data_names = [data_names]\n\n        transposed = []\n        orders = {}\n        orig_axes = {}\n        for n in data_names:\n            orders[n] = self.reorder_axes_indices(n, **pos)\n            orig_axes[n] = self.axes(n).copy()\n\n        for n in data_names:\n            neworder, newaxes = orders[n]\n            self[n]['axes'] = newaxes\n            self[n]['values'] = self[n]['values'].transpose(neworder)\n            for ax in orig_axes[n]:\n                if ax not in transposed:\n                    self[ax]['values'] = self[ax]['values'].transpose(neworder)\n                    transposed.append(ax)\n\n        self.validate()\n        return self\n\n    def mean(self, axis: str) -&gt; 'MeshgridDataDict':\n        \"\"\"Take the mean over the given axis.\n\n        :param axis: which axis to take the average over.\n        :return: data, averaged over ``axis``.\n        \"\"\"\n        return _mesh_mean(self, axis)\n\n    def slice(self, **kwargs: Dict[str, Union[slice, int]]) -&gt; 'MeshgridDataDict':\n        \"\"\"Return a N-d slice of the data.\n\n        :param kwargs: slicing information in the format ``axis: spec``, where\n            ``spec`` can be a ``slice`` object, or an integer (usual slicing \n            notation).\n        :return: sliced data (as a copy)\n        \"\"\"\n        return _mesh_slice(self, **kwargs)\n\n    def squeeze(self) -&gt; None:\n        \"\"\"Remove size-1 dimensions.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.MeshgridDataDict.mean","title":"<code>mean(axis)</code>","text":"<p>Take the mean over the given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>str</code> <p>which axis to take the average over.</p> required <p>Returns:</p> Type Description <code>MeshgridDataDict</code> <p>data, averaged over <code>axis</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def mean(self, axis: str) -&gt; 'MeshgridDataDict':\n    \"\"\"Take the mean over the given axis.\n\n    :param axis: which axis to take the average over.\n    :return: data, averaged over ``axis``.\n    \"\"\"\n    return _mesh_mean(self, axis)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.MeshgridDataDict.reorder_axes","title":"<code>reorder_axes(data_names=None, **pos)</code>","text":"<p>Reorder the axes for all data.</p> <p>This includes transposing the data, since we're on a grid.</p> <p>Parameters:</p> Name Type Description Default <code>data_names</code> <code>Union[str, Sequence[str], None]</code> <p>Which dependents to include. if None are given, all dependents are included.</p> <code>None</code> <code>pos</code> <code>int</code> <p>New axes position in the form <code>axis_name = new_position</code>. non-specified axes positions are adjusted automatically.</p> <code>{}</code> <p>Returns:</p> Type Description <code>MeshgridDataDict</code> <p>Dataset with re-ordered axes.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def reorder_axes(self, data_names: Union[str, Sequence[str], None] = None,\n                 **pos: int) -&gt; 'MeshgridDataDict':\n    \"\"\"\n    Reorder the axes for all data.\n\n    This includes transposing the data, since we're on a grid.\n\n    :param data_names: Which dependents to include. if None are given,\n                       all dependents are included.\n    :param pos: New axes position in the form ``axis_name = new_position``.\n                non-specified axes positions are adjusted automatically.\n\n    :return: Dataset with re-ordered axes.\n    \"\"\"\n    if data_names is None:\n        data_names = self.dependents()\n    if isinstance(data_names, str):\n        data_names = [data_names]\n\n    transposed = []\n    orders = {}\n    orig_axes = {}\n    for n in data_names:\n        orders[n] = self.reorder_axes_indices(n, **pos)\n        orig_axes[n] = self.axes(n).copy()\n\n    for n in data_names:\n        neworder, newaxes = orders[n]\n        self[n]['axes'] = newaxes\n        self[n]['values'] = self[n]['values'].transpose(neworder)\n        for ax in orig_axes[n]:\n            if ax not in transposed:\n                self[ax]['values'] = self[ax]['values'].transpose(neworder)\n                transposed.append(ax)\n\n    self.validate()\n    return self\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.MeshgridDataDict.shape","title":"<code>shape()</code>","text":"<p>Return the shape of the meshgrid.</p> <p>Returns:</p> Type Description <code>Union[None, Tuple[int, ...]]</code> <p>The shape as tuple. <code>None</code> if no data in the set.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def shape(self) -&gt; Union[None, Tuple[int, ...]]:\n    \"\"\"\n    Return the shape of the meshgrid.\n\n    :returns: The shape as tuple. ``None`` if no data in the set.\n    \"\"\"\n    for d, _ in self.data_items():\n        return np.array(self.data_vals(d)).shape\n    return None\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.MeshgridDataDict.slice","title":"<code>slice(**kwargs)</code>","text":"<p>Return a N-d slice of the data.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>Dict[str, Union[slice, int]]</code> <p>slicing information in the format <code>axis: spec</code>, where <code>spec</code> can be a <code>slice</code> object, or an integer (usual slicing  notation).</p> <code>{}</code> <p>Returns:</p> Type Description <code>MeshgridDataDict</code> <p>sliced data (as a copy)</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def slice(self, **kwargs: Dict[str, Union[slice, int]]) -&gt; 'MeshgridDataDict':\n    \"\"\"Return a N-d slice of the data.\n\n    :param kwargs: slicing information in the format ``axis: spec``, where\n        ``spec`` can be a ``slice`` object, or an integer (usual slicing \n        notation).\n    :return: sliced data (as a copy)\n    \"\"\"\n    return _mesh_slice(self, **kwargs)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.MeshgridDataDict.squeeze","title":"<code>squeeze()</code>","text":"<p>Remove size-1 dimensions.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def squeeze(self) -&gt; None:\n    \"\"\"Remove size-1 dimensions.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.MeshgridDataDict.validate","title":"<code>validate()</code>","text":"<p>Validation of the dataset.</p> <p>Performs the following checks: * All dependents must have the same axes. * All shapes need to be identical.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if valid.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def validate(self) -&gt; bool:\n    \"\"\"\n    Validation of the dataset.\n\n    Performs the following checks:\n    * All dependents must have the same axes.\n    * All shapes need to be identical.\n\n    :return: ``True`` if valid.\n    :raises: ``ValueError`` if invalid.\n    \"\"\"\n    if not super().validate():\n        return False\n\n    msg = '\\n'\n\n    axes = None\n    axessrc = ''\n    for d in self.dependents():\n        if axes is None:\n            axes = self.axes(d)\n        else:\n            if axes != self.axes(d):\n                msg += f\" * All dependents must have the same axes, but \"\n                msg += f\"{d} has {self.axes(d)} and {axessrc} has {axes}\\n\"\n\n    shp = None\n    shpsrc = ''\n\n    data_items = dict(self.data_items())\n\n    for n, v in data_items.items():\n        if type(v['values']) not in [np.ndarray, np.ma.core.MaskedArray]:\n            self[n]['values'] = np.array(v['values'])\n\n        if shp is None:\n            shp = v['values'].shape\n            shpsrc = n\n        else:\n            if v['values'].shape != shp:\n                msg += f\" * shapes need to match, but '{n}' has\"\n                msg += f\" {v['values'].shape}, \"\n                msg += f\"and '{shpsrc}' has {shp}.\\n\"\n\n        if msg != '\\n':\n            raise ValueError(msg)\n\n        if 'axes' in v:\n            for axis_num, na in enumerate(v['axes']):\n                # check that the data of the axes matches its use\n                # if data present\n                axis_data = data_items[na]['values']\n\n                # for the data to be a valid meshgrid, we need to have an increase/decrease along each\n                # axis that contains data.\n                if axis_data.size &gt; 0:\n                    # if axis length is 1, then we cannot infer anything about grids yet\n\n                    try:\n                        if axis_data.shape[axis_num] &gt; 1:\n                            steps = np.unique(np.sign(np.diff(axis_data, axis=axis_num)))\n\n                            # for incomplete data, there maybe nan steps -- we need to remove those, \n                            # doesn't mean anything is wrong.\n                            steps = steps[~np.isnan(steps)]\n\n                            if 0 in steps:\n                                msg += (f\"Malformed data: {na} is expected to be {axis_num}th \"\n                                        \"axis but has no variation along that axis.\\n\")\n                            if steps.size &gt; 1:\n                                msg += (f\"Malformed data: axis {na} is not monotonous.\\n\")\n\n                    # can happen if we have bad shapes. but that should already have been caught.\n                    except IndexError:\n                        pass\n\n        if '__shape__' in v:\n            v['__shape__'] = shp\n\n        if msg != '\\n':\n            raise ValueError(msg)\n\n    return True\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.combine_datadicts","title":"<code>combine_datadicts(*dicts)</code>","text":"<p>Try to make one datadict out of multiple.</p> <p>Basic rules:</p> <ul> <li>We try to maintain the input type.</li> <li>Return type is 'downgraded' to DataDictBase if the contents are not   compatible (i.e., different numbers of records in the inputs).</li> </ul> <p>Returns:</p> Type Description <code>Union[DataDictBase, DataDict]</code> <p>Combined data.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def combine_datadicts(*dicts: DataDict) -&gt; Union[DataDictBase, DataDict]:\n    \"\"\"\n    Try to make one datadict out of multiple.\n\n    Basic rules:\n\n    - We try to maintain the input type.\n    - Return type is 'downgraded' to DataDictBase if the contents are not\n      compatible (i.e., different numbers of records in the inputs).\n\n    :returns: Combined data.\n    \"\"\"\n\n    # TODO: deal correctly with MeshGridData when combined with other types\n    # TODO: should we strictly copy all values?\n    # TODO: we should try to consolidate axes as much as possible. Currently\n    #   axes in the return can be separated even if they match (caused\n    #   by earlier mismatches)\n\n    ret = None\n    rettype = None\n\n    for d in dicts:\n        if ret is None:\n            ret = d.copy()\n            rettype = type(d)\n\n        else:\n\n            # if we don't have a well defined number of records anymore,\n            # need to revert the type to DataDictBase\n            if hasattr(d, 'nrecords') and hasattr(ret, 'nrecords'):\n                if d.nrecords() != ret.nrecords():\n                    rettype = DataDictBase\n            else:\n                rettype = DataDictBase\n            ret = rettype(**ret)\n\n            # First, parse the axes in the to-be-added ddict.\n            # if dimensions with same names are present already in the current\n            # return ddict and are not compatible with what's to be added,\n            # rename the incoming dimension.\n            ax_map = {}\n            for d_ax in d.axes():\n                if d_ax in ret.axes():\n                    if num.arrays_equal(d.data_vals(d_ax), ret.data_vals(d_ax)):\n                        ax_map[d_ax] = d_ax\n                    else:\n                        newax = _find_replacement_name(ret, d_ax)\n                        ax_map[d_ax] = newax\n                        ret[newax] = d[d_ax]\n                elif d_ax in ret.dependents():\n                    newax = _find_replacement_name(ret, d_ax)\n                    ax_map[d_ax] = newax\n                    ret[newax] = d[d_ax]\n                else:\n                    ax_map[d_ax] = d_ax\n                    ret[d_ax] = d[d_ax]\n\n            for d_dep in d.dependents():\n                if d_dep in ret:\n                    newdep = _find_replacement_name(ret, d_dep)\n                else:\n                    newdep = d_dep\n\n                dep_axes = [ax_map[ax] for ax in d[d_dep]['axes']]\n                ret[newdep] = d[d_dep]\n                ret[newdep]['axes'] = dep_axes\n\n    if ret is None:\n        ret = DataDict()\n    else:\n        ret.validate()\n\n    return ret\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.datadict_to_meshgrid","title":"<code>datadict_to_meshgrid(data, target_shape=None, inner_axis_order=None, use_existing_shape=False, copy=True)</code>","text":"<p>Try to make a meshgrid from a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataDict</code> <p>Input DataDict.</p> required <code>target_shape</code> <code>Union[Tuple[int, ...], None]</code> <p>Target shape. If <code>None</code> we use <code>guess_shape_from_datadict</code> to infer.</p> <code>None</code> <code>inner_axis_order</code> <code>Union[None, Sequence[str]]</code> <p>If axes of the datadict are not specified in the 'C' order (1st the slowest, last the fastest axis) then the 'true' inner order can be specified as a list of axes names, which has to match the specified axes in all but order. The data is then transposed to conform to the specified order.  .. note:: If this is given, then <code>target_shape</code> needs to be given in in the order of this inner_axis_order. The output data will keep the axis ordering specified in the <code>axes</code> property.</p> <code>None</code> <code>use_existing_shape</code> <code>bool</code> <p>if <code>True</code>, simply use the shape that the data already has. For numpy-array data, this might already be present. If <code>False</code>, flatten and reshape.</p> <code>False</code> <code>copy</code> <code>bool</code> <p>if <code>True</code>, then we make a copy of the data arrays. if <code>False</code>, data array is modified in-place.</p> <code>True</code> <p>Returns:</p> Type Description <code>MeshgridDataDict</code> <p>The generated <code>MeshgridDataDict</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def datadict_to_meshgrid(data: DataDict,\n                         target_shape: Union[Tuple[int, ...], None] = None,\n                         inner_axis_order: Union[None, Sequence[str]] = None,\n                         use_existing_shape: bool = False,\n                         copy: bool = True) \\\n        -&gt; MeshgridDataDict:\n    \"\"\"\n    Try to make a meshgrid from a dataset.\n\n    :param data: Input DataDict.\n    :param target_shape: Target shape. If ``None`` we use\n        ``guess_shape_from_datadict`` to infer.\n    :param inner_axis_order: If axes of the datadict are not specified in the\n        'C' order (1st the slowest, last the fastest axis) then the\n        'true' inner order can be specified as a list of axes names, which has\n        to match the specified axes in all but order. The data is then\n        transposed to conform to the specified order.\n\n        .. note::\n            If this is given, then ``target_shape`` needs to be given in\n            in the order of this inner_axis_order. The output data will keep the\n            axis ordering specified in the `axes` property.\n\n    :param use_existing_shape: if ``True``, simply use the shape that the data\n        already has. For numpy-array data, this might already be present.\n        If ``False``, flatten and reshape.\n    :param copy: if ``True``, then we make a copy of the data arrays.\n        if ``False``, data array is modified in-place.\n\n    :raises: GriddingError (subclass of ValueError) if the data cannot be gridded.\n    :returns: The generated ``MeshgridDataDict``.\n    \"\"\"\n\n    # if the data is empty, return empty MeshgridData\n    if len([k for k, _ in data.data_items()]) == 0:\n        return MeshgridDataDict()\n\n    if not data.axes_are_compatible():\n        raise GriddingError('Non-compatible axes, cannot grid that.')\n\n    if not use_existing_shape and data.is_expandable():\n        data = data.expand()\n    elif use_existing_shape:\n        target_shape = list(data.shapes().values())[0]\n\n    # guess what the shape likely is.\n    if target_shape is None:\n        shp_specs = guess_shape_from_datadict(data)\n        shps = set(order_shape[1] if order_shape is not None\n                   else None for order_shape in shp_specs.values())\n        if len(shps) &gt; 1:\n            raise GriddingError('Cannot determine unique shape for all data.')\n        ret = list(shp_specs.values())[0]\n        if ret is None:\n            raise GriddingError('Shape could not be inferred.')\n        # the guess-function returns both axis order as well as shape.\n        inner_axis_order, target_shape = ret\n\n    # construct new data\n    newdata = MeshgridDataDict(**misc.unwrap_optional(data.structure(add_shape=False)))\n    axlist = data.axes(data.dependents()[0])\n\n    for k, v in data.data_items():\n        vals = num.array1d_to_meshgrid(v['values'], target_shape, copy=copy)\n\n        # if an inner axis order is given, we transpose to transform from that\n        # to the specified order.\n        if inner_axis_order is not None:\n            transpose_idxs = misc.reorder_indices(\n                inner_axis_order, axlist)\n            vals = vals.transpose(transpose_idxs)\n\n        newdata[k]['values'] = vals\n\n    newdata = newdata.sanitize()\n    newdata.validate()\n    return newdata\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.datasets_are_equal","title":"<code>datasets_are_equal(a, b, ignore_meta=False)</code>","text":"<p>Check whether two datasets are equal.</p> <p>Compares type, structure, and content of all fields.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>DataDictBase</code> <p>First dataset.</p> required <code>b</code> <code>DataDictBase</code> <p>Second dataset.</p> required <code>ignore_meta</code> <code>bool</code> <p>If <code>True</code>, do not verify if metadata matches.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> or <code>False</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def datasets_are_equal(a: DataDictBase, b: DataDictBase,\n                       ignore_meta: bool = False) -&gt; bool:\n    \"\"\"Check whether two datasets are equal.\n\n    Compares type, structure, and content of all fields.\n\n    :param a: First dataset.\n    :param b: Second dataset.\n    :param ignore_meta: If ``True``, do not verify if metadata matches.\n    :returns: ``True`` or ``False``.\n    \"\"\"\n\n    if not type(a) == type(b):\n        return False\n\n    if not a.same_structure(a, b):\n        return False\n\n    if not ignore_meta:\n        # are all meta data of a also in b, and are they the same value?\n        for k, v in a.meta_items():\n            if k not in [kk for kk, vv in b.meta_items()]:\n                return False\n            elif b.meta_val(k) != v:\n                return False\n\n        # are all meta data of b also in a?\n        for k, v in b.meta_items():\n            if k not in [kk for kk, vv in a.meta_items()]:\n                return False\n\n    # check all data fields in a\n    for dn, dv in a.data_items():\n\n        # are all fields also present in b?\n        if dn not in [dnn for dnn, dvv in b.data_items()]:\n            return False\n\n        # check if data is equal\n        if not num.arrays_equal(\n                np.array(a.data_vals(dn)),\n                np.array(b.data_vals(dn)),\n        ):\n            return False\n\n        if not ignore_meta:\n            # check meta data\n            for k, v in a.meta_items(dn):\n                if k not in [kk for kk, vv in b.meta_items(dn)]:\n                    return False\n                elif v != b.meta_val(k, dn):\n                    return False\n\n    # only thing left to check is whether there are items in b but not a\n    for dn, dv in b.data_items():\n        if dn not in [dnn for dnn, dvv in a.data_items()]:\n            return False\n\n        if not ignore_meta:\n            for k, v in b.meta_items(dn):\n                if k not in [kk for kk, vv in a.meta_items(dn)]:\n                    return False\n\n    return True\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.datastructure_from_string","title":"<code>datastructure_from_string(description)</code>","text":"<p>Construct a DataDict from a string description.</p> <p>Examples:     * <code>\"data[mV](x, y)\"</code> results in a datadict with one dependent <code>data</code> with unit <code>mV</code> and       two independents, <code>x</code> and <code>y</code>, that do not have units.</p> <pre><code>* ``\"data_1[mV](x, y); data_2[mA](x); x[mV]; y[nT]\"`` results in two dependents,\n  one of them depening on ``x`` and ``y``, the other only on ``x``.\n  Note that ``x`` and ``y`` have units. We can (but do not have to) omit them when specifying\n  the dependencies.\n\n* ``\"data_1[mV](x[mV], y[nT]); data_2[mA](x[mV])\"``. Same result as the previous example.\n</code></pre> <p>Rules:     We recognize descriptions of the form <code>field1[unit1](ax1, ax2, ...); field1[unit2](...); ...</code>.</p> <pre><code>* Field names (like ``field1`` and ``field2`` above) have to start with a letter, and may contain\n  word characters.\n* Field descriptors consist of the name, optional unit (presence signified by square brackets),\n  and optional dependencies (presence signified by round brackets).\n* Dependencies (axes) are implicitly recognized as fields (and thus have the same naming restrictions as field\n  names).\n* Axes are separated by commas.\n* Axes may have a unit when specified as dependency, but besides the name, square brackets, and commas no other\n  characters are recognized within the round brackets that specify the dependency.\n* In addition to being specified as dependency for a field,\n  axes may be specified also as additional field without dependency,\n  for instance to specify the unit (may simplify the string). For example,\n  ``z1[x, y]; z2[x, y]; x[V]; y[V]``.\n* Units may only consist of word characters.\n* Use of unexpected characters will result in the ignoring the part that contains the symbol.\n* The regular expression used to find field descriptors is:\n  ``((?&lt;=\\A)|(?&lt;=\\;))[a-zA-Z]+\\w*(\\[\\w*\\])?(\\(([a-zA-Z]+\\w*(\\[\\w*\\])?\\,?)*\\))?``\n</code></pre> Source code in <code>labcore/data/datadict.py</code> <pre><code>def datastructure_from_string(description: str) -&gt; DataDict:\n    r\"\"\"Construct a DataDict from a string description.\n\n    Examples:\n        * ``\"data[mV](x, y)\"`` results in a datadict with one dependent ``data`` with unit ``mV`` and\n          two independents, ``x`` and ``y``, that do not have units.\n\n        * ``\"data_1[mV](x, y); data_2[mA](x); x[mV]; y[nT]\"`` results in two dependents,\n          one of them depening on ``x`` and ``y``, the other only on ``x``.\n          Note that ``x`` and ``y`` have units. We can (but do not have to) omit them when specifying\n          the dependencies.\n\n        * ``\"data_1[mV](x[mV], y[nT]); data_2[mA](x[mV])\"``. Same result as the previous example.\n\n    Rules:\n        We recognize descriptions of the form ``field1[unit1](ax1, ax2, ...); field1[unit2](...); ...``.\n\n        * Field names (like ``field1`` and ``field2`` above) have to start with a letter, and may contain\n          word characters.\n        * Field descriptors consist of the name, optional unit (presence signified by square brackets),\n          and optional dependencies (presence signified by round brackets).\n        * Dependencies (axes) are implicitly recognized as fields (and thus have the same naming restrictions as field\n          names).\n        * Axes are separated by commas.\n        * Axes may have a unit when specified as dependency, but besides the name, square brackets, and commas no other\n          characters are recognized within the round brackets that specify the dependency.\n        * In addition to being specified as dependency for a field,\n          axes may be specified also as additional field without dependency,\n          for instance to specify the unit (may simplify the string). For example,\n          ``z1[x, y]; z2[x, y]; x[V]; y[V]``.\n        * Units may only consist of word characters.\n        * Use of unexpected characters will result in the ignoring the part that contains the symbol.\n        * The regular expression used to find field descriptors is:\n          ``((?&lt;=\\A)|(?&lt;=\\;))[a-zA-Z]+\\w*(\\[\\w*\\])?(\\(([a-zA-Z]+\\w*(\\[\\w*\\])?\\,?)*\\))?``\n    \"\"\"\n\n    description = description.replace(\" \", \"\")\n\n    data_name_pattern = r\"[a-zA-Z]+\\w*(\\[\\w*\\])?\"\n    pattern = r\"((?&lt;=\\A)|(?&lt;=\\;))\" + data_name_pattern + r\"(\\((\" + data_name_pattern + r\"\\,?)*\\))?\"\n    r = re.compile(pattern)\n\n    data_fields = []\n    while (r.search(description)):\n        match = r.search(description)\n        if match is None: break\n        data_fields.append(description[slice(*match.span())])\n        description = description[match.span()[1]:]\n\n    dd: Dict[str, Any] = dict()\n\n    def analyze_field(df: str) -&gt; Tuple[str, Optional[str], Optional[List[str]]]:\n        has_unit = True if '[' in df and ']' in df else False\n        has_dependencies = True if '(' in df and ')' in df else False\n\n        name: str = \"\"\n        unit: Optional[str] = None\n        axes: Optional[List[str]] = None\n\n        if has_unit:\n            name = df.split('[')[0]\n            unit = df.split('[')[1].split(']')[0]\n            if has_dependencies:\n                axes = df.split('(')[1].split(')')[0].split(',')\n        elif has_dependencies:\n            name = df.split('(')[0]\n            axes = df.split('(')[1].split(')')[0].split(',')\n        else:\n            name = df\n\n        if axes is not None and len(axes) == 0:\n            axes = None\n        return name, unit, axes\n\n    for df in data_fields:\n        name, unit, axes = analyze_field(df)\n\n        # double specifying is only allowed for independents.\n        # if an independent is specified multiple times, units must not collide\n        # (but units do not have to be specified more than once)\n        if name in dd:\n            if 'axes' in dd[name] or axes is not None:\n                raise ValueError(f'{name} is specified more than once.')\n            if 'unit' in dd[name] and unit is not None and dd[name]['unit'] != unit:\n                raise ValueError(f'conflicting units for {name}')\n\n        dd[name] = dict()\n        if unit is not None:\n            dd[name]['unit'] = unit\n\n        if axes is not None:\n            for ax in axes:\n                ax_name, ax_unit, ax_axes = analyze_field(ax)\n\n                # we do not allow nested dependencies.\n                if ax_axes is not None:\n                    raise ValueError(f'{ax_name} is independent, may not have dependencies')\n\n                # we can add fields implicitly from dependencies.\n                # independents may be given both implicitly and explicitly, but only\n                # when units don't collide.\n                if ax_name not in dd:\n                    dd[ax_name] = dict()\n                    if ax_unit is not None:\n                        dd[ax_name]['unit'] = ax_unit\n                else:\n                    if 'unit' in dd[ax_name] and ax_unit is not None and dd[ax_name]['unit'] != ax_unit:\n                        raise ValueError(f'conflicting units for {ax_name}')\n\n                if 'axes' not in dd[name]:\n                    dd[name]['axes'] = []\n                dd[name]['axes'].append(ax_name)\n\n    return DataDict(**dd)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.dd2df","title":"<code>dd2df(dd)</code>","text":"<p>make a pandas Dataframe from a datadict. Uses MultiIndex, and assumes that all data fields are compatible.</p>"},{"location":"data/data_formats/#labcore.data.datadict.dd2df--parameters","title":"Parameters","text":"<p>dd : DataDict     source data</p>"},{"location":"data/data_formats/#labcore.data.datadict.dd2df--returns","title":"Returns","text":"<p>DataFrame     pandas DataFrame</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def dd2df(dd: DataDict):\n    \"\"\"make a pandas Dataframe from a datadict.\n    Uses MultiIndex, and assumes that all data fields are compatible.\n\n    Parameters\n    ----------\n    dd : DataDict\n        source data\n\n    Returns\n    -------\n    DataFrame\n        pandas DataFrame\n    \"\"\"\n    dd_flat = dd.expand()\n    idx = pd.MultiIndex.from_arrays(\n        [dd_flat[a]['values'] for a in dd_flat.axes()],\n        names = dd_flat.axes(),\n    )\n    vals = {d: dd_flat[d]['values'] for d in dd_flat.dependents()}\n    return pd.DataFrame(data=vals, index=idx)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.dd2xr","title":"<code>dd2xr(dd)</code>","text":"<p>makes an xarray Dataset from a MeshgridDataDict.</p> <p>TODO: currently only supports 'regular' grides, i.e., all axes     are independet of each other, and can be represented by 1d arrays.     For each axis, the first slice is used as coordinate values.</p>"},{"location":"data/data_formats/#labcore.data.datadict.dd2xr--parameters","title":"Parameters","text":"<p>dd : MeshgridDataDict     input data</p>"},{"location":"data/data_formats/#labcore.data.datadict.dd2xr--returns","title":"Returns","text":"<p>xr.Dataset     xarray Dataset</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def dd2xr(dd: MeshgridDataDict) -&gt; xr.Dataset:\n    \"\"\"makes an xarray Dataset from a MeshgridDataDict.\n\n    TODO: currently only supports 'regular' grides, i.e., all axes\n        are independet of each other, and can be represented by 1d arrays.\n        For each axis, the first slice is used as coordinate values.\n\n    Parameters\n    ----------\n    dd : MeshgridDataDict\n        input data\n\n    Returns\n    -------\n    xr.Dataset\n        xarray Dataset\n    \"\"\"\n    axes = dd.axes()\n    coords = {}\n    for i, a in enumerate(axes):\n        slices = [0] * len(axes)\n        slices[i] = slice(None)\n        coords[a] = dd[a]['values'][tuple(slices)]\n\n    xds = xr.Dataset(\n        {d: (axes, dd[d]['values']) for d in dd.dependents()},\n        coords=coords,\n    )\n\n    for d in xds.data_vars:\n        xds[d].attrs['units'] = dd[d]['unit']\n    for d in xds.dims:\n        xds[d].attrs['units'] = dd[d]['unit']\n\n    return xds\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.guess_shape_from_datadict","title":"<code>guess_shape_from_datadict(data)</code>","text":"<p>Try to guess the shape of the datadict dependents from the axes values.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataDict</code> <p>Dataset to examine.</p> required <p>Returns:</p> Type Description <code>Dict[str, Union[None, Tuple[List[str], Tuple[int, ...]]]]</code> <p>A dictionary with the dependents as keys, and inferred shapes as values. Value is <code>None</code>, if the shape could not be inferred.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def guess_shape_from_datadict(data: DataDict) -&gt; \\\n        Dict[str, Union[None, Tuple[List[str], Tuple[int, ...]]]]:\n    \"\"\"\n    Try to guess the shape of the datadict dependents from the axes values.\n\n    :param data: Dataset to examine.\n    :return: A dictionary with the dependents as keys, and inferred shapes as\n             values. Value is ``None``, if the shape could not be inferred.\n    \"\"\"\n\n    shapes = {}\n    for d in data.dependents():\n        axnames = data.axes(d)\n        axes: Dict[str, np.ndarray] = {}\n        for a in axnames:\n            axdata = data.data_vals(a)\n            axes[a] = axdata\n        shapes[d] = num.guess_grid_from_sweep_direction(**axes)\n\n    return shapes\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.is_meta_key","title":"<code>is_meta_key(key)</code>","text":"<p>Checks if <code>key</code> is meta information.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The <code>key</code> we are checking.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if it is, <code>False</code> if it isn't.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def is_meta_key(key: str) -&gt; bool:\n    \"\"\"Checks if ``key`` is meta information.\n\n    :param key: The ``key`` we are checking.\n    :return: ``True`` if it is, ``False`` if it isn't.\n    \"\"\"\n    if key[:2] == '__' and key[-2:] == '__':\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.meshgrid_to_datadict","title":"<code>meshgrid_to_datadict(data)</code>","text":"<p>Make a DataDict from a MeshgridDataDict by reshaping the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>MeshgridDataDict</code> <p>Input <code>MeshgridDataDict</code>.</p> required <p>Returns:</p> Type Description <code>DataDict</code> <p>Flattened <code>DataDict</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def meshgrid_to_datadict(data: MeshgridDataDict) -&gt; DataDict:\n    \"\"\"\n    Make a DataDict from a MeshgridDataDict by reshaping the data.\n\n    :param data: Input ``MeshgridDataDict``.\n    :return: Flattened ``DataDict``.\n    \"\"\"\n    newdata = DataDict(**misc.unwrap_optional(data.structure(add_shape=False)))\n    for k, v in data.data_items():\n        val = v['values'].copy().reshape(-1)\n        newdata[k]['values'] = val\n\n    newdata = newdata.sanitize()\n    newdata.validate()\n    return newdata\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.meta_key_to_name","title":"<code>meta_key_to_name(key)</code>","text":"<p>Converts a meta data key to just the name. E.g: for <code>key</code>: \"meta\" returns \"meta\"</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key that is being converted</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the key.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def meta_key_to_name(key: str) -&gt; str:\n    \"\"\"\n    Converts a meta data key to just the name.\n    E.g: for ``key``: \"__meta__\" returns \"meta\"\n\n    :param key: The key that is being converted\n    :return: The name of the key.\n    :raises: ``ValueError`` if the ``key`` is not a meta key.\n\n\n    \"\"\"\n\n    if is_meta_key(key):\n        return key[2:-2]\n    else:\n        raise ValueError(f'{key} is not a meta key.')\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict.meta_name_to_key","title":"<code>meta_name_to_key(name)</code>","text":"<p>Converts <code>name</code> into a meta data key. E.g: \"meta\" gets converted to \"meta\"</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name that is being converted.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The meta data key based on <code>name</code>.</p> Source code in <code>labcore/data/datadict.py</code> <pre><code>def meta_name_to_key(name: str) -&gt; str:\n    \"\"\"\n    Converts ``name`` into a meta data key. E.g: \"meta\" gets converted to \"__meta__\"\n\n    :param name: The name that is being converted.\n    :return: The meta data key based on ``name``.\n    \"\"\"\n    return '__' + name + '__'\n</code></pre>"},{"location":"data/data_formats/#datadict-storage_1","title":"Datadict Storage","text":"<p>plottr.data.datadict_storage</p> <p>Provides file-storage tools for the DataDict class.</p> <p>.. note::     Any function in this module that interacts with a ddh5 file, will create a lock file while it is using the file.     The lock file has the following format: ~.lock. The file lock will get deleted even if the program     crashes. If the process is suddenly stopped however, we cannot guarantee that the file lock will be deleted."},{"location":"data/data_formats/#labcore.data.datadict_storage.AppendMode","title":"<code>AppendMode</code>","text":"<p>             Bases: <code>Enum</code></p> <p>How/Whether to append data to existing data.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>class AppendMode(Enum):\n    \"\"\"How/Whether to append data to existing data.\"\"\"\n\n    #: Data that is additional compared to already existing data is appended.\n    new = 0\n    #: All data is appended to existing data.\n    all = 1\n    #: Data is overwritten.\n    none = 2\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.DDH5Writer","title":"<code>DDH5Writer</code>","text":"<p>             Bases: <code>object</code></p> <p>Context manager for writing data to DDH5. Based on typical needs in taking data in an experimental physics lab.</p> <p>Creates lock file when writing data.</p> <p>Can be used in safe_write_mode to make sure the experiment and data will be saved even if the ddh5 is being used by other programs. In this mode, the data is individually saved in files in a .tmp folder. When the experiment is finished, the data is unified and saved in the original file. If the data is correctly reconstructed, the .tmp folder is deleted. If not you can use the function unify_safe_write_data to reconstruct the data.</p> <p>Parameters:</p> Name Type Description Default <code>basedir</code> <code>Union[str, Path]</code> <p>The root directory in which data is stored. :meth:<code>.create_file_structure</code> is creating the structure inside this root and determines the file name of the data. The default structure implemented here is <code>&lt;root&gt;/YYYY-MM-DD/YYYY-mm-dd_THHMMSS_&lt;ID&gt;-&lt;name&gt;/&lt;filename&gt;.ddh5</code>, where  is a short identifier string and  is the value of parameter <code>name</code>. To change this, re-implement :meth:<code>.data_folder</code> and/or :meth:<code>.create_file_structure</code>. <code>'.'</code> <code>datadict</code> <code>DataDict</code> <p>Initial data object. Must contain at least the structure of the data to be able to use :meth:<code>add_data</code> to add data.</p> required <code>groupname</code> <code>str</code> <p>Name of the top-level group in the file container. An existing group of that name will be deleted.</p> <code>'data'</code> <code>name</code> <code>Optional[str]</code> <p>Name of this dataset. Used in path/file creation and added as meta data.</p> <code>None</code> <code>filename</code> <code>str</code> <p>Filename to use. Defaults to 'data.ddh5'.</p> <code>'data'</code> <code>file_timeout</code> <code>Optional[float]</code> <p>How long the function will wait for the ddh5 file to unlock. If none uses the default value from the :class:<code>FileOpener</code>.</p> <code>None</code> <code>safe_write_mode</code> <code>Optional[bool]</code> <p>If True, will save the data in the safe writing mode. Defaults to False.</p> <code>False</code> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>class DDH5Writer(object):\n    \"\"\"Context manager for writing data to DDH5.\n    Based on typical needs in taking data in an experimental physics lab.\n\n    Creates lock file when writing data.\n\n    Can be used in safe_write_mode to make sure the experiment and data will be saved even if the ddh5 is being used by\n    other programs. In this mode, the data is individually saved in files in a .tmp folder. When the experiment is\n    finished, the data is unified and saved in the original file.\n    If the data is correctly reconstructed, the .tmp folder is deleted. If not you can use the function unify_safe_write_data\n    to reconstruct the data.\n\n\n    :param basedir: The root directory in which data is stored.\n        :meth:`.create_file_structure` is creating the structure inside this root and\n        determines the file name of the data. The default structure implemented here is\n        ``&lt;root&gt;/YYYY-MM-DD/YYYY-mm-dd_THHMMSS_&lt;ID&gt;-&lt;name&gt;/&lt;filename&gt;.ddh5``,\n        where &lt;ID&gt; is a short identifier string and &lt;name&gt; is the value of parameter `name`.\n        To change this, re-implement :meth:`.data_folder` and/or\n        :meth:`.create_file_structure`.\n    :param datadict: Initial data object. Must contain at least the structure of the\n        data to be able to use :meth:`add_data` to add data.\n    :param groupname: Name of the top-level group in the file container. An existing\n        group of that name will be deleted.\n    :param name: Name of this dataset. Used in path/file creation and added as meta data.\n    :param filename: Filename to use. Defaults to 'data.ddh5'.\n    :param file_timeout: How long the function will wait for the ddh5 file to unlock. If none uses the default\n        value from the :class:`FileOpener`.\n    :param safe_write_mode: If True, will save the data in the safe writing mode. Defaults to False.\n    \"\"\"\n\n    # TODO: need an operation mode for not keeping data in memory.\n    # TODO: a mode for working with pre-allocated data\n\n    # Sets how many files before the writer creates a new folder in its safe writing mode\n    n_files_per_dir = 1000\n\n    # Controls how often the writer reconstructs the data in its safe writing mode.\n    # It will reconstruct the data every `n_files_per_reconstruction` files or every `n_seconds_per_reconstruction`\n    # seconds, whichever comes first.\n    n_files_per_reconstruction = 1000\n    n_seconds_per_reconstruction = 10\n\n    def __init__(\n        self,\n        datadict: DataDict,\n        basedir: Union[str, Path] = \".\",\n        groupname: str = \"data\",\n        name: Optional[str] = None,\n        filename: str = \"data\",\n        filepath: Optional[Union[str, Path]] = None,\n        file_timeout: Optional[float] = None,\n        safe_write_mode: Optional[bool] = False,\n    ):\n        \"\"\"Constructor for :class:`.DDH5Writer`\"\"\"\n\n        self.basedir = Path(basedir)\n        self.datadict = datadict\n\n        if name is None:\n            name = \"\"\n        self.name = name\n\n        self.groupname = groupname\n        self.filename = Path(filename)\n\n        self.filepath: Optional[Path] = None\n        if filepath is not None:\n            self.filepath = Path(filepath)\n\n        self.datadict.add_meta(\"dataset.name\", name)\n        self.file_timeout = file_timeout\n        self.uuid = uuid.uuid1()\n\n        self.safe_write_mode = safe_write_mode\n        # Stores how many individual data files have been written for safe_write_mode\n        self.n_files = 0\n        self.last_update_n_files = 0\n        self.last_reconstruction_time = time.time()\n\n    def __enter__(self) -&gt; \"DDH5Writer\":\n        if self.filepath is None:\n            self.filepath = _data_file_path(self.data_file_path(), True)\n        logger.info(f\"Data location: {self.filepath}\")\n\n        nrecords: Optional[int] = self.datadict.nrecords()\n        if nrecords is not None and nrecords &gt; 0:\n            datadict_to_hdf5(\n                self.datadict,\n                str(self.filepath),\n                groupname=self.groupname,\n                append_mode=AppendMode.none,\n                file_timeout=self.file_timeout,\n            )\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        exc_traceback: Optional[TracebackType],\n    ) -&gt; None:\n        assert self.filepath is not None\n\n        if self.safe_write_mode:\n            try:\n                logger.debug(\"Starting reconstruction of data\")\n                dd = reconstruct_safe_write_data(self.filepath, file_timeout=self.file_timeout)\n\n                # Makes sure the reconstructed data matches the one in the .tmp folder\n                assert datasets_are_equal(dd, self.datadict, ignore_meta=True)\n\n                datadict_to_hdf5(dd, self.filepath, groupname=self.groupname, file_timeout=self.file_timeout, append_mode=AppendMode.none)\n                shutil.rmtree(self.filepath.parent / \".tmp\")\n\n            except Exception as e:\n                logger.error(f\"Error while unifying data. Data should be located in the .tmp directory: {e}\")\n                self.add_tag(\"__not_reconstructed__\")\n                raise e\n\n        with FileOpener(self.filepath, \"a\", timeout=self.file_timeout) as f:\n            add_cur_time_attr(f.require_group(self.groupname), name=\"close\")\n        if exc_type is None:\n            # exiting because the measurement is complete\n            self.add_tag(\"__complete__\")\n        else:\n            # exiting because of an exception\n            self.add_tag(\"__interrupted__\")\n\n    def data_folder(self) -&gt; Path:\n        \"\"\"Return the folder, relative to the data root path, in which data will\n        be saved.\n\n        Default format:\n        ``&lt;basedir&gt;/YYYY-MM-DD/YYYY-mm-ddTHHMMSS_&lt;ID&gt;-&lt;name&gt;``.\n        In this implementation we use the first 8 characters of a UUID as ID.\n\n        :returns: The folder path.\n        \"\"\"\n        ID = str(self.uuid).split(\"-\")[0]\n        parent = f\"{datetime.datetime.now().replace(microsecond=0).isoformat().replace(':', '')}_{ID}\"\n        if self.name:\n            parent += f\"-{self.name}\"\n        path = Path(time.strftime(\"%Y-%m-%d\"), parent)\n        return path\n\n    def data_file_path(self) -&gt; Path:\n        \"\"\"Determine the filepath of the data file.\n\n        :returns: The filepath of the data file.\n        \"\"\"\n        data_folder_path = Path(self.basedir, self.data_folder())\n        appendix = \"\"\n        idx = 2\n        while data_folder_path.exists():\n            appendix = f\"-{idx}\"\n            data_folder_path = Path(self.basedir, str(self.data_folder()) + appendix)\n            idx += 1\n\n        return Path(data_folder_path, self.filename)\n\n    def _generate_next_safe_write_path(self):\n        \"\"\"\n        Generates the next path for the data to be saved in the safe writing mode. Should not be used for other things.\n        \"\"\"\n\n        now = datetime.datetime.now()\n\n        # Creates tmp folder\n        tmp_folder = self.filepath.parent / \".tmp\"\n        tmp_folder.mkdir(exist_ok=True)\n\n        # Creates today folder\n        today_folder = tmp_folder / now.strftime(\"%Y-%m-%d\")\n        today_folder.mkdir(exist_ok=True)\n\n        # Creates hour folder\n        hour_folder = today_folder / now.strftime(\"%H\")\n        hour_folder.mkdir(exist_ok=True)\n\n        # Creates minute folder\n        minute_folder = hour_folder / now.strftime(\"%M\")\n        minute_folder.mkdir(exist_ok=True)\n\n        n_secs = 0\n        second_folder = minute_folder / (now.strftime(\"%S\") + f\"_#{str(n_secs)}\")\n        if second_folder.exists():\n            n_data_files = len(list(second_folder.iterdir())) + 1\n            if n_data_files &gt;= self.n_files_per_dir:\n                keep_searching = True\n                while keep_searching:\n                    n_secs += 1\n                    second_folder = minute_folder / (now.strftime(\"%S\") + f\"_#{str(n_secs)}\")\n                    if not second_folder.exists():\n                        keep_searching = False\n                        second_folder.mkdir()\n                    else:\n                        n_data_files = len(list(second_folder.iterdir())) + 1\n                        if n_data_files &lt; self.n_files_per_dir:\n                            keep_searching = False\n\n        # Creates the filename that follows the structure: yyyy-mm-dd-HHMM-SS#_#&lt;total_number_of_files&gt;.ddh5\n        filename = now.strftime(\"%Y-%m-%d-%H_%M_%S\") + f\"_{n_secs}_#{self.n_files}.ddh5\"\n        self.n_files += 1\n\n        return second_folder/filename\n\n    def add_data(self, **kwargs: Any) -&gt; None:\n        \"\"\"Add data to the file (and the internal `DataDict`).\n\n        Requires one keyword argument per data field in the `DataDict`, with\n        the key being the name, and value the data to add. It is required that\n        all added data has the same number of 'rows', i.e., the most outer dimension\n        has to match for data to be inserted faithfully.\n        If some data is scalar and others are not, then the data should be reshaped\n        to (1, ) for the scalar data, and (1, ...) for the others; in other words,\n        an outer dimension with length 1 is added for all.\n        \"\"\"\n        self.datadict.add_data(**kwargs)\n\n        if self.safe_write_mode:\n            clean_dd_copy = self.datadict.structure()\n            clean_dd_copy.add_data(**kwargs)\n            filepath = self._generate_next_safe_write_path()\n\n            datadict_to_hdf5(\n                clean_dd_copy,\n                filepath,\n                groupname=self.groupname,\n                append_mode=AppendMode.new,\n                file_timeout=self.file_timeout,\n            )\n\n            delta_t = time.time() - self.last_reconstruction_time\n\n            # Reconstructs the data every n_files_per_reconstruction files or every n_seconds_per_reconstruction seconds\n            if (self.n_files - self.last_update_n_files &gt;= self.n_files_per_reconstruction or\n                    delta_t &gt; self.n_seconds_per_reconstruction):\n                try:\n                    dd = reconstruct_safe_write_data(self.filepath, unification_from_scratch=False,\n                                                     file_timeout=self.file_timeout)\n                    datadict_to_hdf5(dd, self.filepath, groupname=self.groupname, file_timeout=self.file_timeout, append_mode=AppendMode.none)\n                except RuntimeError as e:\n                    logger.warning(f\"Error while unifying data: {e} \\nData is still getting saved in .tmp directory.\")\n\n                with FileOpener(self.filepath, \"a\", timeout=self.file_timeout) as f:\n                    add_cur_time_attr(f, name=\"last_change\")\n                    add_cur_time_attr(f[self.groupname], name=\"last_change\")\n\n                # Even if I fail at reconstruction, I want to wait the same amount as if it was successful to try again.\n                self.last_reconstruction_time = time.time()\n                self.last_update_n_files = self.n_files\n\n        else:\n            nrecords = self.datadict.nrecords()\n            if nrecords is not None and nrecords &gt; 0:\n                datadict_to_hdf5(\n                    self.datadict,\n                    str(self.filepath),\n                    groupname=self.groupname,\n                    file_timeout=self.file_timeout,\n                )\n\n                assert self.filepath is not None\n                with FileOpener(self.filepath, \"a\", timeout=self.file_timeout) as f:\n                    add_cur_time_attr(f, name=\"last_change\")\n                    add_cur_time_attr(f[self.groupname], name=\"last_change\")\n\n    # convenience methods for saving things in the same directory as the ddh5 file\n\n    def add_tag(self, tags: Union[str, Collection[str]]) -&gt; None:\n        assert self.filepath is not None\n        if isinstance(tags, str):\n            tags = [tags]\n        for tag in tags:\n            open(self.filepath.parent / f\"{tag}.tag\", \"x\").close()\n\n    def backup_file(self, paths: Union[str, Collection[str]]) -&gt; None:\n        assert self.filepath is not None\n        if isinstance(paths, str):\n            paths = [paths]\n        for path in paths:\n            shutil.copy(path, self.filepath.parent)\n\n    def save_text(self, name: str, text: str) -&gt; None:\n        assert self.filepath is not None\n        with open(self.filepath.parent / name, \"x\") as f:\n            f.write(text)\n\n    def save_dict(self, name: str, d: dict) -&gt; None:\n        assert self.filepath is not None\n        with open(self.filepath.parent / name, \"x\") as f:\n            json.dump(d, f, indent=4, ensure_ascii=False, cls=NumpyEncoder)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.DDH5Writer.__init__","title":"<code>__init__(datadict, basedir='.', groupname='data', name=None, filename='data', filepath=None, file_timeout=None, safe_write_mode=False)</code>","text":"<p>Constructor for :class:<code>.DDH5Writer</code></p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def __init__(\n    self,\n    datadict: DataDict,\n    basedir: Union[str, Path] = \".\",\n    groupname: str = \"data\",\n    name: Optional[str] = None,\n    filename: str = \"data\",\n    filepath: Optional[Union[str, Path]] = None,\n    file_timeout: Optional[float] = None,\n    safe_write_mode: Optional[bool] = False,\n):\n    \"\"\"Constructor for :class:`.DDH5Writer`\"\"\"\n\n    self.basedir = Path(basedir)\n    self.datadict = datadict\n\n    if name is None:\n        name = \"\"\n    self.name = name\n\n    self.groupname = groupname\n    self.filename = Path(filename)\n\n    self.filepath: Optional[Path] = None\n    if filepath is not None:\n        self.filepath = Path(filepath)\n\n    self.datadict.add_meta(\"dataset.name\", name)\n    self.file_timeout = file_timeout\n    self.uuid = uuid.uuid1()\n\n    self.safe_write_mode = safe_write_mode\n    # Stores how many individual data files have been written for safe_write_mode\n    self.n_files = 0\n    self.last_update_n_files = 0\n    self.last_reconstruction_time = time.time()\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.DDH5Writer.add_data","title":"<code>add_data(**kwargs)</code>","text":"<p>Add data to the file (and the internal <code>DataDict</code>).</p> <p>Requires one keyword argument per data field in the <code>DataDict</code>, with the key being the name, and value the data to add. It is required that all added data has the same number of 'rows', i.e., the most outer dimension has to match for data to be inserted faithfully. If some data is scalar and others are not, then the data should be reshaped to (1, ) for the scalar data, and (1, ...) for the others; in other words, an outer dimension with length 1 is added for all.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def add_data(self, **kwargs: Any) -&gt; None:\n    \"\"\"Add data to the file (and the internal `DataDict`).\n\n    Requires one keyword argument per data field in the `DataDict`, with\n    the key being the name, and value the data to add. It is required that\n    all added data has the same number of 'rows', i.e., the most outer dimension\n    has to match for data to be inserted faithfully.\n    If some data is scalar and others are not, then the data should be reshaped\n    to (1, ) for the scalar data, and (1, ...) for the others; in other words,\n    an outer dimension with length 1 is added for all.\n    \"\"\"\n    self.datadict.add_data(**kwargs)\n\n    if self.safe_write_mode:\n        clean_dd_copy = self.datadict.structure()\n        clean_dd_copy.add_data(**kwargs)\n        filepath = self._generate_next_safe_write_path()\n\n        datadict_to_hdf5(\n            clean_dd_copy,\n            filepath,\n            groupname=self.groupname,\n            append_mode=AppendMode.new,\n            file_timeout=self.file_timeout,\n        )\n\n        delta_t = time.time() - self.last_reconstruction_time\n\n        # Reconstructs the data every n_files_per_reconstruction files or every n_seconds_per_reconstruction seconds\n        if (self.n_files - self.last_update_n_files &gt;= self.n_files_per_reconstruction or\n                delta_t &gt; self.n_seconds_per_reconstruction):\n            try:\n                dd = reconstruct_safe_write_data(self.filepath, unification_from_scratch=False,\n                                                 file_timeout=self.file_timeout)\n                datadict_to_hdf5(dd, self.filepath, groupname=self.groupname, file_timeout=self.file_timeout, append_mode=AppendMode.none)\n            except RuntimeError as e:\n                logger.warning(f\"Error while unifying data: {e} \\nData is still getting saved in .tmp directory.\")\n\n            with FileOpener(self.filepath, \"a\", timeout=self.file_timeout) as f:\n                add_cur_time_attr(f, name=\"last_change\")\n                add_cur_time_attr(f[self.groupname], name=\"last_change\")\n\n            # Even if I fail at reconstruction, I want to wait the same amount as if it was successful to try again.\n            self.last_reconstruction_time = time.time()\n            self.last_update_n_files = self.n_files\n\n    else:\n        nrecords = self.datadict.nrecords()\n        if nrecords is not None and nrecords &gt; 0:\n            datadict_to_hdf5(\n                self.datadict,\n                str(self.filepath),\n                groupname=self.groupname,\n                file_timeout=self.file_timeout,\n            )\n\n            assert self.filepath is not None\n            with FileOpener(self.filepath, \"a\", timeout=self.file_timeout) as f:\n                add_cur_time_attr(f, name=\"last_change\")\n                add_cur_time_attr(f[self.groupname], name=\"last_change\")\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.DDH5Writer.data_file_path","title":"<code>data_file_path()</code>","text":"<p>Determine the filepath of the data file.</p> <p>Returns:</p> Type Description <code>Path</code> <p>The filepath of the data file.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def data_file_path(self) -&gt; Path:\n    \"\"\"Determine the filepath of the data file.\n\n    :returns: The filepath of the data file.\n    \"\"\"\n    data_folder_path = Path(self.basedir, self.data_folder())\n    appendix = \"\"\n    idx = 2\n    while data_folder_path.exists():\n        appendix = f\"-{idx}\"\n        data_folder_path = Path(self.basedir, str(self.data_folder()) + appendix)\n        idx += 1\n\n    return Path(data_folder_path, self.filename)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.DDH5Writer.data_folder","title":"<code>data_folder()</code>","text":"<p>Return the folder, relative to the data root path, in which data will be saved.</p> <p>Default format: <code>&lt;basedir&gt;/YYYY-MM-DD/YYYY-mm-ddTHHMMSS_&lt;ID&gt;-&lt;name&gt;</code>. In this implementation we use the first 8 characters of a UUID as ID.</p> <p>Returns:</p> Type Description <code>Path</code> <p>The folder path.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def data_folder(self) -&gt; Path:\n    \"\"\"Return the folder, relative to the data root path, in which data will\n    be saved.\n\n    Default format:\n    ``&lt;basedir&gt;/YYYY-MM-DD/YYYY-mm-ddTHHMMSS_&lt;ID&gt;-&lt;name&gt;``.\n    In this implementation we use the first 8 characters of a UUID as ID.\n\n    :returns: The folder path.\n    \"\"\"\n    ID = str(self.uuid).split(\"-\")[0]\n    parent = f\"{datetime.datetime.now().replace(microsecond=0).isoformat().replace(':', '')}_{ID}\"\n    if self.name:\n        parent += f\"-{self.name}\"\n    path = Path(time.strftime(\"%Y-%m-%d\"), parent)\n    return path\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.FileOpener","title":"<code>FileOpener</code>","text":"<p>Context manager for opening files, creates its own file lock to indicate other programs that the file is being used. The lock file follows the following structure: \"~.lock\". <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[Path, str]</code> <p>The file path.</p> required <code>mode</code> <code>str</code> <p>The opening file mode. Only the following modes are supported: 'r', 'w', 'w-', 'a'. Defaults to 'r'.</p> <code>'r'</code> <code>timeout</code> <code>Optional[float]</code> <p>Time, in seconds, the context manager waits for the file to unlock. Defaults to 30.</p> <code>None</code> <code>test_delay</code> <code>float</code> <p>Length of time in between checks. I.e. how long the FileOpener waits to see if a file got unlocked again</p> <code>0.1</code> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>class FileOpener:\n    \"\"\"\n    Context manager for opening files, creates its own file lock to indicate other programs that the file is being\n    used. The lock file follows the following structure: \"~&lt;file_name&gt;.lock\".\n\n    :param path: The file path.\n    :param mode: The opening file mode. Only the following modes are supported: 'r', 'w', 'w-', 'a'. Defaults to 'r'.\n    :param timeout: Time, in seconds, the context manager waits for the file to unlock. Defaults to 30.\n    :param test_delay: Length of time in between checks. I.e. how long the FileOpener waits to see if a file got\n        unlocked again\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Union[Path, str],\n        mode: str = \"r\",\n        timeout: Optional[float] = None,\n        test_delay: float = 0.1,\n    ):\n        self.path = Path(path)\n        self.lock_path = self.path.parent.joinpath(\"~\" + str(self.path.stem) + \".lock\")\n        if mode not in [\"r\", \"w\", \"w-\", \"a\"]:\n            raise ValueError(\"Only 'r', 'w', 'w-', 'a' modes are supported.\")\n        self.mode = mode\n        self.default_timeout = 300.0\n        if timeout is None:\n            self.timeout = self.default_timeout\n        else:\n            self.timeout = timeout\n        self.test_delay = test_delay\n\n        self.file: Optional[h5py.File] = None\n\n    def __enter__(self) -&gt; h5py.File:\n        self.file = self.open_when_unlocked()\n        return self.file\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        exc_traceback: Optional[TracebackType],\n    ) -&gt; None:\n        try:\n            assert self.file is not None\n            self.file.close()\n        finally:\n            if self.lock_path.is_file():\n                self.lock_path.unlink()\n\n    def open_when_unlocked(self) -&gt; h5py.File:\n        t0 = time.time()\n        while True:\n            if not self.lock_path.is_file():\n                try:\n                    self.lock_path.touch(exist_ok=False)\n                # This happens if some other process beat this one and created the file beforehand\n                except FileExistsError:\n                    continue\n\n                while True:\n                    try:\n                        f = h5py.File(str(self.path), self.mode)\n                        return f\n                    except (OSError, PermissionError, RuntimeError):\n                        pass\n                    time.sleep(\n                        self.test_delay\n                    )  # don't overwhelm the FS by very fast repeated calls.\n                    if time.time() - t0 &gt; self.timeout:\n                        raise RuntimeError(\"Waiting or file unlock timeout\")\n\n            time.sleep(\n                self.test_delay\n            )  # don't overwhelm the FS by very fast repeated calls.\n            if time.time() - t0 &gt; self.timeout:\n                raise RuntimeError(\"Lock file remained for longer than timeout time\")\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.add_cur_time_attr","title":"<code>add_cur_time_attr(h5obj, name='creation', prefix='__', suffix='__')</code>","text":"<p>Add current time information to the given HDF5 object, following the format of: <code>&lt;prefix&gt;&lt;name&gt;_time_sec&lt;suffix&gt;</code>.</p> <p>Parameters:</p> Name Type Description Default <code>h5obj</code> <code>Any</code> <p>The HDF5 object.</p> required <code>name</code> <code>str</code> <p>The name of the attribute.</p> <code>'creation'</code> <code>prefix</code> <code>str</code> <p>Prefix of the attribute.</p> <code>'__'</code> <code>suffix</code> <code>str</code> <p>Suffix of the attribute.</p> <code>'__'</code> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def add_cur_time_attr(\n    h5obj: Any, name: str = \"creation\", prefix: str = \"__\", suffix: str = \"__\"\n) -&gt; None:\n    \"\"\"Add current time information to the given HDF5 object, following the format of:\n    ``&lt;prefix&gt;&lt;name&gt;_time_sec&lt;suffix&gt;``.\n\n    :param h5obj: The HDF5 object.\n    :param name: The name of the attribute.\n    :param prefix: Prefix of the attribute.\n    :param suffix: Suffix of the attribute.\n    \"\"\"\n\n    t = time.localtime()\n    tsec = time.mktime(t)\n    tstr = time.strftime(TIMESTRFORMAT, t)\n\n    set_attr(h5obj, prefix + name + \"_time_sec\" + suffix, tsec)\n    set_attr(h5obj, prefix + name + \"_time_str\" + suffix, tstr)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.all_datadicts_from_hdf5","title":"<code>all_datadicts_from_hdf5(path, file_timeout=None, **kwargs)</code>","text":"<p>Loads all the DataDicts contained on a single HDF5 file. Returns a dictionary with the group names as keys and the DataDicts as the values of that key.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>The path of the HDF5 file.</p> required <code>file_timeout</code> <code>Optional[float]</code> <p>How long the function will wait for the ddh5 file to unlock. If none uses the default value from the :class:<code>FileOpener</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with group names as key, and the DataDicts inside them as values.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def all_datadicts_from_hdf5(\n    path: Union[str, Path], file_timeout: Optional[float] = None, **kwargs: Any\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Loads all the DataDicts contained on a single HDF5 file. Returns a dictionary with the group names as keys and\n    the DataDicts as the values of that key.\n\n    :param path: The path of the HDF5 file.\n    :param file_timeout: How long the function will wait for the ddh5 file to unlock. If none uses the default\n        value from the :class:`FileOpener`.\n    :return: Dictionary with group names as key, and the DataDicts inside them as values.\n    \"\"\"\n    filepath = _data_file_path(path)\n    if not os.path.exists(filepath):\n        raise ValueError(\"Specified file does not exist.\")\n\n    ret = {}\n    with FileOpener(filepath, \"r\", file_timeout) as f:\n        keys = [k for k in f.keys()]\n    for k in keys:\n        ret[k] = datadict_from_hdf5(\n            path=path, groupname=k, file_timeout=file_timeout, **kwargs\n        )\n    return ret\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.datadict_from_hdf5","title":"<code>datadict_from_hdf5(path, groupname='data', startidx=None, stopidx=None, structure_only=False, ignore_unequal_lengths=True, file_timeout=None)</code>","text":"<p>Load a DataDict from file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Full filepath without the file extension.</p> required <code>groupname</code> <code>str</code> <p>Name of hdf5 group.</p> <code>'data'</code> <code>startidx</code> <code>Union[int, None]</code> <p>Start row.</p> <code>None</code> <code>stopidx</code> <code>Union[int, None]</code> <p>End row + 1.</p> <code>None</code> <code>structure_only</code> <code>bool</code> <p>If <code>True</code>, don't load the data values.</p> <code>False</code> <code>ignore_unequal_lengths</code> <code>bool</code> <p>If <code>True</code>, don't fail when the rows have unequal length; will return the longest consistent DataDict possible.</p> <code>True</code> <code>file_timeout</code> <code>Optional[float]</code> <p>How long the function will wait for the ddh5 file to unlock. If none uses the default value from the :class:<code>FileOpener</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataDict</code> <p>Validated DataDict.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def datadict_from_hdf5(\n    path: Union[str, Path],\n    groupname: str = \"data\",\n    startidx: Union[int, None] = None,\n    stopidx: Union[int, None] = None,\n    structure_only: bool = False,\n    ignore_unequal_lengths: bool = True,\n    file_timeout: Optional[float] = None,\n) -&gt; DataDict:\n    \"\"\"Load a DataDict from file.\n\n    :param path: Full filepath without the file extension.\n    :param groupname: Name of hdf5 group.\n    :param startidx: Start row.\n    :param stopidx: End row + 1.\n    :param structure_only: If `True`, don't load the data values.\n    :param ignore_unequal_lengths: If `True`, don't fail when the rows have\n        unequal length; will return the longest consistent DataDict possible.\n    :param file_timeout: How long the function will wait for the ddh5 file to unlock. If none uses the default\n        value from the :class:`FileOpener`.\n    :return: Validated DataDict.\n    \"\"\"\n    filepath = _data_file_path(path)\n    if not filepath.exists():\n        raise ValueError(f\"Specified file '{filepath}' does not exist.\")\n\n    if startidx is None:\n        startidx = 0\n\n    res = {}\n    with FileOpener(filepath, \"r\", file_timeout) as f:\n        if groupname not in f:\n            raise ValueError(\"Group does not exist.\")\n\n        grp = f[groupname]\n        keys = list(grp.keys())\n        lens = [len(grp[k][:]) for k in keys]\n\n        if len(set(lens)) &gt; 1:\n            if not ignore_unequal_lengths:\n                raise RuntimeError(\"Unequal lengths in the datasets.\")\n\n            if stopidx is None or stopidx &gt; min(lens):\n                stopidx = min(lens)\n        else:\n            if stopidx is None or stopidx &gt; lens[0]:\n                stopidx = lens[0]\n\n        for attr in grp.attrs:\n            if is_meta_key(attr):\n                res[attr] = deh5ify(grp.attrs[attr])\n\n        for k in keys:\n            ds = grp[k]\n            entry: Dict[str, Union[Collection[Any], np.ndarray]] = dict(\n                values=np.array([]),\n            )\n\n            if \"axes\" in ds.attrs:\n                entry[\"axes\"] = deh5ify(ds.attrs[\"axes\"]).tolist()\n            else:\n                entry[\"axes\"] = []\n\n            if \"unit\" in ds.attrs:\n                entry[\"unit\"] = deh5ify(ds.attrs[\"unit\"])\n\n            if not structure_only:\n                entry[\"values\"] = ds[startidx:stopidx]\n\n            entry[\"__shape__\"] = ds[:].shape\n\n            # and now the meta data\n            for attr in ds.attrs:\n                if is_meta_key(attr):\n                    _val = deh5ify(ds.attrs[attr])\n                    entry[attr] = deh5ify(ds.attrs[attr])\n\n            res[k] = entry\n\n    dd = DataDict(**res)\n    dd.validate()\n    return dd\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.datadict_to_hdf5","title":"<code>datadict_to_hdf5(datadict, path, groupname='data', append_mode=AppendMode.new, file_timeout=None)</code>","text":"<p>Write a DataDict to DDH5</p> <p>Note: Meta data is only written during initial writing of the dataset. If we're appending to existing datasets, we're not setting meta data anymore.</p> <p>Parameters:</p> Name Type Description Default <code>datadict</code> <code>DataDict</code> <p>Datadict to write to disk.</p> required <code>path</code> <code>Union[str, Path]</code> <p>Path of the file (extension may be omitted).</p> required <code>groupname</code> <code>str</code> <p>Name of the top level group to store the data in.</p> <code>'data'</code> <code>append_mode</code> <code>AppendMode</code> <ul> <li><code>AppendMode.none</code> : Delete and re-create group. - <code>AppendMode.new</code> : Append rows in the datadict that exceed the number of existing rows in the dataset already stored. Note: we're not checking for content, only length!  - <code>AppendMode.all</code> : Append all data in datadict to file data sets.</li> </ul> <code>new</code> <code>file_timeout</code> <code>Optional[float]</code> <p>How long the function will wait for the ddh5 file to unlock. Only relevant if you are writing to a file that already exists and some other program is trying to read it at the same time. If none uses the default value from the :class:<code>FileOpener</code>.</p> <code>None</code> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def datadict_to_hdf5(\n    datadict: DataDict,\n    path: Union[str, Path],\n    groupname: str = \"data\",\n    append_mode: AppendMode = AppendMode.new,\n    file_timeout: Optional[float] = None,\n) -&gt; None:\n    \"\"\"Write a DataDict to DDH5\n\n    Note: Meta data is only written during initial writing of the dataset.\n    If we're appending to existing datasets, we're not setting meta\n    data anymore.\n\n    :param datadict: Datadict to write to disk.\n    :param path: Path of the file (extension may be omitted).\n    :param groupname: Name of the top level group to store the data in.\n    :param append_mode:\n        - `AppendMode.none` : Delete and re-create group.\n        - `AppendMode.new` : Append rows in the datadict that exceed\n          the number of existing rows in the dataset already stored.\n          Note: we're not checking for content, only length!\n\n        - `AppendMode.all` : Append all data in datadict to file data sets.\n    :param file_timeout: How long the function will wait for the ddh5 file to unlock. Only relevant if you are\n        writing to a file that already exists and some other program is trying to read it at the same time.\n        If none uses the default value from the :class:`FileOpener`.\n\n    \"\"\"\n    filepath = _data_file_path(path, True)\n    if not filepath.exists():\n        append_mode = AppendMode.none\n\n    with FileOpener(filepath, \"a\", file_timeout) as f:\n        if append_mode is AppendMode.none:\n            init_file(f, groupname)\n        assert groupname in f\n        grp = f[groupname]\n\n        # add top-level meta data.\n        for k, v in datadict.meta_items(clean_keys=False):\n            set_attr(grp, k, v)\n\n        for k, v in datadict.data_items():\n            data = v[\"values\"]\n            shp = data.shape\n            nrows = shp[0]\n\n            # create new dataset, add axes and unit metadata\n            if k not in grp:\n                maxshp = tuple([None] + list(shp[1:]))\n                ds = grp.create_dataset(k, maxshape=maxshp, data=data)\n\n                # add meta data\n                add_cur_time_attr(ds)\n\n                if v.get(\"axes\", []):\n                    set_attr(ds, \"axes\", v[\"axes\"])\n                if v.get(\"unit\", \"\") != \"\":\n                    set_attr(ds, \"unit\", v[\"unit\"])\n\n                for kk, vv in datadict.meta_items(k, clean_keys=False):\n                    set_attr(ds, kk, vv)\n                ds.flush()\n\n            # if the dataset already exits, append data according to\n            # chosen append mode.\n            else:\n                ds = grp[k]\n                dslen = ds.shape[0]\n\n                if append_mode == AppendMode.new:\n                    newshp = tuple([nrows] + list(shp[1:]))\n                    ds.resize(newshp)\n                    ds[dslen:] = data[dslen:]\n                elif append_mode == AppendMode.all:\n                    newshp = tuple([dslen + nrows] + list(shp[1:]))\n                    ds.resize(newshp)\n                    ds[dslen:] = data[:]\n                ds.flush()\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.deh5ify","title":"<code>deh5ify(obj)</code>","text":"<p>Convert slightly mangled types back to more handy ones.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Input object.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Object</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def deh5ify(obj: Any) -&gt; Any:\n    \"\"\"Convert slightly mangled types back to more handy ones.\n\n    :param obj: Input object.\n    :return: Object\n    \"\"\"\n    if type(obj) == bytes:\n        return obj.decode()\n\n    if type(obj) == np.ndarray and obj.dtype.kind == \"S\":\n        return np.char.decode(obj)\n\n    return obj\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.h5ify","title":"<code>h5ify(obj)</code>","text":"<p>Convert an object into something that we can assign to an HDF5 attribute.</p> <p>Performs the following conversions: - list/array of strings -&gt; numpy chararray of unicode type</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Input object.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Object, converted if necessary.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def h5ify(obj: Any) -&gt; Any:\n    \"\"\"\n    Convert an object into something that we can assign to an HDF5 attribute.\n\n    Performs the following conversions:\n    - list/array of strings -&gt; numpy chararray of unicode type\n\n    :param obj: Input object.\n    :return: Object, converted if necessary.\n    \"\"\"\n    if isinstance(obj, list):\n        all_string = True\n        for elt in obj:\n            if not isinstance(elt, str):\n                all_string = False\n                break\n        if not all_string:\n            obj = np.array(obj)\n\n    if type(obj) == np.ndarray and obj.dtype.kind == \"U\":\n        return np.char.encode(obj, encoding=\"utf8\")\n\n    return obj\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.load_as_xr","title":"<code>load_as_xr(folder, fn='data.ddh5', fields=None)</code>","text":"<p>Load ddh5 data as xarray (only for gridable data).</p>"},{"location":"data/data_formats/#labcore.data.datadict_storage.load_as_xr--parameters","title":"Parameters","text":"<p>folder :     data folder fn : str, optional     filename, by default 'data.ddh5'</p>"},{"location":"data/data_formats/#labcore.data.datadict_storage.load_as_xr--returns","title":"Returns","text":"<p>type description</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def load_as_xr(\n    folder: Path, fn=\"data.ddh5\", fields: Optional[List[str]] = None\n) -&gt; xr.Dataset:\n    \"\"\"Load ddh5 data as xarray (only for gridable data).\n\n    Parameters\n    ----------\n    folder :\n        data folder\n    fn : str, optional\n        filename, by default 'data.ddh5'\n\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    fn = folder / fn\n    dd = datadict_from_hdf5(fn)\n    if fields is not None:\n        dd = dd.extract(fields)\n    xrdata = split_complex(dd2xr(datadict_to_meshgrid(dd)))\n    xrdata.attrs[\"raw_data_folder\"] = str(folder.resolve())\n    xrdata.attrs[\"raw_data_fn\"] = str(fn)\n    return xrdata\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.reconstruct_safe_write_data","title":"<code>reconstruct_safe_write_data(path, unification_from_scratch=True, file_timeout=None)</code>","text":"<p>Creates a new DataDict from the data saved in the .tmp folder. This is used when the data is saved in the safe writing mode. The data is saved in individual files in the .tmp folder. This function reconstructs the data from these files and returns a DataDict with the data.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>The path to the folder containing the .tmp path</p> required <code>unification_from_scratch</code> <code>bool</code> <p>If True, will reconstruct the data from scratch. If False, will try to load the data from the last reconstructed file.</p> <code>True</code> <code>file_timeout</code> <code>Optional[float]</code> <p>How long the function will wait for the ddh5 file to unlock. If none uses the default value</p> <code>None</code> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def reconstruct_safe_write_data(path: Union[str, Path],\n                          unification_from_scratch: bool = True,\n                          file_timeout: Optional[float] = None) -&gt; DataDictBase:\n    \"\"\"\n    Creates a new DataDict from the data saved in the .tmp folder. This is used when the data is saved in the safe\n    writing mode. The data is saved in individual files in the .tmp folder. This function reconstructs the data from\n    these files and returns a DataDict with the data.\n\n    :param path: The path to the folder containing the .tmp path\n    :param unification_from_scratch: If True, will reconstruct the data from scratch. If False, will try to load the\n        data from the last reconstructed file.\n    :param file_timeout: How long the function will wait for the ddh5 file to unlock. If none uses the default value\n    \"\"\"\n\n    path = Path(path)\n\n    tmp_path = path.parent / \".tmp\"\n\n    # FIXME: This should probably raise a warning more than a crash, but will leave it as crash for now\n    if not tmp_path.exists():\n        raise ValueError(\"Specified folder does not exist.\")\n\n    files = []\n    for dirpath, dirnames, filenames in os.walk(str(tmp_path)):\n        files.extend([(Path(dirpath)/file) for file in filenames if file.endswith(\".ddh5\")])\n\n    files = sorted(files, key=lambda x: int(x.stem.split(\"#\")[-1]))\n\n    # Checks if data is already there.\n    # If there is, loads it from the latest loaded file not to have to load unnecessary data\n    if path.exists() and not unification_from_scratch:\n        dd = datadict_from_hdf5(path, file_timeout=file_timeout)\n        if not dd.has_meta(\"last_reconstructed_file\"):\n            raise ValueError(\"The file does not have the meta data 'last_reconstructed_file', \"\n                             \"could not know where to reconstruct from.\")\n        last_reconstructed_file = Path(dd.meta_val(\"last_reconstructed_file\"))\n        if not last_reconstructed_file.exists() or last_reconstructed_file not in files:\n            raise ValueError(\"When reconstructing the data, could find the last reconstructed file. \"\n                             \"This indicates that something wrong happened in the tmp folder.\")\n        starting_index = files.index(last_reconstructed_file) + 1\n    else:\n        first = files.pop(0)\n        dd = datadict_from_hdf5(first, file_timeout=file_timeout)\n        starting_index = 0\n\n    for file in files[starting_index:]:\n        d = datadict_from_hdf5(file, file_timeout=file_timeout)\n        # Create a dictionary with just the keys and values to add to the original one.\n        dd.add_data(**{x[0]: d.data_vals(x[0]) for x in d.data_items()})\n\n    # Add shape to axes\n    for name, datavals in dd.data_items():\n        datavals[\"__shape__\"] = tuple(np.array(datavals[\"values\"][:]).shape,)\n\n    # Catches the edge case where there is a single file in the .tmp folder.\n    # This will not happen other than the first time, so it is ok to have that first variable there.\n    if len(files) &gt; 0:\n        dd.add_meta(\"last_reconstructed_file\", str(files[-1]))\n    else:\n        dd.add_meta(\"last_reconstructed_file\", str(first))\n\n    return dd\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.set_attr","title":"<code>set_attr(h5obj, name, val)</code>","text":"<p>Set attribute <code>name</code> of object <code>h5obj</code> to <code>val</code></p> <p>Use :func:<code>h5ify</code> to convert the object, then try to set the attribute to the returned value. If that does not succeed due to a HDF5 typing restriction, set the attribute to the string representation of the value.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def set_attr(h5obj: Any, name: str, val: Any) -&gt; None:\n    \"\"\"Set attribute `name` of object `h5obj` to `val`\n\n    Use :func:`h5ify` to convert the object, then try to set the attribute\n    to the returned value. If that does not succeed due to a HDF5 typing\n    restriction, set the attribute to the string representation of the value.\n    \"\"\"\n    try:\n        h5obj.attrs[name] = h5ify(val)\n    except TypeError:\n        newval = str(val)\n        h5obj.attrs[name] = h5ify(newval)\n</code></pre>"},{"location":"data/data_formats/#labcore.data.datadict_storage.timestamp_from_path","title":"<code>timestamp_from_path(p)</code>","text":"<p>Return a <code>datetime</code> timestamp from a standard-formatted path. Assumes that the path stem has a timestamp that begins in ISO-like format <code>YYYY-mm-ddTHHMMSS</code>.</p> Source code in <code>labcore/data/datadict_storage.py</code> <pre><code>def timestamp_from_path(p: Path) -&gt; datetime.datetime:\n    \"\"\"Return a `datetime` timestamp from a standard-formatted path.\n    Assumes that the path stem has a timestamp that begins in ISO-like format\n    ``YYYY-mm-ddTHHMMSS``.\n    \"\"\"\n    timestring = str(p.stem)[:13] + \":\" + str(p.stem)[13:15] + \":\" + str(p.stem)[15:17]\n    return datetime.datetime.fromisoformat(timestring)\n</code></pre>"},{"location":"data/data_formats/#extra-tools","title":"Extra Tools","text":""},{"location":"data/data_formats/#labcore.data.tools.Data","title":"<code>Data = Union[xr.Dataset, pd.DataFrame]</code>  <code>module-attribute</code>","text":"<p>Type alias for valid data. Can be either a pandas DataFrame or an xarray Dataset.</p>"},{"location":"data/data_formats/#labcore.data.tools.split_complex","title":"<code>split_complex(data)</code>","text":"<p>Split complex dependents into real and imaginary parts.</p> <p>TODO: should update units as well</p>"},{"location":"data/data_formats/#labcore.data.tools.split_complex--parameters","title":"Parameters","text":"<p>data     input data.</p>"},{"location":"data/data_formats/#labcore.data.tools.split_complex--returns","title":"Returns","text":"<p>data with complex dependents split into real and imaginary parts.</p>"},{"location":"data/data_formats/#labcore.data.tools.split_complex--raises","title":"Raises","text":"<p>NotImplementedError     if data is not a pandas DataFrame or an xarray Dataset.</p> Source code in <code>labcore/data/tools.py</code> <pre><code>def split_complex(data: Data) -&gt; Data:\n    \"\"\"Split complex dependents into real and imaginary parts.\n\n    TODO: should update units as well\n\n    Parameters\n    ----------\n    data\n        input data.\n\n    Returns\n    -------\n    data with complex dependents split into real and imaginary parts.\n\n    Raises\n    ------\n    NotImplementedError\n        if data is not a pandas DataFrame or an xarray Dataset.\n    \"\"\"\n    indep, dep = data_dims(data)\n\n    if not isinstance(data, pd.DataFrame) and not isinstance(data, xr.Dataset):\n        raise NotImplementedError\n\n    dropped = []\n    for d in dep:\n        if np.iscomplexobj(data[d]):\n            data[f\"{d}_Re\"] = np.real(data[d])\n            data[f\"{d}_Im\"] = np.imag(data[d])\n            if isinstance(data, xr.Dataset):\n                data[f\"{d}_Re\"].attrs = data[d].attrs\n                data[f\"{d}_Im\"].attrs = data[d].attrs\n            dropped.append(d)\n    if isinstance(data, pd.DataFrame):\n        return data.drop(columns=dropped)\n    else:\n        return data.drop_vars(dropped)\n</code></pre>"},{"location":"examples/Data%20explorer/","title":"Data explorer","text":"In\u00a0[1]: Copied! <pre>from datetime import datetime\nfrom pathlib import Path\n\nimport panel as pn\npn.extension()\n\nfrom labcore.analysis.hvapps import DataSelect, DDH5LoaderNode\n</pre> from datetime import datetime from pathlib import Path  import panel as pn pn.extension()  from labcore.analysis.hvapps import DataSelect, DDH5LoaderNode In\u00a0[8]: Copied! <pre>ds = DataSelect('.')\nds\n</pre> ds = DataSelect('.') ds Out[8]: <pre>BokehModel(combine_events=True, render_bundle={'docs_json': {'4ba4be42-b920-44e1-8cbf-4ad45ad05313': {'version\u2026</pre> <pre>(Event(what='value', name='selected_path', obj=DataSelect(name='DataSelect00920', selected_path=PosixPath('data/2023-11-16T073053_5d6e89ca-qA_power_rabi/data.ddh5')), cls=DataSelect(name='DataSelect00920', selected_path=PosixPath('data/2023-11-16T073053_5d6e89ca-qA_power_rabi/data.ddh5')), old=PosixPath('data/2023-11-16T073144_7bd68e94-qA_ssb_spec_pi/data.ddh5'), new=PosixPath('data/2023-11-16T073053_5d6e89ca-qA_power_rabi/data.ddh5'), type='changed'),)\n(Event(what='value', name='selected_path', obj=DataSelect(name='DataSelect00920', selected_path=PosixPath('data/2023-11-16T073053_5d6e89ca-qA_power_rabi/data.ddh5')), cls=DataSelect(name='DataSelect00920', selected_path=PosixPath('data/2023-11-16T073053_5d6e89ca-qA_power_rabi/data.ddh5')), old=PosixPath('data/2023-11-16T073053_5d6e89ca-qA_power_rabi/data.ddh5'), new=PosixPath('data/2023-11-16T073053_5d6e89ca-qA_power_rabi/data.ddh5'), type='changed'),)\n</pre> In\u00a0[11]: Copied! <pre>str(ds._data_select_widget.value)\n</pre> str(ds._data_select_widget.value) Out[11]: <pre>'data/2023-11-16T073144_7bd68e94-qA_ssb_spec_pi'</pre> In\u00a0[10]: Copied! <pre>m = pn.pane.Markdown(object='ABC')\nm\n</pre> m = pn.pane.Markdown(object='ABC') m Out[10]: <pre>BokehModel(combine_events=True, render_bundle={'docs_json': {'f60e57c0-79ba-4cdb-870a-8c0ae2ccef99': {'version\u2026</pre> In\u00a0[13]: Copied! <pre>def cb(*events):\n    for event in events:\n        print(event.new)\n\nwatcher = ds.param.watch(cb, ['selected_path'])\n</pre> def cb(*events):     for event in events:         print(event.new)  watcher = ds.param.watch(cb, ['selected_path']) In\u00a0[7]: Copied! <pre>ds._data_select_widget.link(m, value='object')\n</pre> ds._data_select_widget.link(m, value='object') Out[7]: <pre>Watcher(inst=Select(name='Data set', options=OrderedDict([(' 07:36:54 -...]), size=15, stylesheets=['\\n:host .bk-input {...], value=PosixPath('data/2023-11-16..., width=800), cls=&lt;class 'panel.widgets.select.Select'&gt;, fn=&lt;function Reactive.link.&lt;locals&gt;.link_cb at 0x7fd20429d480&gt;, mode='args', onlychanged=True, parameter_names=('value',), what='value', queued=False, precedence=0)</pre> In\u00a0[\u00a0]: Copied! <pre>def cb(*events):\n    print(events)\n\nwatcher = \n</pre> def cb(*events):     print(events)  watcher =  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[5]: Copied! <pre>loader = DDH5LoaderNode(ds.selected_path)\napp = pn.Column(\n    loader,\n    loader.plot,\n)\napp\n</pre> loader = DDH5LoaderNode(ds.selected_path) app = pn.Column(     loader,     loader.plot, ) app Out[5]: <pre>BokehModel(combine_events=True, render_bundle={'docs_json': {'3ffb4b51-541c-4b14-b0e4-a0d175595bb8': {'version\u2026</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/Holoviz-based%20plotting%20in%20the%20lab%20-%20Primer/","title":"Holoviz-based plotting in the lab - Primer","text":"<p>This notebook gives a brief intro to using holoviz-based plotting, incl our own tools that work with it.</p> <p>To make sure interactivity works correctly, run this notebook in an environment that has all the right stuff installed (i.e., your labcore environment)</p> In\u00a0[6]: Copied! <pre># first, make a dataset in datadict\nimport numpy as np\n\nfrom labcore.testing.dispersive_qubit_readout_data import chevron_dataset\n\nraw_data = chevron_dataset(\n    Omega_0=1e6,\n    Delta_vals=np.linspace(-1e6, 1e6, 20),\n    t_vals=np.linspace(0, 3e-6, 20),\n    n=20,  # number of shots\n)\n\ntype(raw_data), raw_data\n</pre> # first, make a dataset in datadict import numpy as np  from labcore.testing.dispersive_qubit_readout_data import chevron_dataset  raw_data = chevron_dataset(     Omega_0=1e6,     Delta_vals=np.linspace(-1e6, 1e6, 20),     t_vals=np.linspace(0, 3e-6, 20),     n=20,  # number of shots )  type(raw_data), raw_data Out[6]: <pre>(labcore.data.datadict.DataDict,\n signal: (400, 20)\n   \u2319 repetition: (400, 20)\n   \u2319 detuning (Hz): (400,)\n   \u2319 time (s): (400,))</pre> In\u00a0[3]: Copied! <pre># next -- convert into xarray. since we know its a nice regular grid, that's the easiest choice here.\nfrom labcore.data.datadict import datadict_to_meshgrid, dd2xr\nfrom labcore.data.tools import split_complex\n\n# with the holoviz (or all pydata) tools, complex data isn't always the best, so we split it immediately.\nxrdata = split_complex(\n    dd2xr(datadict_to_meshgrid(raw_data))\n)\nxrdata\n</pre> # next -- convert into xarray. since we know its a nice regular grid, that's the easiest choice here. from labcore.data.datadict import datadict_to_meshgrid, dd2xr from labcore.data.tools import split_complex  # with the holoviz (or all pydata) tools, complex data isn't always the best, so we split it immediately. xrdata = split_complex(     dd2xr(datadict_to_meshgrid(raw_data)) ) xrdata Out[3]: <pre>&lt;xarray.Dataset&gt;\nDimensions:     (repetition: 20, detuning: 20, time: 20)\nCoordinates:\n  * repetition  (repetition) int64 1 2 3 4 5 6 7 8 9 ... 13 14 15 16 17 18 19 20\n  * detuning    (detuning) float64 -1e+06 -8.947e+05 ... 8.947e+05 1e+06\n  * time        (time) float64 0.0 1.579e-07 3.158e-07 ... 2.842e-06 3e-06\nData variables:\n    signal_Re   (repetition, detuning, time) float64 2.085 1.837 ... 2.129 1.809\n    signal_Im   (repetition, detuning, time) float64 0.4333 0.4132 ... 0.618</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>repetition: 20</li><li>detuning: 20</li><li>time: 20</li></ul></li><li>Coordinates: (3)<ul><li>repetition(repetition)int641 2 3 4 5 6 7 ... 15 16 17 18 19 20<pre>array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n       19, 20])</pre></li><li>detuning(detuning)float64-1e+06 -8.947e+05 ... 1e+06<pre>array([-1000000.      ,  -894736.842105,  -789473.684211,  -684210.526316,\n        -578947.368421,  -473684.210526,  -368421.052632,  -263157.894737,\n        -157894.736842,   -52631.578947,    52631.578947,   157894.736842,\n         263157.894737,   368421.052632,   473684.210526,   578947.368421,\n         684210.526316,   789473.684211,   894736.842105,  1000000.      ])</pre></li><li>time(time)float640.0 1.579e-07 ... 2.842e-06 3e-06<pre>array([0.000000e+00, 1.578947e-07, 3.157895e-07, 4.736842e-07, 6.315789e-07,\n       7.894737e-07, 9.473684e-07, 1.105263e-06, 1.263158e-06, 1.421053e-06,\n       1.578947e-06, 1.736842e-06, 1.894737e-06, 2.052632e-06, 2.210526e-06,\n       2.368421e-06, 2.526316e-06, 2.684211e-06, 2.842105e-06, 3.000000e-06])</pre></li></ul></li><li>Data variables: (2)<ul><li>signal_Re(repetition, detuning, time)float642.085 1.837 1.817 ... 2.129 1.809<pre>array([[[ 2.0851939 ,  1.83727863,  1.81690448, ...,  2.56526006,\n          2.43875258,  2.58742792],\n        [ 1.62842295,  1.55057649, -0.02121912, ...,  0.14267972,\n          1.81500827,  2.38626988],\n        [ 1.3066802 ,  2.09997738, -0.38328366, ...,  1.87326002,\n          2.29177096,  1.68055914],\n        ...,\n        [ 2.65276905,  1.98888767,  0.2566441 , ..., -0.03979531,\n         -0.07094792,  1.78484301],\n        [ 2.00509194,  1.83970035,  1.70723588, ...,  0.09904967,\n          1.27428081,  1.50922241],\n        [ 2.71748561,  2.06437326, -0.06360528, ...,  1.57288186,\n          1.73186957,  2.57015356]],\n\n       [[ 1.9974292 ,  1.14630178, -0.37400418, ...,  1.9895205 ,\n          2.24054055,  1.76566939],\n        [ 2.04096079,  1.56035418,  0.08069875, ...,  2.01149441,\n          3.30612649,  2.26998237],\n        [ 1.26433686,  3.54597364, -0.34866773, ...,  0.12259455,\n          0.79041058,  1.28952712],\n...\n        [ 2.30030213,  1.01658706,  1.71381811, ...,  0.99411573,\n          2.16233766,  1.98668358],\n        [ 1.74576817,  2.11499347,  2.13085457, ...,  2.13709   ,\n          1.41863882,  2.97141426],\n        [ 2.19827526,  0.21545599,  0.98735214, ...,  2.65736886,\n          2.32386422,  2.20618771]],\n\n       [[ 1.8289988 ,  2.59407019, -0.24254022, ...,  1.03664099,\n          2.93782371,  2.21651199],\n        [ 1.32646094,  2.07718757, -0.4232972 , ...,  1.29332442,\n          2.06354481,  1.91395166],\n        [ 2.61670771,  1.28755507,  2.04907833, ...,  0.29563388,\n          1.67593694,  1.89946439],\n        ...,\n        [ 2.27551711,  2.6075095 ,  0.68144205, ...,  2.33161072,\n         -0.50588016,  1.94095499],\n        [ 1.92124748,  2.43519627,  0.45130262, ..., -0.11526138,\n          2.62476728,  2.84275303],\n        [ 2.30900089,  2.07135007,  1.68178912, ...,  0.19946094,\n          2.1294448 ,  1.80945159]]])</pre></li><li>signal_Im(repetition, detuning, time)float640.4333 0.4132 ... 0.5651 0.618<pre>array([[[ 4.33331976e-01,  4.13180700e-01,  7.19167793e-01, ...,\n         -7.55043555e-01,  5.64193310e-01, -1.97088202e-01],\n        [-1.54007804e-02,  1.11123945e-02,  2.63470278e+00, ...,\n          1.86262091e+00, -1.11053845e-01, -6.74806025e-01],\n        [-6.97373221e-01, -1.09999182e+00,  1.97304894e+00, ...,\n         -3.62671257e-01, -1.04984259e-01,  6.76603619e-01],\n        ...,\n        [ 2.72758276e-01, -6.68977378e-01,  1.36671376e+00, ...,\n          1.64056199e+00,  2.86257172e+00, -2.38564185e-03],\n        [-3.75613783e-01, -6.20009349e-01,  3.66205976e-01, ...,\n          2.13175017e+00,  3.27313501e-01, -2.94930669e-01],\n        [-7.22722183e-01, -3.09303221e-01,  1.63896237e+00, ...,\n          3.78687500e-01, -2.91357835e-01,  3.11283098e-01]],\n\n       [[-2.37387704e-01, -2.66721615e-01,  8.45059615e-01, ...,\n          3.16332567e-01, -1.28795901e-01, -1.60166878e-01],\n        [-2.25371161e-02, -3.53440534e-01,  2.56418621e+00, ...,\n          8.63708698e-01,  5.64639703e-02,  4.28550084e-01],\n        [ 7.63651604e-01,  5.60525287e-01,  2.26645695e+00, ...,\n          1.97589030e+00,  2.03954829e+00, -2.02848155e-01],\n...\n        [ 8.96788128e-01,  2.55030593e-01, -2.91397072e-01, ...,\n          3.06128869e-01,  6.63412542e-01,  5.38096369e-01],\n        [-2.62282977e-01,  6.88560027e-01,  2.35201411e-01, ...,\n          5.68684570e-02, -3.03798495e-01, -6.41625055e-01],\n        [ 5.16818301e-01,  1.92932353e+00, -7.44890272e-01, ...,\n         -7.87731533e-02,  4.77596691e-01, -1.67441382e-01]],\n\n       [[ 4.60202794e-01,  1.72346126e-01,  1.73976574e+00, ...,\n          1.58372237e-01,  9.49080071e-01,  4.20641983e-01],\n        [ 5.46535526e-01,  2.26097247e-01,  1.87478713e+00, ...,\n         -8.22224728e-01,  7.78867094e-01, -9.73560799e-01],\n        [ 1.47087110e-01,  2.65841275e-02, -1.33910428e-01, ...,\n          2.81750702e+00,  2.59548382e-01,  5.42427105e-01],\n        ...,\n        [ 9.80104391e-01, -4.86673487e-01,  1.75141841e+00, ...,\n          5.58410981e-02,  1.88475913e+00, -3.76147790e-01],\n        [ 3.20776538e-01, -7.45326801e-03,  1.78496994e+00, ...,\n          2.10680104e+00, -5.79809980e-01, -8.44912031e-01],\n        [-2.66867865e-01, -6.38558976e-01,  4.52101158e-01, ...,\n          1.85990760e+00,  5.65132230e-01,  6.18006842e-01]]])</pre></li></ul></li><li>Indexes: (3)<ul><li>repetitionPandasIndex<pre>PandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], dtype='int64', name='repetition'))</pre></li><li>detuningPandasIndex<pre>PandasIndex(Index([         -1000000.0,  -894736.8421052631,  -789473.6842105263,\n        -684210.5263157894,  -578947.3684210526, -473684.21052631584,\n         -368421.052631579, -263157.89473684214, -157894.73684210528,\n        -52631.57894736843,   52631.57894736831,  157894.73684210517,\n          263157.894736842,   368421.0526315789,   473684.2105263157,\n         578947.3684210526,   684210.5263157894,   789473.6842105263,\n         894736.8421052631,           1000000.0],\n      dtype='float64', name='detuning'))</pre></li><li>timePandasIndex<pre>PandasIndex(Index([                   0.0, 1.5789473684210527e-07, 3.1578947368421055e-07,\n        4.736842105263158e-07,  6.315789473684211e-07,  7.894736842105264e-07,\n        9.473684210526316e-07, 1.1052631578947369e-06, 1.2631578947368422e-06,\n       1.4210526315789475e-06, 1.5789473684210528e-06,  1.736842105263158e-06,\n       1.8947368421052632e-06, 2.0526315789473687e-06, 2.2105263157894738e-06,\n       2.3684210526315793e-06, 2.5263157894736844e-06, 2.6842105263157895e-06,\n        2.842105263157895e-06,                  3e-06],\n      dtype='float64', name='time'))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[4]: Copied! <pre># now we can directly use hvplot on this\nimport hvplot.xarray  # this import patches xarray objects so we can use hvplot on them.\n\n# plot: average over repetition, then plot the real part as 2d map.\nplot = xrdata.signal_Re.mean('repetition').hvplot.quadmesh(\n    x='detuning',\n    y='time',\n)\nplot\n</pre> # now we can directly use hvplot on this import hvplot.xarray  # this import patches xarray objects so we can use hvplot on them.  # plot: average over repetition, then plot the real part as 2d map. plot = xrdata.signal_Re.mean('repetition').hvplot.quadmesh(     x='detuning',     y='time', ) plot Out[4]: In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[5]: Copied! <pre># it's also pretty easy to make linecuts with sliders\n_data = xrdata.mean('repetition')\n\n# here: overlay line and scatter plot\n# can change x to get a different cut\nplot = _data.hvplot.line(x='time') * _data.hvplot.scatter(x='time')\nplot\n</pre> # it's also pretty easy to make linecuts with sliders _data = xrdata.mean('repetition')  # here: overlay line and scatter plot # can change x to get a different cut plot = _data.hvplot.line(x='time') * _data.hvplot.scatter(x='time') plot Out[5]: In\u00a0[7]: Copied! <pre># looking at readout histograms -- use simply all points in the set\n# hexbin is a very simple way to have a quick look at this. \n# doesn't offer too much control, but is \nxrdata.hvplot(\n    kind='hexbin',\n    aspect=1,\n    groupby=[],\n    x='signal_Re',\n    y='signal_Im',\n)\n</pre> # looking at readout histograms -- use simply all points in the set # hexbin is a very simple way to have a quick look at this.  # doesn't offer too much control, but is  xrdata.hvplot(     kind='hexbin',     aspect=1,     groupby=[],     x='signal_Re',     y='signal_Im', ) Out[7]: In\u00a0[8]: Copied! <pre># if we want to select based on some time/detuning values...\nxrdata.hvplot(\n    kind='hexbin',\n    aspect=1,\n    groupby=['time', 'detuning'],\n    x='signal_Re',\n    y='signal_Im',\n    xlim=(-3,3),\n    ylim=(-3,3)\n)\n</pre> # if we want to select based on some time/detuning values... xrdata.hvplot(     kind='hexbin',     aspect=1,     groupby=['time', 'detuning'],     x='signal_Re',     y='signal_Im',     xlim=(-3,3),     ylim=(-3,3) ) Out[8]: In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/Holoviz-based%20plotting%20in%20the%20lab%20-%20Primer/#holoviz-based-plotting-in-the-lab-primer","title":"Holoviz-based plotting in the lab - Primer\u00b6","text":""},{"location":"examples/Holoviz-based%20plotting%20in%20the%20lab%20-%20Primer/#some-basic-preliminaries","title":"Some basic preliminaries\u00b6","text":"<p>We assume that <code>raw</code> data is in DataDict formats. For processing and plotting we convert to either <code>pandas.DataFrame</code> (for ungridded data) or <code>xarray.Dataset</code> (for gridded data). This approach should be the general way we handle data in the lab.</p>"},{"location":"examples/Holoviz-based%20plotting%20in%20the%20lab%20-%20Primer/#brief-primer-on-vanilla-holoviz","title":"Brief primer on vanilla holoviz\u00b6","text":"<p>We have some tools on top of it for general easy data exploration.</p> <p>But for data analysis it's probably very wise for everyone to learn how to use holoviz directly. It allows making custom plots extremely easily.</p> <p>Docs are here: https://holoviz.org; see in particular <code>holoviews</code> and <code>hvplot</code>.</p> <p>Here is a very simple example -- we use synthetic Rabi/Chevron data for that. But much more is possible -- check out the examples in the documentation for how to do different things.</p>"},{"location":"examples/Intro%20to%20our%20Holoviz%20apps/","title":"Intro to our Holoviz apps","text":"In\u00a0[5]: Copied! <pre>import numpy as np\nimport xarray as xr\n\nimport panel as pn\npn.extension()\n\nfrom labcore.testing.dispersive_qubit_readout_data import chevron_dataset\nfrom labcore.data.datadict import datadict_to_meshgrid, dd2xr\nfrom labcore.analysis import split_complex\nfrom labcore.analysis.hvplotting import Node\n</pre> import numpy as np import xarray as xr  import panel as pn pn.extension()  from labcore.testing.dispersive_qubit_readout_data import chevron_dataset from labcore.data.datadict import datadict_to_meshgrid, dd2xr from labcore.analysis import split_complex from labcore.analysis.hvplotting import Node In\u00a0[7]: Copied! <pre># generate some generic Rabi-like data\nraw_data = chevron_dataset(\n    Omega_0=1e6,\n    Delta_vals=np.linspace(-1e6, 1e6, 20),\n    t_vals=np.linspace(0, 3e-6, 20),\n    n=100,  # number of shots\n)\n\n# convert directly to xarray.\n# also: with the holoviz (or all pydata) tools, complex data isn't always the most convenient, so we split it immediately.\nxrdata = split_complex(dd2xr(datadict_to_meshgrid(raw_data.expand())))\n</pre> # generate some generic Rabi-like data raw_data = chevron_dataset(     Omega_0=1e6,     Delta_vals=np.linspace(-1e6, 1e6, 20),     t_vals=np.linspace(0, 3e-6, 20),     n=100,  # number of shots )  # convert directly to xarray. # also: with the holoviz (or all pydata) tools, complex data isn't always the most convenient, so we split it immediately. xrdata = split_complex(dd2xr(datadict_to_meshgrid(raw_data.expand()))) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[8]: Copied! <pre>n = Node()\nn\n</pre> n = Node() n Out[8]: <p>Note: there is no input data, so we have also no output data:</p> In\u00a0[10]: Copied! <pre>n.data_out\n</pre> n.data_out <p>Now, let's set some data:</p> In\u00a0[13]: Copied! <pre>n.data_in = xrdata\nn.data_out\n</pre> n.data_in = xrdata n.data_out Out[13]: <pre>&lt;xarray.Dataset&gt;\nDimensions:     (repetition: 100, detuning: 20, time: 20)\nCoordinates:\n  * repetition  (repetition) int64 1 2 3 4 5 6 7 8 ... 93 94 95 96 97 98 99 100\n  * detuning    (detuning) float64 -1e+06 -8.947e+05 ... 8.947e+05 1e+06\n  * time        (time) float64 0.0 1.579e-07 3.158e-07 ... 2.842e-06 3e-06\nData variables:\n    signal_Re   (repetition, detuning, time) float64 2.394 2.416 ... 1.473 2.239\n    signal_Im   (repetition, detuning, time) float64 0.6124 0.5184 ... 0.7653</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>repetition: 100</li><li>detuning: 20</li><li>time: 20</li></ul></li><li>Coordinates: (3)<ul><li>repetition(repetition)int641 2 3 4 5 6 ... 95 96 97 98 99 100<pre>array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n        29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n        57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n        71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n        85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n        99, 100])</pre></li><li>detuning(detuning)float64-1e+06 -8.947e+05 ... 1e+06<pre>array([-1000000.      ,  -894736.842105,  -789473.684211,  -684210.526316,\n        -578947.368421,  -473684.210526,  -368421.052632,  -263157.894737,\n        -157894.736842,   -52631.578947,    52631.578947,   157894.736842,\n         263157.894737,   368421.052632,   473684.210526,   578947.368421,\n         684210.526316,   789473.684211,   894736.842105,  1000000.      ])</pre></li><li>time(time)float640.0 1.579e-07 ... 2.842e-06 3e-06<pre>array([0.000000e+00, 1.578947e-07, 3.157895e-07, 4.736842e-07, 6.315789e-07,\n       7.894737e-07, 9.473684e-07, 1.105263e-06, 1.263158e-06, 1.421053e-06,\n       1.578947e-06, 1.736842e-06, 1.894737e-06, 2.052632e-06, 2.210526e-06,\n       2.368421e-06, 2.526316e-06, 2.684211e-06, 2.842105e-06, 3.000000e-06])</pre></li></ul></li><li>Data variables: (2)<ul><li>signal_Re(repetition, detuning, time)float642.394 2.416 2.011 ... 1.473 2.239<pre>array([[[ 2.39429204,  2.41584085,  2.01070382, ...,  0.6793216 ,\n          2.40363714,  1.84911351],\n        [ 1.20058654,  0.38661186, -0.00937807, ...,  1.75357879,\n          1.54847952,  2.35827275],\n        [ 2.41412335,  0.45049803,  0.08999442, ..., -0.05222153,\n         -0.05433743,  2.42819182],\n        ...,\n        [ 1.43617869,  2.47237218,  0.49377027, ...,  0.45416915,\n          0.77174222,  1.61199389],\n        [ 2.72212855,  0.96724549, -0.07665558, ...,  0.55679343,\n         -0.13133571,  2.69979919],\n        [ 1.37780344,  2.39873711,  0.6753374 , ...,  2.84024508,\n          1.83308746,  1.35408574]],\n\n       [[ 1.61140291,  1.99985761,  1.71308173, ...,  1.12535782,\n          1.95211842,  0.04698709],\n        [ 1.38891653, -0.30882788, -0.68283045, ..., -0.41126179,\n          1.63722469,  2.20281887],\n        [ 1.85195278,  0.98095402,  2.86235175, ...,  2.85720975,\n          1.67642489,  2.02264347],\n...\n        [ 2.45424413,  1.97817553, -0.16036014, ...,  2.37403284,\n          2.1342944 ,  1.88157219],\n        [ 1.87642135,  1.44188519, -0.32405311, ...,  1.49219097,\n          2.01843329,  2.7472376 ],\n        [ 2.05309515,  2.81978425,  2.57091351, ...,  1.5781437 ,\n          1.94156871,  2.0546083 ]],\n\n       [[ 1.42775298,  1.63658385,  2.08598928, ...,  0.09562478,\n          2.36919346,  1.55970098],\n        [ 1.95123319,  0.09412897,  0.21869851, ...,  0.04774279,\n          1.94256876,  2.23526748],\n        [ 2.62100716,  2.13166133, -0.06878885, ...,  2.34982587,\n          1.69033609,  2.99005151],\n        ...,\n        [ 2.51083966,  2.14627053,  2.11965435, ..., -0.04852749,\n          1.82382828,  1.1774061 ],\n        [ 2.86878792,  2.27512861,  0.919346  , ..., -0.42102062,\n          2.25091241,  1.65840419],\n        [ 2.08326324,  1.61226336, -0.32004031, ...,  0.11225661,\n          1.47272199,  2.23852907]]])</pre></li><li>signal_Im(repetition, detuning, time)float640.6124 0.5184 ... 0.01058 0.7653<pre>array([[[ 6.12439108e-01,  5.18371782e-01,  5.37610698e-01, ...,\n          2.79891003e+00,  4.70894072e-01, -2.66921560e-01],\n        [ 6.08095583e-02,  2.14812469e+00,  2.51789045e+00, ...,\n         -5.32404394e-01, -2.21957557e-01,  1.32042513e-01],\n        [-3.56678744e-01,  1.55751874e-01,  2.55762606e+00, ...,\n          1.84020202e+00,  1.56732843e+00,  4.43405943e-01],\n        ...,\n        [-7.73251510e-01,  7.84068620e-01,  1.61664216e+00, ...,\n          2.53640404e+00,  2.42237481e+00,  3.89334112e-01],\n        [ 3.72180998e-01,  8.95917906e-01,  2.81327267e+00, ...,\n          2.34984038e+00,  1.87400679e+00,  3.01958223e-01],\n        [ 9.71940778e-01, -8.12839349e-02,  2.26240358e+00, ...,\n         -5.54946405e-01,  7.25710090e-01,  4.61186834e-01]],\n\n       [[ 2.30062557e-01, -5.39251607e-01, -1.49084643e-01, ...,\n          6.83342128e-02, -1.47124004e-01,  2.22704947e+00],\n        [-5.02726635e-01,  2.10082407e+00,  1.56912321e+00, ...,\n          2.24352756e+00, -5.49738010e-01, -4.31328129e-01],\n        [-2.28589141e-01, -8.25650541e-02, -2.82386289e-01, ...,\n         -2.54353554e-01, -6.60173598e-01,  1.86845278e-01],\n...\n        [-6.34680441e-02,  5.53216266e-01,  2.61957215e+00, ...,\n         -1.46180957e-01, -1.31822609e-01,  3.10733970e-02],\n        [-1.01504979e-01, -5.95690263e-01,  1.86810551e+00, ...,\n         -3.00842301e-03, -5.60020614e-01, -1.15270200e-01],\n        [ 6.96537377e-02, -2.65448933e-01, -8.67848943e-02, ...,\n          1.88832992e-02, -6.97018424e-02,  5.51572531e-01]],\n\n       [[ 5.77733932e-02,  4.49966193e-01, -3.17608069e-01, ...,\n          1.48937500e+00, -1.83142237e-01, -3.61452923e-01],\n        [-7.17090804e-01,  1.73602557e+00,  1.66805554e+00, ...,\n          2.81057648e+00, -2.38979670e-01, -1.40718115e-01],\n        [ 1.31608837e-01,  7.38725888e-02,  2.17430591e+00, ...,\n         -1.21735869e-01, -1.54676491e-01,  2.60753912e-01],\n        ...,\n        [-2.24798920e-01, -4.30408288e-01,  2.20729028e-02, ...,\n          1.31371250e+00,  1.70229825e-01, -2.13814390e-01],\n        [-7.78459016e-02,  3.62070825e-01,  2.51885359e+00, ...,\n          1.14211801e+00,  9.91125450e-02, -5.20870902e-01],\n        [-5.15084296e-01, -3.80074990e-01,  1.40922337e+00, ...,\n          2.06647356e+00,  1.05807313e-02,  7.65276896e-01]]])</pre></li></ul></li><li>Indexes: (3)<ul><li>repetitionPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n        29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n        57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n        71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n        85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n        99, 100],\n      dtype='int64', name='repetition'))</pre></li><li>detuningPandasIndex<pre>PandasIndex(Index([         -1000000.0,  -894736.8421052631,  -789473.6842105263,\n        -684210.5263157894,  -578947.3684210526, -473684.21052631584,\n         -368421.052631579, -263157.89473684214, -157894.73684210528,\n        -52631.57894736843,   52631.57894736831,  157894.73684210517,\n          263157.894736842,   368421.0526315789,   473684.2105263157,\n         578947.3684210526,   684210.5263157894,   789473.6842105263,\n         894736.8421052631,           1000000.0],\n      dtype='float64', name='detuning'))</pre></li><li>timePandasIndex<pre>PandasIndex(Index([                   0.0, 1.5789473684210527e-07, 3.1578947368421055e-07,\n        4.736842105263158e-07,  6.315789473684211e-07,  7.894736842105264e-07,\n        9.473684210526316e-07, 1.1052631578947369e-06, 1.2631578947368422e-06,\n       1.4210526315789475e-06, 1.5789473684210528e-06,  1.736842105263158e-06,\n       1.8947368421052632e-06, 2.0526315789473687e-06, 2.2105263157894738e-06,\n       2.3684210526315793e-06, 2.5263157894736844e-06, 2.6842105263157895e-06,\n        2.842105263157895e-06,                  3e-06],\n      dtype='float64', name='time'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <p>OK, not very exciting yet. But internally stuff has happened -- the data went through the processing routine, and the output of that routine is now available as output data.</p> <p>Note: we always look at the data and plot it; that holds for every node. When we embed the <code>.plot</code> object into a viewable (like a panel layout) we get our custom plot app we can use to slice our data.</p> In\u00a0[17]: Copied! <pre>pn.Column(\n    n.plot\n)\n</pre> pn.Column(     n.plot ) Out[17]: In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[18]: Copied! <pre>from labcore.data.datadict import DataDict\nfrom labcore.analysis.hvplotting import LoaderNodeBase\n\nclass RabiSimulation(LoaderNodeBase):\n    def load_data(self) -&gt; DataDict:\n        Omega_0 = 1\n        Delta_vals = np.linspace(-2, 2, 20)\n        t_vals = np.linspace(0, 3, 20)\n        nreps = 10\n        dd = chevron_dataset(Omega_0, Delta_vals, t_vals, nreps).expand()\n        return dd\n\ns = RabiSimulation(name='sim')\napp = pn.Column(\n    s,\n    s.plot,\n)\napp\n</pre> from labcore.data.datadict import DataDict from labcore.analysis.hvplotting import LoaderNodeBase  class RabiSimulation(LoaderNodeBase):     def load_data(self) -&gt; DataDict:         Omega_0 = 1         Delta_vals = np.linspace(-2, 2, 20)         t_vals = np.linspace(0, 3, 20)         nreps = 10         dd = chevron_dataset(Omega_0, Delta_vals, t_vals, nreps).expand()         return dd  s = RabiSimulation(name='sim') app = pn.Column(     s,     s.plot, ) app Out[18]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/Intro%20to%20our%20Holoviz%20apps/#intro-to-our-holoviz-apps","title":"Intro to our Holoviz apps\u00b6","text":""},{"location":"examples/Intro%20to%20our%20Holoviz%20apps/#nodes","title":"Nodes\u00b6","text":"<p>let's have a look at what <code>Node</code>s are. To work with them, we create some dummy data.</p>"},{"location":"examples/Intro%20to%20our%20Holoviz%20apps/#a-trivial-example","title":"A trivial example\u00b6","text":"<p>By default, nodes don't do anything but pass data around between them if they're connected correctly. In this example we just create a node and display it. Nothing is seen...</p>"},{"location":"examples/Intro%20to%20our%20Holoviz%20apps/#a-basic-loader-node","title":"A basic loader node\u00b6","text":"<p>Loaders are specific nodes that load data. That means, they do not have any input data, only output data. Every loader node must have a method <code>load_data</code> that returns a <code>DataDict</code>.</p> <p>The base class for loaders already comes with a set of preprocessing options: averaging over dimension that can be specified (you have to type in the name, and it'll average over it if it's there), auto-gridding, and auto-refresh.</p> <p>In the example below, you can either load a freshly generated set of data by pressing the Load Data button, or repeatedly by setting Auto-refresh to some value (disabling will stop it).</p> <p>TODO Stuff that's been set on the dimension sliders is currently being reset everytime the data is reloaded.</p>"},{"location":"examples/Introduction%20to%20sweeping/","title":"Init","text":"In\u00a0[1]: Copied! <pre># %load_ext autoreload\n# %autoreload 2\n</pre> # %load_ext autoreload # %autoreload 2 In\u00a0[1]: Copied! <pre>from pprint import pprint\nimport numpy as np\nimport qcodes as qc\n\nfrom labcore.measurement import *\n</pre> from pprint import pprint import numpy as np import qcodes as qc  from labcore.measurement import * <p>The way we would like to measure looks something like this:</p> <pre>    &gt;&gt;&gt; m = Measurement(\n    ...     sweep_object,\n    ...     setup=setup_function,\n    ...     finish=teardown_function,\n    ... )\n    ... m.run(**config_options)\n</pre> <p>The reason why we would like to define the measurement in an object is to be able to have access to main characteristics (such as the type of data acquired during the run) in advance, before any measurement code is executed. This will also be useful for serializing measurements.</p> <p>The most tricky aspect here is to define what the <code>sweep</code> object is. Often we define the flow in an experiment by directly using for-loops and the like. But that will not allow us the desired goals. We need to come up with an object-based description that makes the essence of the flow clear without executing it.</p> <ul> <li><p>a sweep object can be iterated over. each step performs some actions, and returns some data. that means, we want to be able to use it as follows.  We call the dictionary that is produced for each step a record.</p> <pre>  &gt;&gt;&gt; for data in sweep_object:\n  ...    print(data)\n  {variable_1: some_data, variable_2: more_data}\n  {variable_1: different_data, variable_2: more_different_data}\n</pre> </li> <li><p>a sweep object is defined by a pointer and 0 or more actions.</p> <ul> <li>A pointer is again an iterable, and the coordinates it traverses may or may not be known in advance.</li> <li>Actions are callables that may take the values the pointer is returning at each iteration as arguments. Each action is executed once for each pointer.</li> </ul> <p>A simple sweep can then be defined like this:</p> <pre>    &gt;&gt;&gt; sweep_object = Sweep(range(5), func_1, func_2)\n</pre> <p>Executing this sweep will loop over the range, and will then call <code>func_1(i)</code> and subsequently <code>func_2(i)</code>, for each <code>i</code> in the range from 0 to 4.</p> </li> <li><p>Sweeps can be combined in ways that result in nesting, zipping, or appending. Combining sweeps again results in a sweep. This will allow us to construct modular measurements from pre-defined blocks.</p> </li> <li><p>After definition, but before execution, we can easily infer what records the sweep produces.</p> </li> </ul> <p>In the following first look a prototypical measurement protocol. After that we have a closer look at individual components.</p> <p>Lets say we have the following task:</p> <ol> <li>our basic measurement is to record the phase as a function of frequency (for instance with a VNA)</li> <li>we do this as function of some other parameter that tunes something in the experiment (maybe a voltage)</li> <li>finally, we need to average out some slow noise, so we repeat everything some number of times</li> <li>the tuning might heat up the sample, so we want to keep an eye on it. We want to measure the fridge temperature once per repetition.</li> </ol> <p>Being good with organizing our tools and prefering a modular way of putting together measurements, we have already defined the main building blocks so we can re-use them. They might even be located in some module that import for a particular class of experiments.</p> <p>The functions that return data we want to save later are decorated with <code>recording</code>, to describe what kind of data they produce. (Note: the decorator is not necessary; we can also use the function <code>record_as</code>, as we'll see below)</p> In\u00a0[2]: Copied! <pre># these are just some dummy functions that follow the recipe outlined above.\n\ndef tune_something(param):\n    print(f'adjusting something in-situ using param={param}')\n\n@recording(\n    independent('frq', type='array', unit='Hz'), \n    dependent('phase', depends_on=['frq'], type='array', unit='rad')\n)\ndef measure_frequency_trace(npoints=3):\n    return np.arange(1,npoints+1)*1e6, np.random.normal(size=npoints)\n\n\n@recording(dependent('temperature', unit='K'))\ndef measure_temperature():\n    return np.random.normal(loc=0.1, scale=0.01)\n</pre> # these are just some dummy functions that follow the recipe outlined above.  def tune_something(param):     print(f'adjusting something in-situ using param={param}')  @recording(     independent('frq', type='array', unit='Hz'),      dependent('phase', depends_on=['frq'], type='array', unit='rad') ) def measure_frequency_trace(npoints=3):     return np.arange(1,npoints+1)*1e6, np.random.normal(size=npoints)   @recording(dependent('temperature', unit='K')) def measure_temperature():     return np.random.normal(loc=0.1, scale=0.01) <p>We now use these functions to assemble the measurement loop. It works like this:</p> <ul> <li>The matrix multiplication operator <code>@</code> creates a nested loop of sweeps (the outer loop are the repetitions, the inner loop the tuning of the parameter).</li> <li>The multiplication operator <code>*</code> is like an inner product (or zip), i.e., results in element-wise combination. That is, for each value of <code>param</code> we run <code>measure_frequency_trace</code>.</li> <li>The addition operator <code>+</code> appends sweeps or actions to sweeps. I.e., <code>measure_temperature</code> is executed once after each <code>param</code> sweep.</li> </ul> <p>Finally, we can, even without running any measurement code, already look at the data that the loop will produce.</p> In\u00a0[3]: Copied! <pre>sweep = (\n    sweep_parameter('repetition', range(3))\n    @ (sweep_parameter('param', range(3), tune_something)\n       * measure_frequency_trace\n       + measure_temperature)\n)\n\npprint(sweep.get_data_specs())\nprint()\n</pre> sweep = (     sweep_parameter('repetition', range(3))     @ (sweep_parameter('param', range(3), tune_something)        * measure_frequency_trace        + measure_temperature) )  pprint(sweep.get_data_specs()) print() <pre>(repetition, param, frq, phase(repetition, param, frq), temperature(repetition))\n\n</pre> <p>Running the sweep is very easy -- we can simply iterate over it. Each sweep coordinate produces a data set that by default contains everything that has been annotated as recording data (the <code>sweep_parameter</code> function implicitly generates a record for the parameter that is being varied).</p> In\u00a0[4]: Copied! <pre>for data in sweep:\n    print(data)\n</pre> for data in sweep:     print(data) <pre>adjusting something in-situ using param=0\n{'repetition': 0, 'param': 0, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 0.89408564, -1.78220988, -0.03659925]), 'temperature': None}\nadjusting something in-situ using param=1\n{'repetition': 0, 'param': 1, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 2.03131721,  0.40310144, -1.1691722 ]), 'temperature': None}\nadjusting something in-situ using param=2\n{'repetition': 0, 'param': 2, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 0.39590923, -0.74580651, -0.48511114]), 'temperature': None}\n{'repetition': 0, 'param': None, 'frq': None, 'phase': None, 'temperature': 0.1269433488426204}\nadjusting something in-situ using param=0\n{'repetition': 1, 'param': 0, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 0.7951673 ,  0.74914095, -0.12481228]), 'temperature': None}\nadjusting something in-situ using param=1\n{'repetition': 1, 'param': 1, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 0.72542661, -0.07237564,  0.20433795]), 'temperature': None}\nadjusting something in-situ using param=2\n{'repetition': 1, 'param': 2, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 1.68295933,  0.44069152, -2.13190624]), 'temperature': None}\n{'repetition': 1, 'param': None, 'frq': None, 'phase': None, 'temperature': 0.09588440739380934}\nadjusting something in-situ using param=0\n{'repetition': 2, 'param': 0, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 0.30728013, -0.57762722, -1.49087012]), 'temperature': None}\nadjusting something in-situ using param=1\n{'repetition': 2, 'param': 1, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 0.9391771 , -0.1194195 , -0.93337162]), 'temperature': None}\nadjusting something in-situ using param=2\n{'repetition': 2, 'param': 2, 'frq': array([1000000., 2000000., 3000000.]), 'phase': array([ 0.10980382, -0.46763241,  1.62517513]), 'temperature': None}\n{'repetition': 2, 'param': None, 'frq': None, 'phase': None, 'temperature': 0.12279970580903614}\n</pre> <p>Sweeps are often done over qcodes parameters, and the data we acquire may also come from parameters.</p> <p>In this minimal example we set a parameter (<code>x</code>) to a range of values, and get data from another parameter for each set value.</p> In\u00a0[5]: Copied! <pre>from qcodes import Parameter\n\ndef measure_stuff():\n    return np.random.normal()\n\nx = Parameter('x', set_cmd=lambda x: print(f'setting x to {x}'), initial_value=0)\ndata = Parameter('data', get_cmd=lambda: np.random.normal())\n\nfor record in sweep_parameter(x, range(3), get_parameter(data)):\n    print(record)\n</pre> from qcodes import Parameter  def measure_stuff():     return np.random.normal()  x = Parameter('x', set_cmd=lambda x: print(f'setting x to {x}'), initial_value=0) data = Parameter('data', get_cmd=lambda: np.random.normal())  for record in sweep_parameter(x, range(3), get_parameter(data)):     print(record) <pre>setting x to 0\nsetting x to 0\n{'x': 0, 'data': -0.7198138975798806}\nsetting x to 1\n{'x': 1, 'data': -0.012136113084703805}\nsetting x to 2\n{'x': 2, 'data': 0.7356664798447984}\n</pre> <p>The main ingredients for a single sweep is 1) a pointer iterable, and 2) a variable number of actions to execute at each iteration step. Both pointer and actions may generate records.</p> <p>The most bare example would look something like this:</p> In\u00a0[6]: Copied! <pre>for data in Sweep(range(3)):\n    print(data)\n</pre> for data in Sweep(range(3)):     print(data) <pre>{}\n{}\n{}\n</pre> <p>We loop over the iterable, but only empty records are generated.</p> <p>We can use <code>record_as</code> to indicate that generated values should be recorded:</p> In\u00a0[7]: Copied! <pre>def my_func():\n    return 0\n\nsweep = Sweep(\n    record_as(range(3), independent('x')), # this is the pointer. We specify 'x' as an independent (we control it)\n    record_as(my_func, 'y') # y is not declared as independent; \n                            # dependent (on what it depends is partially determined by the sweep) is the default.\n)\n\npprint(sweep.get_data_specs())\n\nfor data in sweep:\n    print(data)\n</pre> def my_func():     return 0  sweep = Sweep(     record_as(range(3), independent('x')), # this is the pointer. We specify 'x' as an independent (we control it)     record_as(my_func, 'y') # y is not declared as independent;                              # dependent (on what it depends is partially determined by the sweep) is the default. )  pprint(sweep.get_data_specs())  for data in sweep:     print(data) <pre>(x, y(x))\n{'x': 0, 'y': 0}\n{'x': 1, 'y': 0}\n{'x': 2, 'y': 0}\n</pre> <p>A more convenient way of doing exactly the same thing:</p> In\u00a0[8]: Copied! <pre>sweep = sweep_parameter('x', range(3), record_as(my_func, 'y'))\n\nfor data in sweep:\n    print(data)\n</pre> sweep = sweep_parameter('x', range(3), record_as(my_func, 'y'))  for data in sweep:     print(data) <pre>{'x': 0, 'y': 0}\n{'x': 1, 'y': 0}\n{'x': 2, 'y': 0}\n</pre> <p>Elements can also produce records with multiple parameters:</p> In\u00a0[9]: Copied! <pre>def my_func():\n    return 1, 2\n\nsweep = Sweep(\n    record_as(zip(range(3), ['a', 'b', 'c']), independent('number'), independent('string')), # a pointer with two parameters\n    record_as(my_func, 'one', 'two')\n)\n\npprint(sweep.get_data_specs())\n\nfor data in sweep:\n    print(data)\n</pre> def my_func():     return 1, 2  sweep = Sweep(     record_as(zip(range(3), ['a', 'b', 'c']), independent('number'), independent('string')), # a pointer with two parameters     record_as(my_func, 'one', 'two') )  pprint(sweep.get_data_specs())  for data in sweep:     print(data) <pre>(number, string, one(number, string), two(number, string))\n{'number': 0, 'string': 'a', 'one': 1, 'two': 2}\n{'number': 1, 'string': 'b', 'one': 1, 'two': 2}\n{'number': 2, 'string': 'c', 'one': 1, 'two': 2}\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Many functions we are using take optional parameters we only want to specify just before executing the sweep (but are constant throughout the sweep).</p> <p>If we don't want to resort to global variables we can do so by using <code>Sweep.set_action_opts</code>. It accepts the names of action functions as keywords, and dictionaries containing keyword arguments to pass to those functions as value. Keywords specified in this way always override key words that are passed around internally in the sweep (See further below for an explanation on how parameters are passed internally).</p> In\u00a0[30]: Copied! <pre>def test_fun(value, a_property=0):\n    print('inside test_fun:')\n    print(f\"value: {value}, property: {a_property}\")\n    print()\n    return value\n\ndef another_fun(another_value, *args, **kwargs):\n    print('inside another_fun:')\n    print(f\"my value: {another_value}\")\n    print(f\"other stuff:\", args, kwargs)\n    print()\n\nsweep_1 = sweep_parameter('value', range(3), record_as(test_fun, dependent('data')))\nsweep_2 = sweep_parameter('another_value', range(2), another_fun)\n\nsweep = (\n    sweep_1\n    @ sweep_2\n)\n\nsweep.set_options(\n    test_fun = dict(a_property=1),\n    another_fun = dict(another_value='Hello', another_property=True)\n)\n\nfor data in sweep:\n    print(\"Data:\", data)\n    print()\n</pre> def test_fun(value, a_property=0):     print('inside test_fun:')     print(f\"value: {value}, property: {a_property}\")     print()     return value  def another_fun(another_value, *args, **kwargs):     print('inside another_fun:')     print(f\"my value: {another_value}\")     print(f\"other stuff:\", args, kwargs)     print()  sweep_1 = sweep_parameter('value', range(3), record_as(test_fun, dependent('data'))) sweep_2 = sweep_parameter('another_value', range(2), another_fun)  sweep = (     sweep_1     @ sweep_2 )  sweep.set_options(     test_fun = dict(a_property=1),     another_fun = dict(another_value='Hello', another_property=True) )  for data in sweep:     print(\"Data:\", data)     print() <pre>inside test_fun:\nvalue: 0, property: 1\n\ninside another_fun:\nmy value: Hello\nother stuff: () {'value': 0, 'data': 0, 'another_property': True}\n\nData: {'value': 0, 'data': 0, 'another_value': 0}\n\ninside another_fun:\nmy value: Hello\nother stuff: () {'value': 0, 'data': 0, 'another_property': True}\n\nData: {'value': 0, 'data': 0, 'another_value': 1}\n\ninside test_fun:\nvalue: 1, property: 1\n\ninside another_fun:\nmy value: Hello\nother stuff: () {'value': 1, 'data': 1, 'another_property': True}\n\nData: {'value': 1, 'data': 1, 'another_value': 0}\n\ninside another_fun:\nmy value: Hello\nother stuff: () {'value': 1, 'data': 1, 'another_property': True}\n\nData: {'value': 1, 'data': 1, 'another_value': 1}\n\ninside test_fun:\nvalue: 2, property: 1\n\ninside another_fun:\nmy value: Hello\nother stuff: () {'value': 2, 'data': 2, 'another_property': True}\n\nData: {'value': 2, 'data': 2, 'another_value': 0}\n\ninside another_fun:\nmy value: Hello\nother stuff: () {'value': 2, 'data': 2, 'another_property': True}\n\nData: {'value': 2, 'data': 2, 'another_value': 1}\n\n</pre> <p>A simple example for how to append sweeps to each other. The <code>sweep_parameter</code> function creates a 1D sweep over a parameter that we can specify just with a name. It will automatically result in a returned record with that name when it is set.</p> <p>We create two sweeps that consist of a parameter sweep and an action that returns a random number as dependent variable. The sweep parameter will automatically be inserted as a dependency in that case. Here, the annotation of the return data is done using <code>record_as</code>. This allows us to use the same function twice with different return data names.</p> <p>We finally attach another function call to the sweep. It is executed only once at the very end (internally it's made into a 'null sweep'). It is also not annotated at all, so won't record any data.</p> <p>Note: <code>Sweep.return_none</code> controls whether we include data fields that have returned nothing during setting a pointer or executing an action. It can be set on the class or the instance of a particular sweep. Setting it to true (the default) guarantees that each data spec of the sweep has an entry per sweep point, even if it is <code>None</code>.</p> In\u00a0[11]: Copied! <pre>def get_random_number():\n    return np.random.rand()\n\ndef get_another_random_number():\n    print('rolling the dice!')\n    return np.random.rand()\n\n\n# change this to see what happens.\nSweep.record_none = False\n\nsweep_1 = sweep_parameter('x', range(3), record_as(get_random_number, dependent('y')))\nsweep_2 = sweep_parameter('a', range(4), record_as(get_random_number, dependent('b')))\n\nfor data in sweep_1 + sweep_2 + get_another_random_number:\n    print(data)\n    \n# just to set it back for the other examples\nSweep.record_none = True\n</pre> def get_random_number():     return np.random.rand()  def get_another_random_number():     print('rolling the dice!')     return np.random.rand()   # change this to see what happens. Sweep.record_none = False  sweep_1 = sweep_parameter('x', range(3), record_as(get_random_number, dependent('y'))) sweep_2 = sweep_parameter('a', range(4), record_as(get_random_number, dependent('b')))  for data in sweep_1 + sweep_2 + get_another_random_number:     print(data)      # just to set it back for the other examples Sweep.record_none = True <pre>{'x': 0, 'y': 0.9687729205561979}\n{'x': 1, 'y': 0.4434610036271559}\n{'x': 2, 'y': 0.7991319563194824}\n{'a': 0, 'b': 0.7989985780105594}\n{'a': 1, 'b': 0.9542764680604046}\n{'a': 2, 'b': 0.016014756874430325}\n{'a': 3, 'b': 0.5827642622420539}\nrolling the dice!\n{}\n</pre> <p>By multiplying we refer to an inner product, i.e., the result is basically what you'd expect from <code>zip</code>-ing two iterables.</p> <p>Simplest case: we have a sweep and want to attach another action to each sweep point:</p> In\u00a0[12]: Copied! <pre>sweep = (\n    sweep_parameter('x', range(3), record_as(get_random_number, dependent('data_1')))\n    * record_as(get_random_number, dependent('data_2'))\n)\n\npprint(sweep.get_data_specs())\nprint()\n\nfor data in sweep:\n    print(data)\n</pre> sweep = (     sweep_parameter('x', range(3), record_as(get_random_number, dependent('data_1')))     * record_as(get_random_number, dependent('data_2')) )  pprint(sweep.get_data_specs()) print()  for data in sweep:     print(data) <pre>(x, data_1(x), data_2(x))\n\n{'x': 0, 'data_1': 0.9369037617368199, 'data_2': 0.5595742250611065}\n{'x': 1, 'data_1': 0.06516845680757466, 'data_2': 0.9516372937866395}\n{'x': 2, 'data_1': 0.34547840652874906, 'data_2': 0.4447657956353076}\n</pre> <p>If the two objects we want to combine are both sweeps, then we get zip-like behavior (and dependencies stay separate).</p> In\u00a0[13]: Copied! <pre>sweep = (\n    sweep_parameter('x', range(3), record_as(get_random_number, dependent('data_1')))\n    * sweep_parameter('y', range(5), record_as(get_random_number, dependent('data_2')))\n)\n\npprint(sweep.get_data_specs())\nprint()\n\nfor data in sweep:\n    print(data)\n</pre> sweep = (     sweep_parameter('x', range(3), record_as(get_random_number, dependent('data_1')))     * sweep_parameter('y', range(5), record_as(get_random_number, dependent('data_2'))) )  pprint(sweep.get_data_specs()) print()  for data in sweep:     print(data) <pre>(x, data_1(x), y, data_2(y))\n\n{'x': 0, 'data_1': 0.6517601377057347, 'y': 0, 'data_2': 0.015530741822005312}\n{'x': 1, 'data_1': 0.9097117607352513, 'y': 1, 'data_2': 0.7423884916639105}\n{'x': 2, 'data_1': 0.40946649898624865, 'y': 2, 'data_2': 0.9181472371035658}\n</pre> <p>The most simple example:</p> <p>Sweep parameters (say, 'x', 'y', and 'z') against each other, and perform a measurement at each point. For syntactic brevity we're using the matrix multiplication ('@') operator for nesting (you can also use <code>labcore.measurement.sweep.nest_sweeps</code>).</p> In\u00a0[14]: Copied! <pre>@recording(dependent('my_data'))\ndef measure_something():\n    return np.random.rand()\n\nmy_sweep = (\n    sweep_parameter('x', range(3)) \n    @ sweep_parameter('y', np.linspace(0,1,3))\n    @ sweep_parameter('z', range(-5, -2))\n    @ measure_something\n)\n\nfor data in my_sweep:\n    print(data)\n</pre> @recording(dependent('my_data')) def measure_something():     return np.random.rand()  my_sweep = (     sweep_parameter('x', range(3))      @ sweep_parameter('y', np.linspace(0,1,3))     @ sweep_parameter('z', range(-5, -2))     @ measure_something )  for data in my_sweep:     print(data) <pre>{'x': 0, 'y': 0.0, 'z': -5, 'my_data': 0.47353193015484174}\n{'x': 0, 'y': 0.0, 'z': -4, 'my_data': 0.40909548872169266}\n{'x': 0, 'y': 0.0, 'z': -3, 'my_data': 0.2887164655738411}\n{'x': 0, 'y': 0.5, 'z': -5, 'my_data': 0.22061258119580063}\n{'x': 0, 'y': 0.5, 'z': -4, 'my_data': 0.6509422045598774}\n{'x': 0, 'y': 0.5, 'z': -3, 'my_data': 0.045451454297620986}\n{'x': 0, 'y': 1.0, 'z': -5, 'my_data': 0.45433695172994093}\n{'x': 0, 'y': 1.0, 'z': -4, 'my_data': 0.9701096584234756}\n{'x': 0, 'y': 1.0, 'z': -3, 'my_data': 0.8099880589060339}\n{'x': 1, 'y': 0.0, 'z': -5, 'my_data': 0.90471234702373}\n{'x': 1, 'y': 0.0, 'z': -4, 'my_data': 0.4098835565833152}\n{'x': 1, 'y': 0.0, 'z': -3, 'my_data': 0.5401028037551512}\n{'x': 1, 'y': 0.5, 'z': -5, 'my_data': 0.42093875192378905}\n{'x': 1, 'y': 0.5, 'z': -4, 'my_data': 0.35074624010110955}\n{'x': 1, 'y': 0.5, 'z': -3, 'my_data': 0.20451480949590906}\n{'x': 1, 'y': 1.0, 'z': -5, 'my_data': 0.9761882331945407}\n{'x': 1, 'y': 1.0, 'z': -4, 'my_data': 0.9084876764306075}\n{'x': 1, 'y': 1.0, 'z': -3, 'my_data': 0.07699555004515124}\n{'x': 2, 'y': 0.0, 'z': -5, 'my_data': 0.8068526683340999}\n{'x': 2, 'y': 0.0, 'z': -4, 'my_data': 0.20795196032405305}\n{'x': 2, 'y': 0.0, 'z': -3, 'my_data': 0.27873785786468197}\n{'x': 2, 'y': 0.5, 'z': -5, 'my_data': 0.9547886815867028}\n{'x': 2, 'y': 0.5, 'z': -4, 'my_data': 0.3428051725706732}\n{'x': 2, 'y': 0.5, 'z': -3, 'my_data': 0.1381437598605173}\n{'x': 2, 'y': 1.0, 'z': -5, 'my_data': 0.6873739735255319}\n{'x': 2, 'y': 1.0, 'z': -4, 'my_data': 0.33974736653496396}\n{'x': 2, 'y': 1.0, 'z': -3, 'my_data': 0.7680863529816836}\n</pre> <p>The outer loops can be more complex sweeps as well -- for example, we can also execute measurements on each nesting level.</p> In\u00a0[15]: Copied! <pre>def measure_something():\n    return np.random.rand()\n\nsweep_1 = sweep_parameter('x', range(3), record_as(measure_something, 'a'))\nsweep_2 = sweep_parameter('y', range(4), record_as(measure_something, 'b'))\n\nfor data in sweep_1 @ sweep_2 @ record_as(get_random_number, 'more_data'):\n    print(data)\n</pre> def measure_something():     return np.random.rand()  sweep_1 = sweep_parameter('x', range(3), record_as(measure_something, 'a')) sweep_2 = sweep_parameter('y', range(4), record_as(measure_something, 'b'))  for data in sweep_1 @ sweep_2 @ record_as(get_random_number, 'more_data'):     print(data) <pre>{'x': 0, 'a': 0.14798648471552067, 'y': 0, 'b': 0.85181779143027, 'more_data': 0.04760130402551599}\n{'x': 0, 'a': 0.14798648471552067, 'y': 1, 'b': 0.6936892585093728, 'more_data': 0.3022591474797921}\n{'x': 0, 'a': 0.14798648471552067, 'y': 2, 'b': 0.5703084895756598, 'more_data': 0.306778684213204}\n{'x': 0, 'a': 0.14798648471552067, 'y': 3, 'b': 0.48382890498908726, 'more_data': 0.8693224030983092}\n{'x': 1, 'a': 0.43161622927739274, 'y': 0, 'b': 0.29284100013745995, 'more_data': 0.029904832942683646}\n{'x': 1, 'a': 0.43161622927739274, 'y': 1, 'b': 0.6155091075616117, 'more_data': 0.9386751305041878}\n{'x': 1, 'a': 0.43161622927739274, 'y': 2, 'b': 0.02910600115117823, 'more_data': 0.4508315971185247}\n{'x': 1, 'a': 0.43161622927739274, 'y': 3, 'b': 0.7310670947737475, 'more_data': 0.5215169146689735}\n{'x': 2, 'a': 0.4025748067429352, 'y': 0, 'b': 0.09713497018638206, 'more_data': 0.02374119489672022}\n{'x': 2, 'a': 0.4025748067429352, 'y': 1, 'b': 0.13888810375672433, 'more_data': 0.9239587154375959}\n{'x': 2, 'a': 0.4025748067429352, 'y': 2, 'b': 0.04421346905020085, 'more_data': 0.41418277108350077}\n{'x': 2, 'a': 0.4025748067429352, 'y': 3, 'b': 0.8246263996276458, 'more_data': 0.7581821041086125}\n</pre> <p>A not uncommon task in quantum circuits:</p> <ol> <li>sweep some parameter. We're interested in some response of the system on this parameter.</li> <li>Hovewer, changing this parameter changes an operation point of our sample. To deal with this we need to perform an auxiliary measurement, and based on its result we set some other parameter. (A familiar case: we increase a drive power that is expected to have some effect on a qubit. But after changing the power we need to first find the readout resonator frequency because of the changed Stark shift.)</li> <li>After this 'calibration step' we can now measure the response we're actually looking for.</li> </ol> <p>Further, we want to record not only the data that is taken in the last step, but also the calibration data.</p> <p>All together this leads us to a measurement structure as below. As before, the building blocks are modular and relatively self-contained, and might be part of some package.</p> <p>The data this will produce is two records per sweep parameter (<code>x</code>, creatively): one that contains the calibration measurement and result, and one for the actual measurement.</p> In\u00a0[16]: Copied! <pre>@recording(\n    independent('readout_probe_points', type='array'),\n    dependent('readout_probe_response', type='array', depends_on=['readout_probe_points']),\n    dependent('readout_point')  # note: we don't make this dependent on readout_probe_points\n)\ndef calibrate_readout():\n    \"\"\"An example for a readout calibration.\"\"\"\n    pts = np.linspace(0, 1, 3)\n    response = np.random.normal(size=3, scale=10)\n    result = response.max()  # some analysis of the calibration measurement\n    return pts, response, result\n    \n\ndef set_operation_point(value):\n    print(f'setting the readout point to {value}')\n    \n\n# the actual measurement function accepts the argument `readout_point` which will be passed from the calibration.\n@recording(\n    independent('probe_frequency', type='array'),\n    dependent('probe_response', type='array', depends_on=['probe_frequency']),\n)\ndef perform_measurement(readout_point):\n    set_operation_point(readout_point)\n    return np.arange(3)+10, np.random.normal(size=3, loc=readout_point)\n\n# because of the way brackets are set here, we need to make a sweep out of the calibrate_readout \n# function. this is easily done with the 'once' function, which creates a length-1 sweep with no additional \n# return data.\nsweep = (\n    sweep_parameter('x', range(3))\n    @ (once(calibrate_readout) + perform_measurement)\n)\n\nfor data in sweep:\n    pprint(data)\n</pre> @recording(     independent('readout_probe_points', type='array'),     dependent('readout_probe_response', type='array', depends_on=['readout_probe_points']),     dependent('readout_point')  # note: we don't make this dependent on readout_probe_points ) def calibrate_readout():     \"\"\"An example for a readout calibration.\"\"\"     pts = np.linspace(0, 1, 3)     response = np.random.normal(size=3, scale=10)     result = response.max()  # some analysis of the calibration measurement     return pts, response, result       def set_operation_point(value):     print(f'setting the readout point to {value}')       # the actual measurement function accepts the argument `readout_point` which will be passed from the calibration. @recording(     independent('probe_frequency', type='array'),     dependent('probe_response', type='array', depends_on=['probe_frequency']), ) def perform_measurement(readout_point):     set_operation_point(readout_point)     return np.arange(3)+10, np.random.normal(size=3, loc=readout_point)  # because of the way brackets are set here, we need to make a sweep out of the calibrate_readout  # function. this is easily done with the 'once' function, which creates a length-1 sweep with no additional  # return data. sweep = (     sweep_parameter('x', range(3))     @ (once(calibrate_readout) + perform_measurement) )  for data in sweep:     pprint(data) <pre>{'probe_frequency': None,\n 'probe_response': None,\n 'readout_point': 9.902716831014812,\n 'readout_probe_points': array([0. , 0.5, 1. ]),\n 'readout_probe_response': array([ 4.18671719, -0.64338861,  9.90271683]),\n 'x': 0}\nsetting the readout point to 9.902716831014812\n{'probe_frequency': array([10, 11, 12]),\n 'probe_response': array([ 8.50247593,  9.33888991, 11.44649896]),\n 'readout_point': None,\n 'readout_probe_points': None,\n 'readout_probe_response': None,\n 'x': 0}\n{'probe_frequency': None,\n 'probe_response': None,\n 'readout_point': 9.152387414440057,\n 'readout_probe_points': array([0. , 0.5, 1. ]),\n 'readout_probe_response': array([ -1.38415022,   9.15238741, -23.15551414]),\n 'x': 1}\nsetting the readout point to 9.152387414440057\n{'probe_frequency': array([10, 11, 12]),\n 'probe_response': array([9.55336264, 9.91959456, 8.41813702]),\n 'readout_point': None,\n 'readout_probe_points': None,\n 'readout_probe_response': None,\n 'x': 1}\n{'probe_frequency': None,\n 'probe_response': None,\n 'readout_point': 11.221415238459393,\n 'readout_probe_points': array([0. , 0.5, 1. ]),\n 'readout_probe_response': array([11.22141524,  4.30442778,  9.18277042]),\n 'x': 2}\nsetting the readout point to 11.221415238459393\n{'probe_frequency': array([10, 11, 12]),\n 'probe_response': array([10.71310701, 10.29105064, 11.82850645]),\n 'readout_point': None,\n 'readout_probe_points': None,\n 'readout_probe_response': None,\n 'x': 2}\n</pre> In\u00a0[17]: Copied! <pre>pprint(sweep.get_data_specs())\n</pre> pprint(sweep.get_data_specs()) <pre>(x,\n readout_probe_points,\n readout_probe_response(x, readout_probe_points),\n readout_point(x),\n probe_frequency,\n probe_response(x, probe_frequency))\n</pre> <p>These are just some snippets that show how we can annotate records and what the results are.</p> <p>Without record annotations sweeps still are executed, but no data is recorded:</p> In\u00a0[18]: Copied! <pre>sweep_object = Sweep(range(3), lambda x: np.random.normal(size=x))\nfor data in sweep_object:\n    print(data)\n</pre> sweep_object = Sweep(range(3), lambda x: np.random.normal(size=x)) for data in sweep_object:     print(data) <pre>{}\n{}\n{}\n</pre> <p>The underlying object we use for declaring data returns is <code>DataSpec</code>. <code>ds</code> is just a shortcut that points to its constructor.</p> <p><code>independent</code> (or <code>indep</code>) is creates a DataSpec with <code>depends_on=None</code>, and <code>dependent</code> creates a DataSpec with <code>depends_on=[]</code>. If <code>depends_on</code> is <code>None</code>, it will remain independent even when the annotated object is embedded in larger structures. If it is <code>[]</code> then more dependencies are added automatically.</p> In\u00a0[19]: Copied! <pre># defining some example measurement functions without short-hand notations\n\n@recording(DataSpec('x'), DataSpec('y', depends_on=['x'], type='array'))\ndef measure_stuff(n, *args, **kwargs):\n    return n, np.random.normal(size=n)\n\n@recording(ds('a'))\ndef set_stuff(x, *args, **kwargs):\n    return x\n\nmeasure_stuff(1), set_stuff(1)\n</pre> # defining some example measurement functions without short-hand notations  @recording(DataSpec('x'), DataSpec('y', depends_on=['x'], type='array')) def measure_stuff(n, *args, **kwargs):     return n, np.random.normal(size=n)  @recording(ds('a')) def set_stuff(x, *args, **kwargs):     return x  measure_stuff(1), set_stuff(1) Out[19]: <pre>({'x': 1, 'y': array([1.13945709])}, {'a': 1})</pre> <p>Generators can also be annotated to produce data.</p> In\u00a0[20]: Copied! <pre>@recording(ds('a'))\ndef make_sequence(n):\n    for i in range(n):\n        yield i\n        \nfor data in make_sequence(3):\n    print(data)\n</pre> @recording(ds('a')) def make_sequence(n):     for i in range(n):         yield i          for data in make_sequence(3):     print(data) <pre>{'a': 0}\n{'a': 1}\n{'a': 2}\n</pre> <p>Using <code>record_as</code> is a practical way of annotating records just before executing, independently of an earlier function definition. This works with functions and generators as well.</p> In\u00a0[21]: Copied! <pre>def get_some_data(n):\n    return np.random.normal(size=n)\n\nrecord_as(get_some_data, ds('random_var'))(3)\n</pre> def get_some_data(n):     return np.random.normal(size=n)  record_as(get_some_data, ds('random_var'))(3) Out[21]: <pre>{'random_var': array([-0.13268483,  0.98189131,  0.36335112])}</pre> <p>record also provides a simple short hand for labelling regular iterables and iterators: it automatically removes surplus values, and always returns values for all specified data, even if the annotated object does not return in (missing values will be <code>None</code>)</p> In\u00a0[22]: Copied! <pre>for data in record_as(zip(np.linspace(0,1,6), np.arange(6)), ds('x')):\n    print(data)\n    \nfor data in record_as(zip(np.linspace(0,1,6), np.arange(6)), ds('x'), ds('y')):\n    print(data)\n    \nfor data in record_as(np.linspace(0,1,6), ds('x'), ds('y')):\n    print(data)\n</pre> for data in record_as(zip(np.linspace(0,1,6), np.arange(6)), ds('x')):     print(data)      for data in record_as(zip(np.linspace(0,1,6), np.arange(6)), ds('x'), ds('y')):     print(data)      for data in record_as(np.linspace(0,1,6), ds('x'), ds('y')):     print(data) <pre>{'x': 0.0}\n{'x': 0.2}\n{'x': 0.4}\n{'x': 0.6000000000000001}\n{'x': 0.8}\n{'x': 1.0}\n{'x': 0.0, 'y': 0}\n{'x': 0.2, 'y': 1}\n{'x': 0.4, 'y': 2}\n{'x': 0.6000000000000001, 'y': 3}\n{'x': 0.8, 'y': 4}\n{'x': 1.0, 'y': 5}\n{'x': 0.0, 'y': None}\n{'x': 0.2, 'y': None}\n{'x': 0.4, 'y': None}\n{'x': 0.6000000000000001, 'y': None}\n{'x': 0.8, 'y': None}\n{'x': 1.0, 'y': None}\n</pre> <p>Everything that is generated by functions (or pointers and sweeps) can in principle be passed on to subsequently executed elements.</p> <p>When there's no record annotations arguments may still be passed as positional arguments:</p> In\u00a0[23]: Copied! <pre>def test(*args, **kwargs):\n    print(args, kwargs)\n    return 100\n    \nfor data in Sweep(range(3), test):\n    print(data)\n</pre> def test(*args, **kwargs):     print(args, kwargs)     return 100      for data in Sweep(range(3), test):     print(data) <pre>(0,) {}\n{}\n(1,) {}\n{}\n(2,) {}\n{}\n</pre> <p>Because it would get too confusing otherwise, positional arguments only get passed originating from a pointer to all actions in a single sweep. In the following example the two <code>test</code> functions in the first sweep are passed the same integer, whereas the function in the second sweep is only receiving (<code>x</code>, <code>True</code>) or (<code>y</code>, <code>False</code>). Note that the return of <code>test</code> is not passed to any other object.</p> In\u00a0[24]: Copied! <pre>for data in Sweep(range(3), test, test) * Sweep(zip(['x', 'y'], [True, False]), test):\n    print(data)\n</pre> for data in Sweep(range(3), test, test) * Sweep(zip(['x', 'y'], [True, False]), test):     print(data) <pre>(0,) {}\n(0,) {}\n('x', True) {}\n{}\n(1,) {}\n(1,) {}\n('y', False) {}\n{}\n(2,) {}\n(2,) {}\n</pre> <p>In the previous example, <code>test</code> received any arguments passed to it because its signature included variational positional arguments (<code>*args</code>). The situation changes when this is not the case. The function is receiving only arguments that it can accept.</p> In\u00a0[25]: Copied! <pre>def test_2(x=2):\n    print(x)\n    return True\n\nfor data in Sweep(zip([1,2], [3,4]), test_2):\n    pass\n</pre> def test_2(x=2):     print(x)     return True  for data in Sweep(zip([1,2], [3,4]), test_2):     pass <pre>1\n2\n</pre> <p>We are more flexible when we use keyword arguments. Here, the rule is:</p> <ol> <li>All records produced are passed to all subsequent functions in the sweep (even across different sub-sweeps!) that accept the keyword.</li> <li>If a pointer yields non-annotated values, these are still used as positional arguments, but only where accepted, and with higher priority given to keywords.</li> <li>using <code>lambda</code> and <code>record_as</code> allow pretty simple translation of records and argument names to avoid conflicts.</li> <li>some elementary control over passing behavior is provided by <code>Sweep.pass_on_returns</code> and <code>Sweep.pass_on_none</code>.<ol> <li><code>Sweep.pass_on_returns</code> defaults to <code>True</code>. If set to <code>False</code>, nothing will be passed on.</li> <li><code>Sweep.pass_on_none</code> defaults to <code>False</code>. If set to <code>False</code> the behavior is such that records that are <code>None</code> will not be passed on further. (Because <code>None</code> is typically indicating that function did not return anything as data even though a record was declard using <code>recording</code> or <code>record_as</code>).</li> <li>Note: At the moment we can set those only globally using the class attribute; a likely update in the future.</li> </ol> </li> </ol> <p>Some examples:</p> In\u00a0[26]: Copied! <pre>def test(x, y, z=5):\n    print(\"my three arguments:\", x, y, z)\n    return x, y, z\n\ndef print_all_args(*args, **kwargs):\n    print(\"arguments at the end of the line:\", args, kwargs)\n    \n    \nfor data in sweep_parameter('x', range(3), test):\n    print(\"data:\", data)\n    \nprint()\nsweep = (\n    sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))\n    @ print_all_args\n)\nfor data in sweep:\n    print(\"data:\", data)\n    \nprint()\nsweep = (\n    sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))\n    @ record_as(lambda xx, yy, zz: test(xx, yy, zz), dependent('some'), dependent('different'), dependent('names'))\n    @ print_all_args\n    + print_all_args\n)\nfor data in sweep:\n    print(\"data:\", data)\n</pre> def test(x, y, z=5):     print(\"my three arguments:\", x, y, z)     return x, y, z  def print_all_args(*args, **kwargs):     print(\"arguments at the end of the line:\", args, kwargs)           for data in sweep_parameter('x', range(3), test):     print(\"data:\", data)      print() sweep = (     sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))     @ print_all_args ) for data in sweep:     print(\"data:\", data)      print() sweep = (     sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))     @ record_as(lambda xx, yy, zz: test(xx, yy, zz), dependent('some'), dependent('different'), dependent('names'))     @ print_all_args     + print_all_args ) for data in sweep:     print(\"data:\", data) <pre>my three arguments: 0 None 5\ndata: {'x': 0}\nmy three arguments: 1 None 5\ndata: {'x': 1}\nmy three arguments: 2 None 5\ndata: {'x': 2}\n\nmy three arguments: None 0 5\narguments at the end of the line: () {'y': 0, 'yy': 0, 'zz': 5}\ndata: {'y': 0, 'xx': None, 'yy': 0, 'zz': 5}\nmy three arguments: None 1 5\narguments at the end of the line: () {'y': 1, 'yy': 1, 'zz': 5}\ndata: {'y': 1, 'xx': None, 'yy': 1, 'zz': 5}\nmy three arguments: None 2 5\narguments at the end of the line: () {'y': 2, 'yy': 2, 'zz': 5}\ndata: {'y': 2, 'xx': None, 'yy': 2, 'zz': 5}\n\nmy three arguments: None 0 5\nmy three arguments: None 0 5\narguments at the end of the line: () {'y': 0, 'yy': 0, 'zz': 5, 'different': 0, 'names': 5}\ndata: {'y': 0, 'xx': None, 'yy': 0, 'zz': 5, 'some': None, 'different': 0, 'names': 5}\nmy three arguments: None 1 5\nmy three arguments: None 1 5\narguments at the end of the line: () {'y': 1, 'yy': 1, 'zz': 5, 'different': 1, 'names': 5}\ndata: {'y': 1, 'xx': None, 'yy': 1, 'zz': 5, 'some': None, 'different': 1, 'names': 5}\nmy three arguments: None 2 5\nmy three arguments: None 2 5\narguments at the end of the line: () {'y': 2, 'yy': 2, 'zz': 5, 'different': 2, 'names': 5}\ndata: {'y': 2, 'xx': None, 'yy': 2, 'zz': 5, 'some': None, 'different': 2, 'names': 5}\narguments at the end of the line: () {'y': 2, 'yy': 2, 'zz': 5, 'different': 2, 'names': 5}\ndata: {'y': None, 'xx': None, 'yy': None, 'zz': None, 'some': None, 'different': None, 'names': None}\n</pre> In\u00a0[27]: Copied! <pre>Sweep.pass_on_returns = False\n\nsweep = (\n    sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))\n    @ print_all_args\n)\nfor data in sweep:\n    print(\"data:\", data)\n\n# setting back to default\nSweep.pass_on_returns = True\n</pre> Sweep.pass_on_returns = False  sweep = (     sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))     @ print_all_args ) for data in sweep:     print(\"data:\", data)  # setting back to default Sweep.pass_on_returns = True <pre>my three arguments: None None 5\narguments at the end of the line: () {}\ndata: {'y': 0, 'xx': None, 'yy': None, 'zz': 5}\nmy three arguments: None None 5\narguments at the end of the line: () {}\ndata: {'y': 1, 'xx': None, 'yy': None, 'zz': 5}\nmy three arguments: None None 5\narguments at the end of the line: () {}\ndata: {'y': 2, 'xx': None, 'yy': None, 'zz': 5}\n</pre> In\u00a0[28]: Copied! <pre>Sweep.pass_on_none = True\n\nsweep = (\n    sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))\n    @ print_all_args\n)\n\nfor data in sweep:\n    print(\"data:\", data)\n    \n# setting back to default\nSweep.pass_on_none = False\n</pre> Sweep.pass_on_none = True  sweep = (     sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))     @ print_all_args )  for data in sweep:     print(\"data:\", data)      # setting back to default Sweep.pass_on_none = False <pre>my three arguments: None 0 5\narguments at the end of the line: (None,) {'y': 0, 'xx': None, 'yy': 0, 'zz': 5}\ndata: {'y': 0, 'xx': None, 'yy': 0, 'zz': 5}\nmy three arguments: None 1 5\narguments at the end of the line: (None,) {'y': 1, 'xx': None, 'yy': 1, 'zz': 5}\ndata: {'y': 1, 'xx': None, 'yy': 1, 'zz': 5}\nmy three arguments: None 2 5\narguments at the end of the line: (None,) {'y': 2, 'xx': None, 'yy': 2, 'zz': 5}\ndata: {'y': 2, 'xx': None, 'yy': 2, 'zz': 5}\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/Introduction%20to%20sweeping/#init","title":"Init\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#intro","title":"Intro\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#main-requirements-for-sweeps","title":"Main requirements for sweeps\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#examples","title":"Examples\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#jumping-right-in","title":"Jumping right in\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#a-prototypical-slightly-non-trivial-measurement-protocol","title":"A prototypical, slightly non-trivial measurement protocol\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#a-qcodes-parameter-sweep","title":"A QCoDeS parameter sweep\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#constructing-single-sweeps","title":"Constructing single sweeps\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#specifying-options-before-executing-a-sweep","title":"Specifying options before executing a sweep\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#appending","title":"Appending\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#multiplying","title":"Multiplying\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#nesting-sweeps","title":"Nesting sweeps\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#combining-operators-and-more-complex-constructs","title":"Combining operators and more complex constructs\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#looking-a-bit-deeper","title":"Looking a bit deeper\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#annotating-objects-for-recording","title":"Annotating objects for recording\u00b6","text":""},{"location":"examples/Introduction%20to%20sweeping/#passing-parameters-in-a-sweep","title":"Passing parameters in a sweep\u00b6","text":""},{"location":"examples/hvplot_visualization_guide/","title":"Pretty hvplot and exporting","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nfrom labcore.analysis.hv_pretty import setup_plotting, format_ax, add_legend, correctly_sized_figure, set_arial_font, save_plot_as_png\n</pre> import numpy as np import pandas as pd from labcore.analysis.hv_pretty import setup_plotting, format_ax, add_legend, correctly_sized_figure, set_arial_font, save_plot_as_png  In\u00a0[2]: Copied! <pre>df = pd.DataFrame({\n    'x': np.linspace(0, 10, 100),\n    'y': np.sin(np.linspace(0, 10, 100))\n})\n\n# Setup styling\nsetup_plotting()\n\n# Create plot\nplot = df.hvplot.line(x='x', y='y', label='sin(x)', line_width=2, color='crimson')\n\n# Apply formatting\nplot = format_ax(plot, title='Sine Wave', xlabel='X', ylabel='Y',\n                 fontsize=32, title_fontsize=48, tick_fontsize=32)\n\n# Add legend (if overlayed)\nplot = add_legend(plot)\n\n# Set size\nplot = plot.opts(**correctly_sized_figure(2.75, 1.5))\n\n# Set font\nplot = plot.opts(hooks=[set_arial_font])\n\nplot\n</pre> df = pd.DataFrame({     'x': np.linspace(0, 10, 100),     'y': np.sin(np.linspace(0, 10, 100)) })  # Setup styling setup_plotting()  # Create plot plot = df.hvplot.line(x='x', y='y', label='sin(x)', line_width=2, color='crimson')  # Apply formatting plot = format_ax(plot, title='Sine Wave', xlabel='X', ylabel='Y',                  fontsize=32, title_fontsize=48, tick_fontsize=32)  # Add legend (if overlayed) plot = add_legend(plot)  # Set size plot = plot.opts(**correctly_sized_figure(2.75, 1.5))  # Set font plot = plot.opts(hooks=[set_arial_font])  plot  Out[2]: In\u00a0[3]: Copied! <pre>save_plot_as_png(\n    plot=plot,\n    filename=\"sine_wave.png\",\n    width_in=2.75,\n    height_in=1.5,\n    dpi=300\n)\n</pre> save_plot_as_png(     plot=plot,     filename=\"sine_wave.png\",     width_in=2.75,     height_in=1.5,     dpi=300 ) In\u00a0[9]: Copied! <pre># Create sample data\ndf = pd.DataFrame({\n    'x': np.linspace(0, 10, 100),\n    'y1': np.sin(np.linspace(0, 10, 100)),\n    'y2': np.cos(np.linspace(0, 10, 100))\n})\n\n# Create two separate line plots with labels\nline1 = df.hvplot.line(x='x', y='y1', label='Sine Wave')\nline2 = df.hvplot.line(x='x', y='y2', label='Cosine Wave')\n\nsetup_plotting()\n\n# Overlay both lines\noverlay = line1 * line2\n\noverlay = add_legend(overlay, location='top_left', show=True)\noverlay.opts(**correctly_sized_figure(2.75, 1.5))\noverlay.opts(hooks=[set_arial_font])\noverlay = format_ax(overlay, title='Sine Wave', xlabel='X', ylabel='Y',\n                 fontsize=18, title_fontsize=24, tick_fontsize=18)\noverlay\n</pre> # Create sample data df = pd.DataFrame({     'x': np.linspace(0, 10, 100),     'y1': np.sin(np.linspace(0, 10, 100)),     'y2': np.cos(np.linspace(0, 10, 100)) })  # Create two separate line plots with labels line1 = df.hvplot.line(x='x', y='y1', label='Sine Wave') line2 = df.hvplot.line(x='x', y='y2', label='Cosine Wave')  setup_plotting()  # Overlay both lines overlay = line1 * line2  overlay = add_legend(overlay, location='top_left', show=True) overlay.opts(**correctly_sized_figure(2.75, 1.5)) overlay.opts(hooks=[set_arial_font]) overlay = format_ax(overlay, title='Sine Wave', xlabel='X', ylabel='Y',                  fontsize=18, title_fontsize=24, tick_fontsize=18) overlay Out[9]: In\u00a0[30]: Copied! <pre>save_plot_as_png(\n    plot=overlay,\n    filename=\"sincos_wave.png\",\n    width_in=2.75,\n    height_in=1.5,\n    dpi=300\n)\n</pre> save_plot_as_png(     plot=overlay,     filename=\"sincos_wave.png\",     width_in=2.75,     height_in=1.5,     dpi=300 )"},{"location":"instruments/instrumentmonitoring/","title":"Instrument Monitoring","text":"<p>The following is a guide to set up a dashboard for the monitoring of instruments. It contains capabilities for data storage, data visualization, and real-time alerts. More information on the tool is provided in the next section.</p> <p>Note</p> <p>The following guide assumes the user has the instrumentserver installed and has basic familiarity with it and using config files, labcore installed, basic familiarity with Docker, and a basic understanding of what Grafana and InfluxDB are</p>"},{"location":"instruments/instrumentmonitoring/#overview","title":"Overview","text":"<p>This tool is designed to be able to facilitate the monitoring of instruments. It consists of multiple parts that must be set up:</p> <p></p> <p>Above is a diagram showcasing the architecture for a dashboard for the monitoring of two separate instruments. The architecture consists of two PCs that communicate with the instrument using qCoDeS, which broadcast the data they receive to a central computer where the dashboard is hosted.</p> <p>Docker</p> <p>Docker is the service used to host Grafana and InfluxDB locally. Both of the services have a server that runs inside of a Docker container on your internet-connected device, and will be accessible through the network the computer is connected to. Both Influx and Grafana will be accessible with an internet connection to the computer running Docker.</p> <p>Grafana</p> <p>Grafana is the service used to visualize the data gathered from your instrument(s) of choice. It has functionality to both have visualization through dashboards, and also alerting capabilities through Slack integration and more. Below is an example of what a Grafana dashboard may look like.</p> <p>Grafana is hosted locally on a internet-connected device, and can then be viewed while connected to the network and logging in to your Grafana account. It will live in a Docker container. (More on that later)</p> <p></p> <p>Below is a sample alert send out by Grafana on Slack. The alert notifies that a parameter (in this case MC) has passed a threshold. This is for a dilution refrigerator, and the parameter in this case is a value from a temperature sensor. This one, MC, is in the mixing chamber.</p> <p></p> <p>InfluxDB</p> <p>InfluxDB is the database used to store data fetched from instruments. It stores the data in time-series format (each data point has a time). It can then be accessed by Grafana in order to construct time-series plots of the various parameters in the database (as shown above).</p> <p>InfluxDB should be hosted on the same device as Grafana. It will also be in a Docker container. (again, more on that later)</p> <p>The Instrumentserver</p> <p>The instrumentserver runs on a computer that can talk with your instrument through a network connection. The instrumentserver will ask your instrument for the data you specify, which will then be sent back to the instrumentserver by the instrument.</p> <p>Based on a yaml config file, the instrumentserver can then ask for the correct data from the instrument and broadcast it to the internet (to be used for visualizations).</p> <p>In the instrumentserver, for each instrument, the user provides a list of parameters to get values or states from, with a corresponding rate (in seconds) for how often to poll the parameter.</p> <p>The Listener</p> <p>The listener is ran on the same computer that is running the Docker containers for Grafana and InfluxDB. It subscribes to the broadcasts from the instrumentservers, and then writes the data to the InfluxDB database. The listener can also be configured to write to a CSV file, however InfluxDB is recommended.</p> <p>Note</p> <p>The following portion assumes the user has the instrumentserver installed and labcore installed.</p>"},{"location":"instruments/instrumentmonitoring/#quick-start-guide","title":"Quick Start Guide","text":"<p>This section is a guide to quickly set up an instrument monitoring dashboard for an arbitrary number of instruments.</p>"},{"location":"instruments/instrumentmonitoring/#step-1-instrumentserver-setup","title":"Step 1: Instrumentserver setup","text":"<p>First, locate or create a qCoDeS driver for your instrument. Also, make sure the instrument is connected to some sort of network (generally a switch), and find its IP address on the private network. Also, locate the correct port to communicate with the instrument (generally found in the manual for the instrument).</p> <p>Once you have all of this information, set up a PC (windows, linux, etc.) that is connected to the same network (switch) as the instrument you want to monitor. Install the instrumentserver and labcore on this PC.</p> <p>Decide on a port you want to broadcast data through on the PC. Then create a config file for the instrumentserver using the above qCoDeS driver, ports, etc. Check out the section for the instrumentserver config file.</p> <p>Then, start the instrumentserver. See starting the instrumentserver.</p>"},{"location":"instruments/instrumentmonitoring/#step-2-influxdb-and-grafana","title":"Step 2: InfluxDB and Grafana","text":"<p>Set up a PC that you would like to host the dashboard on. Install labcore and the instrumentserver on this PC. Install docker and start the docker engine. Follow the docker section to set up a docker compose file. Make sure that InfluxDB and Grafana are able to be accessed.</p>"},{"location":"instruments/instrumentmonitoring/#step-3-the-listener","title":"Step 3: The Listener","text":"<p>On the same PC that Grafana and Influx were started on:</p> <p>Keep track of the address and port that the instrumentserver is broadcasting to in the previous section. Use this information, the information you used to set up InfluxDB, plus the parameters you want to monitor to fill out the config file.</p> <p>You can then start the listener.</p>"},{"location":"instruments/instrumentmonitoring/#step-4-grafana-customization","title":"Step 4: Grafana Customization","text":"<p>If the previous steps were done correctly with no issues, the Influx database should start to be populated. Then, one can follow the guide at https://grafana.com/grafana/dashboards/ in order to create a dashboard using InfluxDB as data source. The grafana documentation also has guides on setting up alerting to Slack and other services.</p>"},{"location":"instruments/instrumentmonitoring/#the-instrumentserver","title":"The Instrumentserver","text":"<p>In order to use the dashboard, we will need to have an instance of the instrumentserver running to fetch data from the fridge computer. </p>"},{"location":"instruments/instrumentmonitoring/#config-file","title":"Config File","text":"<p>Below is an example instrumentserver configuration file that can be used for the dashboard.</p> <pre><code>instruments:\n\n  fridge_nh:\n    type: labcore.instruments.qcodes_drivers.Oxford.triton.OxfordTriton\n    address: 192.168.1.1\n    init: \n      port: 33576\n      temp_channel_mapping:\n          T1: \"PT2_HEAD\"\n          T2: \"PT2_PLATE\"\n          T3: \"STILL_PLATE\"\n          T4: \"COLD_PLATE\"\n          T6: \"PT1_HEAD\"\n          T7: \"PT1_PLATE\"\n          T8: \"MC_PLATE_RUO2\"\n\n    pollingRate:\n      comp_state: 15\n      PT1_PLATE: 15\n      PT2_PLATE: 15\n      STILL_PLATE: 15\n      COLD_PLATE: 15\n      MC_PLATE_RUO2: 15\n      turb1_state: 15\n      turb1_speed: 15\n\nnetworking:\n  externalBroadcast: \"tcp://128.174.123.123:6000\"\n</code></pre> <p>As usual, we declare an qCoDeS instrument. In this case we are using an Oxford Triton Dilution Refrigerator. The driver for this instrument is in labcore:</p> <pre><code>labcore.instruments.qcodes_drivers.Oxford.triton.OxfordTriton\n</code></pre> <p>In general, one can find a community-made driver (if it exists), or create one.</p> <p><code>address</code>: fill out the field with the IPv4 address of the instrument (on the same network as the computer you are running the instrumentserver on)</p> <p><code>init</code>: there are two items that must be filled out:</p> <p><code>port</code>: From the manual of the instrument being used, provide the port to communicate with. (For Oxford Triton, this port is <code>33576</code>).</p> <p><code>pollingRate</code>: provide a dictionary for how often to poll each parameter given. For each parameter that you wish to fetch data for, add it as a new line in the dictionary, followed by the interval (in seconds) to fetch it.</p> <p><code>networking</code>: For the dashboard, only one field is required, <code>externalBroadcast</code>. Locate the IPv4 address of the computer you are running the instrumentserver on for the internet network you wish to broadcast the data to. Include the port to broadcast to as well.</p> <p>Specific to Oxford Triton (from the driver): <code>temp_channel_mapping</code>: Create a dictionary containing the mapping between name and temperature channel for each channel you would like a named parameter for. In the provided config, 7 Temperature Channels are used to create named parameters. Channels can be found on the Lakeshore thermometry dialog on the fridge computer.</p>"},{"location":"instruments/instrumentmonitoring/#starting-the-instrument-server","title":"Starting the Instrument Server","text":"<p>Use the following to start the instrumentserver. Replace serverConfig.yml with the path to the config file you created above.</p> <pre><code>$ instrumentserver -c serverConfig.yml --gui False\n</code></pre> <p>You should start the instrumentserver using the above commmand in no GUI mode first (to improve stability). Then, you can use the following detached mode if you wish to use the GUI:</p> <pre><code>$ instrumentserver-detached\n</code></pre> <p>Note</p> <p>The following portion assumes the user has: - instrumentserver installed</p>"},{"location":"instruments/instrumentmonitoring/#the-listener","title":"The Listener","text":"<p>To use the dashboard, we will also need to run an instance of the listener on whichever computer you wish to host the dashboard on. (The computer with the listener and the computer with the instrumentserver must be on the same network). The listener can be used for writing data either in a CSV file or the InfluxDB database.</p>"},{"location":"instruments/instrumentmonitoring/#config-file_1","title":"Config File","text":"<p>Below is an example listener configuration file that can be used for the dashboard.</p> <pre><code># addresses to listen for broadcasts at\naddresses: [\"tcp://128.174.123.123:6000\",\"tcp://128.174.456.456:6000\",\"tcp://128.174.789.789:6000\"]\n\n# list of parameters to listen for, if empty, will listen for all broadcasts\nparams: []\n\n# path to write data to for the CSV listener\ncsv_path: C:\\Users\\jmnol\\OneDrive\\Documents\\InstrumentServerData\\data.csv\n\n# type of listener (where the listener writes data to)\ntype: \"Influx\"\n\n# InfluxDB token for Influx listener\ntoken: \"token\"\n\n# InfluxDB org for Influx listener\norg: \"pfafflab\"\n\n# InfluxDB buckets for Influx listener, in the same order as addresses\nbucketDict: {\"fridge_nh\":\"niflheim\",\"fridge_kk\":\"kelvin_klein\",\"fridge_dt\":\"demeter\"}\n\n# InfluxDB url for Influx listener\nurl: \"http://localhost:8086\"\n\n# measurement Name for Influx listener\nmeasurementNameDict: {\"fridge_nh\":\"niflheim_telemetry\",\"fridge_kk\":\"kelvin_klein_telemetry\",\"fridge_dt\":\"demeter_telemetry\"}\n</code></pre>"},{"location":"instruments/instrumentmonitoring/#necessary-parameters-for-using-influxdb","title":"Necessary Parameters for using InfluxDB","text":"<p><code>addresses</code>: List of addresses of where to subscribe to broadcasts from. These are the addresses on the network of the computer running the instrumentserver</p> <p><code>params</code>: List of all parameters to listen for, if empty, the listener will listen to all broadcasts</p> <p><code>type</code>: \"Influx\"</p> <p><code>token</code>: Token to write to InfluxDB. (Created when setting up Influx)</p> <p><code>org</code>: Organization to write to InfluxDB. (Created when setting up Influx)</p> <p><code>bucketDict</code>: Dictionary containing the mapping for each instrument to a bucket in Influx</p> <p><code>url</code>: URL to where the Influx database is hosted on the computer running the listener</p> <p><code>measurementNameDict</code>: Name of the measurement (one of the fields for a data point) that will be applied to the data from an instrument</p>"},{"location":"instruments/instrumentmonitoring/#necessary-parameters-for-using-csv","title":"Necessary Parameters for using CSV","text":"<p><code>addresses</code>: List of addresses of where to subscribe to broadcasts from. These are the addresses on the network of the computer running the instrumentserver</p> <p><code>paramDict</code>: Dictionary containing the list of parameters to listen for for each instrument. If the list for an instrument is empty, the listener will listen for all broadcasts from that instrument.</p> <p><code>csv_path</code>: Path of the csv file to write data to. A CSV file doesn't need to exist at the path as the listener will create one if one does not exist.</p> <p><code>type</code>: \"CSV\"</p>"},{"location":"instruments/instrumentmonitoring/#starting-the-listener","title":"Starting the Listener","text":"<p>Use the following to start the instrumentserver. Replace listenerConfig.yml with the path to the config file you created above.</p> <pre><code>$ instrumentserver-listener -c listenerConfig.yml\n</code></pre> <p>One may choose to use the following command to not display output and instead have it written to a file:</p> <pre><code>$ nohup instrumentserver-listener -c listenerConfig.yml\n</code></pre> <p>The process can be killed with:</p> <pre><code>$ ps aux | grep instrumentserver-listener\n</code></pre> <p>You can then find the ID number of the process and kill it with:</p> <pre><code>$ kill -15 {INSERT ID}\n</code></pre> <p>Note</p> <p>The following portion assumes the user has the Docker Engine installed and basic familiarity with Docker</p>"},{"location":"instruments/instrumentmonitoring/#docker","title":"Docker","text":"<p>Docker is the service that will be used to host both Influx and Grafana.</p> <pre><code>services:\n\n  grafana:\n\n    image: grafana\n    container_name: grafana\n    restart: unless-stopped\n\n    ports:\n     - '1000:1000'\n\n    volumes:\n      - grafana-storage:/var/lib/grafana\n      - ./data:/etc/grafana/data\n\n    entrypoint: [\"/bin/sh\", \"-c\", \"export GF_SECURITY_ADMIN_USER=$(cat /run/secrets/.env.grafana-username) &amp;&amp; /run.sh\"]\n    entrypoint: [\"/bin/sh\", \"-c\", \"export GF_SECURITY_ADMIN_PASSWORD=$(cat /run/secrets/.env.grafana-password) &amp;&amp; /run.sh\"]\n\n    secrets:\n      - grafana-username\n      - grafana-password\n\n  influxdb2:\n\n    image: influxdb:2\n\n    ports:\n      - 8080:8080\n\n    environment:\n      DOCKER_INFLUXDB_INIT_MODE: setup\n      DOCKER_INFLUXDB_INIT_USERNAME_FILE: /run/secrets/influxdb2-admin-username\n      DOCKER_INFLUXDB_INIT_PASSWORD_FILE: /run/secrets/influxdb2-admin-password\n      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN_FILE: /run/secrets/influxdb2-admin-token\n      DOCKER_INFLUXDB_INIT_ORG: org\n      DOCKER_INFLUXDB_INIT_BUCKET: bucket1\n\n    secrets:\n      - influxdb2-admin-username\n      - influxdb2-admin-password\n      - influxdb2-admin-token\n\n    volumes:\n      - type: volume\n        source: influxdb2-data\n        target: /var/lib/influxdb2\n      - type: volume\n        source: influxdb2-config\n        target: /etc/influxdb2\n\nvolumes:\n  grafana-storage: {}\n  influxdb2-data:\n  influxdb2-config:\n\nsecrets:\n  grafana-username:\n    file: .env.grafana-username\n  grafana-password:\n    file: .env.grafana-password\n  influxdb2-admin-username:\n    file: .env.influxdb2-admin-username\n  influxdb2-admin-password:\n    file: .env.influxdb2-admin-password\n  influxdb2-admin-token:\n    file: .env.influxdb2-admin-token\n</code></pre> <p>Above is a sample Docker Compose file. This is what is used to start the instances of Grafana and InfluxDB. Most of it should not be modified.</p> <p>To use the above file, provide 5 files: <pre><code> .env.grafana-username\n .env.grafana-password\n .env.influxdb2-admin-username\n .env.influxdb2-admin-password\n .env.influxdb2-admin-token\n</code></pre> These will be the respective usernames and passwords for each service, and then a token for the database, which is used by the entity writing to the database. These files should be in the same directory as the docker compose file.</p> <p>If you wish to add more plugins, modify a few things:</p> <ol> <li> <p>Modify the Dockerfile. On the line including, \"GF_INSTALL_PLUGINS\", include your wanted plugins in a comma-separated list.</p> </li> <li> <p>Run the following command: <pre><code>$ sudo docker build -t (insert-image-name) .\n</code></pre> Replace (insert-image-name) with your desired name and directory location.</p> </li> <li> <p>Modify the docker compose file: Under the grafana section, under \"image\", replace the default image \"grafana\" with your newly created image.</p> </li> </ol> <p>Now that your Docker compose is fully set up, you can start both services with the following command (run in the directory of the docker compose file) <pre><code>$ sudo docker compose up -d\n</code></pre></p> <p>You can then close both with the following: <pre><code>$ sudo docker compose down\n</code></pre></p> <p>Note</p> <p>Closing will take ~ 10 seconds</p>"},{"location":"instruments/instrumentmonitoring/#influxdb","title":"InfluxDB","text":"<p>Now that you have the instances of Grafana and Influx working, there is a bit more setup necessary to put it all together.</p> <p>First, you must create a bucket where you wish to store your data.</p> <p>Now, you should have all of the necessary information to fill out the config file for the listener (section is above). As long as everything is set up correctly, if the listener is running and receiving data, it should be writing the data it receives to Influx.</p>"},{"location":"instruments/instrumentmonitoring/#grafana","title":"Grafana","text":"<p>Now that you have an Influx database being populated by your data, you are ready to set up a dashboard. To create a dashboard, please follow the documentation for grafana https://grafana.com/docs/grafana/latest/dashboards/.</p> <p>To use the data from Influx, you must add it as a source: https://grafana.com/docs/grafana/latest/datasources/</p> <p>Then, within each panel of the dashboard, you must write a query to get the correct data from the database.</p> <p>Here is an example query that may be helpful (or a good starting point): <pre><code>from(bucket: \"bucket1\")\n  |&gt; range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |&gt; filter(fn: (r) =&gt; r[\"_measurement\"] == \"measurement1\")\n  |&gt; filter(fn: (r) =&gt; r[\"_field\"] == \"value\")\n  |&gt; filter(fn: (r) =&gt; r[\"name\"] == \"bucket1.param1\" or r[\"name\"] == \"bucket1.param2\")\n  |&gt; aggregateWindow(every: v.windowPeriod, fn: mean, createEmpty: false)\n  |&gt; yield(name: \"mean\")\n</code></pre> The above query will display parameters in bucket1 with fields \"measurement\" being \"measurement1\", \"field\" being \"value\", and name being \"param1\" or \"param2\".</p> <p>When creating your panel, select \"Time Series\" in Grafana.</p> <p>More information on creating dashboards can be found on the grafana documentation page: https://grafana.com/docs/grafana/latest/dashboards/.</p> <p>Also, information on setting up Slack alerts can also be found there.</p>"},{"location":"instruments/instrumentmonitoring/#notification-templates","title":"Notification Templates","text":"<p>Here is a sample notofication template:</p> <pre><code>{{ define \"general.title\" }}\n{{ if gt (len .Alerts) 0 }}\n{{ range .Alerts }}\nAlert: {{ .Labels.alertname }} - {{ .Status | title }}\n{{ end }}\n{{ else }}\nNo active alerts\n{{ end }}\n{{ end }}\n\n{{ define \"general.message\" }}\n{{ if or (gt (len .Alerts.Firing) 0) (gt (len .Alerts.Resolved) 0) }}\n{{ if gt (len .Alerts.Firing) 0 }}\n{{ range .Alerts.Firing }}\n- **Alert Name:** {{ .Labels.alertname }}\n- **Description:** {{ .Annotations.summary }}\n{{ end }}\n{{ end }}\n\n{{ if gt (len .Alerts.Resolved) 0 }}\n{{ range .Alerts.Resolved }}\n- **Alert Name:** {{ .Labels.alertname }}\n- **Description:** {{ .Annotations.summary }}\n{{ end }}\n{{ end }}\n{{ else }}\nNo alerts to display.\n{{ end }}\n{{ end }}\n</code></pre>"},{"location":"instruments/instrumentmonitoring/#creating-alert-conditions-in-grafana","title":"Creating Alert Conditions in Grafana","text":"<p>On the homepage, navigate to Alert Rules</p> <p></p> <p>For creating new alerts rules for a dashboard with existing rules, it is easiest to duplicate an existing rule. Navigate under the folder of the instrument you wish to create a new alert for:</p> <p></p> <p>First, enter the name of the alert you want to add:</p> <p></p> <p>If you are creating an alert for a parameter that is different from the rule you duplicated, you must change the database query. Replace the highlighted portion with the parameter you want to set up an alert for. (Names of parameters can be seen under the dashboard graphs)</p> <p></p> <p>To change the alert condition, only modify the highlighted portion, select a condition such as \"is below\", and then input the wanted value of the condition. For example if we wanted to send an alert when the temperature of a plate goes below 50 mK, you would choose \"is below\" and \"0.050\".</p> <p></p> <p>Assuming you duplicating an existing alert, the only part left to add is a description like the picture shown below:</p> <p></p> <p>Then, navigate to the top right of the screen and select \"Save rule and exit\".</p> <p>The new alert rule should now be working.</p>"},{"location":"instruments/instrumentmonitoring/#creating-slack-bots","title":"Creating Slack Bots","text":"<p>To create a slack bot, head to https://api.slack.com/apps. Create a new application, and add it to the slack workspace you want to send alert in. Go to your application, and go to \"Incoming Webhooks\" under Features. Create a new webhook with the channel you want to post alerts in. You will use this in Grafana in order to send messages in slack.</p> <p>In this application menu, you can also edit other general features of the bot, such as its status, description, and profile picture.</p>"},{"location":"instruments/instrumentmonitoring/#creating-alert-conditions-from-scratch","title":"Creating Alert Conditions from Scratch","text":"<p>If there are no existing alert conditions for the dashboard you wish to set up, follow this portion.</p> <p>First, navigate to the Contact Points tab. Go to Notification Templates and make sure you have a message and title template. Examples can be found in notificationtemplates.</p> <p>Then, go back to the main contact points tab, and check if there is a contact point for the dashboard you are setting up alerts for. If not, select \"Create Contact Point\".</p> <p></p> <p>Choose a name corresponding to the dashboard. Choose your integration type. For this guide we will choose Slack. Then, fill in the Webhook url section with the webhook of the channel you wish to send alerts to. You must have a Slack App set up. Information on how to do this can be found on Slack API website.</p> <p>Then, under optional slack settings, use the two created templates to upload to the \"title\" and \"text body\" fields.</p> <p>Navigate to the Notification Policies tab, under Alerting. Under the default policy, select \"new child policy\".</p> <p></p> <p>Fill in the label portion with the name of the instrument/dashboard, and have the condition be \"= 1\". Add the contact point you just created to the policy. Then, select \"Override General timings\", and set the repeat interval to a high number \"say 52w\". This will ensure the alert will only fire once, at the moment the threshold is passed.</p> <p>Then, navigate to the alert rules tab and select \"New alert rule\". Follow creatingconditions to fill out sections 1 and 2.</p> <p>Now you should be on section 3. \"Set evaluation behaviour. I would recommend creating a new folder for your instrument/dashboard if one does not exist. Then, create a default evaluation group (can be used for all the elements in the folder). I have found that evaultation every 30 seconds with a 30 second pending period work well. Then, navigate to \"Configure no data and error handling\". I have found that using \"Keep Last State\" for both will result in no false alerts if missing/bad data is encountered.</p> <p></p> <p>Then, under \"Configure labels and notifications\", set your label you created on the notification policy to 1, and under \"Notifications\", select \"Use notification policy\"</p> <p>You may want to use the preview routing option to make sure everything is set up correctly.</p> <p>Then, you shouild configure the notification message under part 5 with a description for your alert. Then you can select \"Save rule and exit\" in the top right.</p> <p>Your alert condition should now be working correctly and sending slack alerts when the threshold you set it passed.</p>"},{"location":"instruments/instrumentserver/","title":"Instrumentserver","text":"<p>The aim of Instrumentserver is to facilitate QCoDeS access across a variety of process and devices. We communicate with the server through a TCP/IP connection allowing us to talk to it from any independent process or separate device in the same network.</p> <p>Instrumentserver also includes a virtual instrument called Parameter Manager, whose job is to be a centralized and single source of truth for various parameters values with a user-friendly graphical interface to facilitate changing parameters.</p> <p>Note</p> <p>The instrumentserver lives in its own repository, here. Documentation is here to have a central place for all the documentation of the Tools For Experiments.</p> <p>Warning</p> <p>This guide is not up to date. Some new core features are not currently documented like configuration files and new features are in development. If you have questions on how to use these, please contact Marcos at: marcosf2@illinois.edu.</p>"},{"location":"instruments/instrumentserver/#installation","title":"Installation","text":"<p>At the moment Instrumentserver is not on pip or conda so the only way of installing it is to install it from github directly. To do that first clone the github repo, and install into the desired environment using the editable pip install.</p>"},{"location":"instruments/instrumentserver/#quick-overview","title":"Quick Overview","text":""},{"location":"instruments/instrumentserver/#instrumentserver_1","title":"Instrumentserver","text":"<p>To open the instrument server we simple run the command on a terminal:</p> <pre><code>$ instrumentserver\n</code></pre> <p>This will open the GUI of the server and start running it.</p> <p></p> <p>Note</p> <p>The server can be run without a gui by passing the <code>--gui False</code> argument.</p> <p>By default, instrumentserver listens to the local host IP address (127.0.0.1) and the port 5555. To be able to communicate with the server through other devices in the network we have to specify the IP address we want the server to listen to. For this we pass the argument <code>-a &lt;IP_address&gt;</code> and <code>-p &lt;port_number&gt;</code>:</p> <pre><code>$ instrumentserver -a 192.168.1.1 -p 12345\n</code></pre> <p>This will make the server listen to both the local host and the IP address 192.168.1.1 with port 12345.</p> <p>We communicate with the server with Python code. This can be done anywhere that python can run, an IPython console, a Jupyter notebook, etc. The easiest way of creating a Client instance and running the find_or_create_instrument method.</p> <p>Note</p> <p>Remember to pass the instrument specific arguments and keyword arguments necessary for the specific QCoDeS instrument you are trying to open.</p> <p>This will look for the specified instrument with the given name in the server or create it if the instrument does not exist, and return it:</p> <pre><code>&gt;&gt;&gt; cli = Client()\n&gt;&gt;&gt; dummy_instrument = cli.find_or_create_instrument(instrument_class='instrumentserver.testing.dummy_instruments.generic.DummyChannel', name='dummy_instrument')\n</code></pre> <p>Note</p> <p>If we are trying to talk to a server running in a different device in the network we need to specify the IP address and port with the arguments host and port when creating the Client.</p> <p>After this we can see that the instrument has been created in the server.</p> <p></p> <p>After that we can use the instrument like a normal QCoDeS instrument. We can create a Client from any process and get the dummy_instrument by simply using the find_or_create_instrument method:</p> <pre><code>&gt;&gt;&gt; dummy_instrument = cli.find_or_create_instrument(name='dummy_instrument')\n</code></pre>"},{"location":"instruments/instrumentserver/#parameter-manager","title":"Parameter Manager","text":"<p>Note</p> <p>The parameter manager can also be opened from a config file, more instructions on how to do this will come in the near future.</p> <p>Instrumentserver also comes with the virtual instrument Parameter Manager. The Parameter Manager allows us to store values in an instrument inside of the Instrumentserver, allowing us to access them from any process or devices in the same network. The idea of it is to have a single source of truth for parameters whose values change frequently, and it provides a GUI from which you can change the values and easily see what they are.</p> <p>To open the Parameter Manager we first need to open the Instrumentserver. Once we have the server open, we can run the command:</p> <p><pre><code>$ instrumentserver-param-manager\n</code></pre> This will create an instance of the virtual instrument in the Instrumentserver and will open the GUI for the Parameter Manager.</p> <p>Note</p> <p>At the moment the parameter manager can only be opened from the device that is currently hosting the server. If you are utilizing a different port, this can be specified by passing the terminal argument <code>--port</code> followed by the port.</p> <p>We'll simply get an empty window now. The bottom of the window allows us to add arbitrary parameters and values, where dots serve as hierarchy separators (like objects and their children in python).</p> <p></p> <p>We can add some parameters and then retrieve them from anywhere that can run python code:</p> <pre><code>&gt;&gt;&gt; cli = Client()\n&gt;&gt;&gt; params = cli.find_or_create_instrument('parameter_manager') # 'parameter_manager` is the name the startup script gives the instrument by default\n&gt;&gt;&gt; params.qubit.pipulse.len()\n40\n</code></pre> <p>We can change parameters by calling the same function but passing as an argument the new value:</p> <pre><code>&gt;&gt;&gt; params.qubit.pipulse.len(789)\n</code></pre> <p>We can add or remove parameters with code too:</p> <pre><code>&gt;&gt;&gt; params.add_parameter('qubit.anharmonicity', initial_value=-150.0, unit='MHz')\n&gt;&gt;&gt; params.remove_parameter('qubit.pipulse.amp')\n</code></pre> <p>All of these changes get updated live in the GUI:</p> <p></p> <p>Changing things in the GUI will also be reflected in the code.</p> <p>Warning</p> <p>Changing something from the GUI only changes the code if we are calling the parameter manager directly. If we store a value in a separate variable and then change the GUI, the value in the variable might not get update. Because of this, we always recommend to call the Parameter Manager directly instead of saving the values in variables.</p>"},{"location":"instruments/qcodes_instruments/instruments/","title":"Our QCoDeS Drivers","text":"<p>The following are our own QCoDeS drivers that we have developed (or borrowed and modified) for our own use. They are all available in the <code>labcore</code> package.</p>"},{"location":"instruments/qcodes_instruments/instruments/#specific-drivers","title":"Specific Drivers","text":""},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight","title":"<code>Keysight</code>","text":""},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B","title":"<code>Keysight_N9030B</code>","text":"<p>A driver to control the Keysight N9030B spectrum analyzer using pyVISA and qcodes</p> <p>@author: Pfafflab (UIUC): Xi Cao, Michael Mollenhauer</p>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030B","title":"<code>KeysightN9030B</code>","text":"<p>             Bases: <code>VisaInstrument</code></p> <p>Driver for Keysight N9030B PXA signal analyzer. Keysight N9030B PXA signal analyzer is part of Keysight X-Series Multi-touch Signal Analyzers. This driver allows Swept SA measurements in Spectrum Analyzer mode and Log Plot measurements in Phase Noise mode of the instrument.</p> <p>Args:     name     address</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>class KeysightN9030B(VisaInstrument):\n    \"\"\"\n    Driver for Keysight N9030B PXA signal analyzer. Keysight N9030B PXA\n    signal analyzer is part of Keysight X-Series Multi-touch Signal\n    Analyzers.\n    This driver allows Swept SA measurements in Spectrum Analyzer mode and\n    Log Plot measurements in Phase Noise mode of the instrument.\n\n    Args:\n        name\n        address\n    \"\"\"\n\n    def __init__(self, name: str, address: str, timeout=None, **kwargs: Any, ) -&gt; None:\n        super().__init__(name, address, timeout, terminator=\"\\n\", **kwargs)\n\n        self.default_timout: float = 3600\n        self._min_freq: float\n        self._max_freq: float\n        self._additional_wait: float = 1\n\n        self.add_parameter(\n            name=\"mode\",\n            get_cmd=\":INSTrument:SELect?\",\n            set_cmd=\":INSTrument:SELect {}\",\n            vals=Enum(*self._available_modes()),\n            docstring=\"Allows setting of different modes present and licensed \"\n            \"for the instrument.\",\n        )\n\n        self.add_parameter(\n            name=\"measurement\",\n            get_cmd=\":CONFigure?\",\n            set_cmd=\":CONFigure:{}\",\n            vals=Enum(\"SAN\", \"LPL\"),\n            docstring=\"Sets measurement type from among the available \"\n            \"measurement types.\",\n        )\n\n        self.add_parameter(\n            name=\"cont_meas\",\n            initial_value=False,\n            get_cmd=self._get_cont_meas,\n            set_cmd=self._enable_cont_meas,\n            get_parser=int,\n            vals = Ints(0, 1),\n            docstring=\"Enables or disables continuous measurement.\",\n        )\n\n        self.add_parameter(\n            name=\"format\",\n            get_cmd=\":FORMat:TRACe:DATA?\",\n            set_cmd=\":FORMat:TRACe:DATA {}\",\n            val_mapping={\n                \"ascii\": \"ASCii\",\n                \"int32\": \"INTeger,32\",\n                \"real32\": \"REAL,32\",\n                \"real64\": \"REAL,64\",\n            },\n            docstring=\"Sets up format of data received\",\n        )\n\n        if \"SA\" in self._available_modes():\n            sa_mode = KeysightN9030BSpectrumAnalyzerMode(self, name=\"sa\")\n            self.add_submodule(\"sa\", sa_mode)\n            for ch in list(np.arange(1,13,1)):\n                channel = KeysightN9030BSpectrumAnalyzerModeMarkers(self, name=f\"sa_marker{ch}\", marker_channel=ch)\n                self.add_submodule(f\"sa_marker{ch}\", channel)\n        else:\n            self.log.info(\"Spectrum Analyzer mode is not available on this instrument.\")\n\n        if \"PNOISE\" in self._available_modes():\n            pnoise_mode = KeysightN9030BPhaseNoiseMode(self, name=\"pn\")\n            self.add_submodule(\"pn\", pnoise_mode)\n        else:\n            self.log.info(\"Phase Noise mode is not available on this instrument.\")\n        self.connect_message()\n\n\n    def _get_cont_meas(self) -&gt; int:\n        \"\"\"\n        Get the status of if the instrument is in contiuous measurement mode\n        \"\"\"\n        status = int(self.ask(\":INITiate:CONTinuous?\"))\n        return status\n\n\n    def _available_modes(self) -&gt; tuple[str, ...]:\n        \"\"\"\n        Returns present and licensed modes for the instrument.\n        \"\"\"\n        available_modes = self.ask(\":INSTrument:CATalog?\")\n        av_modes = available_modes[1:-1].split(\",\")\n        modes: tuple[str, ...] = ()\n        for i, mode in enumerate(av_modes):\n            if i == 0:\n                modes = modes + (mode.split(\" \")[0],)\n            else:\n                modes = modes + (mode.split(\" \")[1],)\n        return modes\n\n    def _available_meas(self) -&gt; tuple[str, ...]:\n        \"\"\"\n        Gives available measurement with a given mode for the instrument\n        \"\"\"\n        available_meas = self.ask(\":CONFigure:CATalog?\")\n        av_meas = available_meas[1:-1].split(\",\")\n        measurements: tuple[str, ...] = ()\n        for i, meas in enumerate(av_meas):\n            if i == 0:\n                measurements = measurements + (meas,)\n            else:\n                measurements = measurements + (meas[1:],)\n        return measurements\n\n    def _enable_cont_meas(self, val: str) -&gt; None:\n        \"\"\"\n        Sets continuous measurement to ON or OFF.\n        \"\"\"\n        self.write(f\":INITiate:CONTinuous {val}\")\n\n    def _options(self) -&gt; tuple[str, ...]:\n        \"\"\"\n        Returns installed options numbers.\n        \"\"\"\n        options_raw = self.ask(\"*OPT?\")\n        return tuple(options_raw[1:-1].split(\",\"))\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Reset the instrument by sending the RST command\n        \"\"\"\n        self.write(\"*RST\")\n\n    def abort(self) -&gt; None:\n        \"\"\"\n        Aborts the measurement\n        \"\"\"\n        self.write(\":ABORt\")\n\n    def ask_test(self, askstring) -&gt; None:\n        \"\"\"\n        Directly sending a string for ask command\n        \"\"\"\n        data = self.ask(askstring)\n        return data\n\n    def write_test(self, writestring) -&gt; None:\n        \"\"\"\n        Directly sending a string for write command\n        \"\"\"\n        data = self.write(writestring)\n        return data\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030B.abort","title":"<code>abort()</code>","text":"<p>Aborts the measurement</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def abort(self) -&gt; None:\n    \"\"\"\n    Aborts the measurement\n    \"\"\"\n    self.write(\":ABORt\")\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030B.ask_test","title":"<code>ask_test(askstring)</code>","text":"<p>Directly sending a string for ask command</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def ask_test(self, askstring) -&gt; None:\n    \"\"\"\n    Directly sending a string for ask command\n    \"\"\"\n    data = self.ask(askstring)\n    return data\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030B.reset","title":"<code>reset()</code>","text":"<p>Reset the instrument by sending the RST command</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Reset the instrument by sending the RST command\n    \"\"\"\n    self.write(\"*RST\")\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030B.write_test","title":"<code>write_test(writestring)</code>","text":"<p>Directly sending a string for write command</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def write_test(self, writestring) -&gt; None:\n    \"\"\"\n    Directly sending a string for write command\n    \"\"\"\n    data = self.write(writestring)\n    return data\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030BPhaseNoiseMode","title":"<code>KeysightN9030BPhaseNoiseMode</code>","text":"<p>             Bases: <code>InstrumentChannel</code></p> <p>Phase Noise Mode for Keysight N9030B instrument.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>class KeysightN9030BPhaseNoiseMode(InstrumentChannel):\n    \"\"\"\n    Phase Noise Mode for Keysight N9030B instrument.\n    \"\"\"\n\n    def __init__(self, parent: KeysightN9030B, name: str, *arg: Any, **kwargs: Any):\n        super().__init__(parent, name, *arg, **kwargs)\n\n        self._min_freq = 1\n        self._valid_max_freq: dict[str, float] = {\n            \"503\": 3699999995,\n            \"508\": 8499999995,\n            \"513\": 13799999995,\n            \"526\": 26999999995,\n            \"544\": 44499999995,\n        }\n        opt: str | None = None\n        for hw_opt_for_max_freq in self._valid_max_freq.keys():\n            if hw_opt_for_max_freq in self.root_instrument._options():\n                opt = hw_opt_for_max_freq\n        assert opt is not None\n        self._max_freq = self._valid_max_freq[opt]\n\n        self.add_parameter(\n            name=\"npts\",\n            get_cmd=\":SENSe:LPLot:SWEep:POINts?\",\n            set_cmd=\":SENSe:LPLot:SWEep:POINts {}\",\n            get_parser=int,\n            vals=Ints(601, 20001),\n            docstring=\"Number of points for the sweep\",\n        )\n\n        self.add_parameter(\n            name=\"start_offset\",\n            unit=\"Hz\",\n            get_cmd=\":SENSe:LPLot:FREQuency:OFFSet:STARt?\",\n            set_cmd=self._set_start_offset,\n            get_parser=float,\n            vals=Numbers(self._min_freq, self._max_freq - 10),\n            docstring=\"start frequency offset for the plot\",\n        )\n\n        self.add_parameter(\n            name=\"stop_offset\",\n            unit=\"Hz\",\n            get_cmd=\":SENSe:LPLot:FREQuency:OFFSet:STOP?\",\n            set_cmd=self._set_stop_offset,\n            get_parser=float,\n            vals=Numbers(self._min_freq + 99, self._max_freq),\n            docstring=\"stop frequency offset for the plot\",\n        )\n\n        self.add_parameter(\n            name=\"signal_tracking_enabled\",\n            get_cmd=\":SENSe:FREQuency:CARRier:TRACk?\",\n            set_cmd=\":SENSe:FREQuency:CARRier:TRACk {}\",\n            val_mapping=create_on_off_val_mapping(on_val=\"ON\", off_val=\"OFF\"),\n            docstring=\"Gets/Sets signal tracking. When signal tracking is \"\n            \"enabled carrier signal is repeatedly realigned. Signal \"\n            \"Tracking assumes the new acquisition occurs repeatedly \"\n            \"without pause.\",\n        )\n\n        self.add_parameter(\n            name=\"freq_axis\",\n            label=\"Frequency\",\n            unit=\"Hz\",\n            start=self.start_offset,\n            stop=self.stop_offset,\n            npts=self.npts,\n            vals=Arrays(shape=(self.npts.get_latest,)),\n            parameter_class=FrequencyAxis,\n            docstring=\"Creates frequency axis for the sweep from \"\n            \"start_offset, stop_offset and npts values.\",\n        )\n\n        self.add_parameter(\n            name=\"trace\",\n            label=\"Trace\",\n            unit=\"dB\",\n            number=3,\n            vals=Arrays(shape=(self.npts.get_latest,)),\n            setpoints=(self.freq_axis,),\n            parameter_class=Trace,\n            docstring=\"Gets trace data.\",\n        )\n\n    def _set_start_offset(self, val: float) -&gt; None:\n        \"\"\"\n        Sets start offset for frequency in the plot\n        \"\"\"\n        stop_offset = self.stop_offset()\n        self.write(f\":SENSe:LPLot:FREQuency:OFFSet:STARt {val}\")\n        start_offset = self.start_offset()\n\n        if abs(val - start_offset) &gt;= 1:\n            self.log.warning(\n                f\"Could not set start offset to {val} setting it to {start_offset}\"\n            )\n        if val &gt;= stop_offset or abs(val - stop_offset) &lt; 10:\n            self.log.warning(\n                f\"Provided start frequency offset {val} Hz was \"\n                f\"greater than preset stop frequency offset \"\n                f\"{stop_offset} Hz. Provided start frequency \"\n                f\"offset {val} Hz is set and new stop freq offset\"\n                f\" is: {self.stop_offset()} Hz.\"\n            )\n\n    def _set_stop_offset(self, val: float) -&gt; None:\n        \"\"\"\n        Sets stop offset for frequency in the plot\n        \"\"\"\n        start_offset = self.start_offset()\n        self.write(f\":SENSe:LPLot:FREQuency:OFFSet:STOP {val}\")\n        stop_offset = self.stop_offset()\n\n        if abs(val - stop_offset) &gt;= 1:\n            self.log.warning(\n                f\"Could not set stop offset to {val} setting it to {stop_offset}\"\n            )\n\n        if val &lt;= start_offset or abs(val - start_offset) &lt; 10:\n            self.log.warning(\n                f\"Provided stop frequency offset {val} Hz was \"\n                f\"less than preset start frequency offset \"\n                f\"{start_offset} Hz. Provided stop frequency \"\n                f\"offset {val} Hz is set and new start freq offset\"\n                f\" is: {self.start_offset()} Hz.\"\n            )\n\n    def _get_data(self, trace_num: int) -&gt; ParamRawDataType:\n        \"\"\"\n        Gets data from the measurement.\n        \"\"\"\n        raw_data = self.ask(f\":READ:{self.root_instrument.measurement()}{1}?\")\n        trace_res_details = np.array(raw_data.rstrip().split(\",\")).astype(\"float64\")\n\n        if len(trace_res_details) != 7 or (\n            len(trace_res_details) &gt;= 1 and trace_res_details[0] &lt; -50\n        ):\n            self.log.warning(\"Carrier(s) Incorrect or Missing!\")\n            return -1 * np.ones(self.npts())\n\n        try:\n            data_str = self.ask(\n                f\":READ:{self.root_instrument.measurement()}{trace_num}?\"\n            )\n            data = np.array(data_str.rstrip().split(\",\")).astype(\"float64\")\n        except TimeoutError as e:\n            raise TimeoutError(\"Couldn't receive any data. Command timed out.\") from e\n\n        trace_data = data[1::2]\n        return trace_data\n\n    def setup_log_plot_sweep(\n        self, start_offset: float, stop_offset: float, npts: int\n    ) -&gt; None:\n        \"\"\"\n        Sets up the Log Plot measurement sweep for Phase Noise Mode.\n        \"\"\"\n        self.root_instrument.mode(\"PNOISE\")\n        if \"LPL\" in self.root_instrument._available_meas():\n            self.root_instrument.measurement(\"LPL\")\n        else:\n            raise RuntimeError(\n                \"Log Plot measurement is not available on your \"\n                \"Keysight N9030B instrument with Phase Noise \"\n                \"mode.\"\n            )\n\n        self.start_offset(start_offset)\n        self.stop_offset(stop_offset)\n        self.npts(npts)\n\n    def autotune(self) -&gt; None:\n        \"\"\"\n        On autotune, the measurement automatically searches for and tunes to\n        the strongest signal in the full span of the analyzer.\n        \"\"\"\n        self.write(\":SENSe:FREQuency:CARRier:SEARch\")\n        self.start_offset()\n        self.stop_offset()\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030BPhaseNoiseMode.autotune","title":"<code>autotune()</code>","text":"<p>On autotune, the measurement automatically searches for and tunes to the strongest signal in the full span of the analyzer.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def autotune(self) -&gt; None:\n    \"\"\"\n    On autotune, the measurement automatically searches for and tunes to\n    the strongest signal in the full span of the analyzer.\n    \"\"\"\n    self.write(\":SENSe:FREQuency:CARRier:SEARch\")\n    self.start_offset()\n    self.stop_offset()\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030BPhaseNoiseMode.setup_log_plot_sweep","title":"<code>setup_log_plot_sweep(start_offset, stop_offset, npts)</code>","text":"<p>Sets up the Log Plot measurement sweep for Phase Noise Mode.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def setup_log_plot_sweep(\n    self, start_offset: float, stop_offset: float, npts: int\n) -&gt; None:\n    \"\"\"\n    Sets up the Log Plot measurement sweep for Phase Noise Mode.\n    \"\"\"\n    self.root_instrument.mode(\"PNOISE\")\n    if \"LPL\" in self.root_instrument._available_meas():\n        self.root_instrument.measurement(\"LPL\")\n    else:\n        raise RuntimeError(\n            \"Log Plot measurement is not available on your \"\n            \"Keysight N9030B instrument with Phase Noise \"\n            \"mode.\"\n        )\n\n    self.start_offset(start_offset)\n    self.stop_offset(stop_offset)\n    self.npts(npts)\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030BSpectrumAnalyzerMode","title":"<code>KeysightN9030BSpectrumAnalyzerMode</code>","text":"<p>             Bases: <code>InstrumentChannel</code></p> <p>Spectrum Analyzer Mode for Keysight N9030B instrument.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>class KeysightN9030BSpectrumAnalyzerMode(InstrumentChannel):\n    \"\"\"\n    Spectrum Analyzer Mode for Keysight N9030B instrument.\n    \"\"\"\n\n    def __init__(self, parent: KeysightN9030B, name: str, *arg: Any, **kwargs: Any):\n        super().__init__(parent, name, *arg, **kwargs)\n\n        self._min_freq = -8e7\n        self._valid_max_freq: dict[str, float] = {\n            \"503\": 3.7e9,\n            \"508\": 8.5e9,\n            \"513\": 13.8e9,\n            \"526\": 27e9,\n            \"544\": 44.5e9,\n        }\n        opt: str | None = None\n        for hw_opt_for_max_freq in self._valid_max_freq.keys():\n            if hw_opt_for_max_freq in self.root_instrument._options():\n                opt = hw_opt_for_max_freq\n        assert opt is not None\n        self._max_freq = self._valid_max_freq[opt]\n\n        self.add_parameter(\n            name=\"average_count\", \n            unit=\"\", \n            get_cmd=\":SENS:AVER:COUN?\", \n            set_cmd=self._set_average_count, \n            get_parser=int, \n            vals=Numbers(1, 10000),\n            docstring=\"total average count for the trace\", \n        )\n\n        self.add_parameter(\n            name=\"start\",\n            unit=\"Hz\",\n            get_cmd=\":SENSe:FREQuency:STARt?\",\n            set_cmd=self._set_start,\n            get_parser=float,\n            vals=Numbers(self._min_freq, self._max_freq - 10),\n            docstring=\"start frequency for the sweep\",\n        )\n\n        self.add_parameter(\n            name=\"stop\",\n            unit=\"Hz\",\n            get_cmd=\":SENSe:FREQuency:STOP?\",\n            set_cmd=self._set_stop,\n            get_parser=float,\n            vals=Numbers(self._min_freq + 10, self._max_freq),\n            docstring=\"stop frequency for the sweep\",\n        )\n\n        self.add_parameter(\n            name=\"center\",\n            unit=\"Hz\",\n            get_cmd=\":SENSe:FREQuency:CENTer?\",\n            set_cmd=self._set_center,\n            get_parser=float,\n            vals=Numbers(self._min_freq + 5, self._max_freq - 5),\n            docstring=\"Sets and gets center frequency\",\n        )\n\n        self.add_parameter(\n            name=\"span\",\n            unit=\"Hz\",\n            get_cmd=\":SENSe:FREQuency:SPAN?\",\n            set_cmd=self._set_span,\n            get_parser=float,\n            vals=Numbers(10, self._max_freq - self._min_freq),\n            docstring=\"Changes span of frequency\",\n        )\n\n        self.add_parameter(\n            name=\"npts\",\n            get_cmd=\":SENSe:SWEep:POINts?\",\n            set_cmd=self._set_npts,\n            get_parser=int,\n            vals=Ints(1, 20001),\n            docstring=\"Number of points for the sweep\",\n        )\n\n        self.add_parameter(\n            name=\"res_bandwidth\",\n            label=\"Resolution bandwidth\",\n            unit=\"Hz\",\n            get_cmd=\":SENSe:BANDwidth?\",\n            set_cmd=\":SENSe:BANDwidth {}\",\n            get_parser=float,\n            docstring=\"get and set resolution bandwidth\"\n        )\n\n        self.add_parameter(\n            name=\"sweep_time\",\n            label=\"Sweep time\",\n            get_cmd=\":SENSe:SWEep:TIME?\",\n            set_cmd=\":SENSe:SWEep:TIME {}\",\n            get_parser=float,\n            unit=\"s\",\n            docstring=\"gets sweep time\",\n        )\n\n        self.add_parameter(\n            name=\"amp_ref_level\",\n            label=\"Reference level\",\n            get_cmd=\":DISP:WIND:TRAC:Y:RLEV?\",\n            set_cmd=\":DISP:WIND:TRAC:Y:RLEV {}\",\n            get_parser=float,\n            unit=\"dBm\",\n            docstring=\"set the top value on the y-axis\",\n        )\n\n        self.add_parameter(\n            name=\"amp_scale\",\n            label=\"Scale / Div\",\n            get_cmd=\":DISP:WIND:TRAC:Y:PDIV?\",\n            set_cmd=\":DISP:WIND:TRAC:Y:PDIV {}\",\n            get_parser=float,\n            unit=\"dB\",\n            docstring=\"set the scale per div on the y-axis\",\n        )\n\n        self.add_parameter(\n            name=\"auto_sweep_time_enabled\",\n            get_cmd=\":SENSe:SWEep:TIME:AUTO?\",\n            set_cmd=self._enable_auto_sweep_time,\n            val_mapping=create_on_off_val_mapping(on_val=\"ON\", off_val=\"OFF\"),\n            docstring=\"enables auto sweep time\",\n        )\n\n        self.add_parameter(\n            name=\"auto_sweep_type_enabled\",\n            get_cmd=\":SENSe:SWEep:TYPE:AUTO?\",\n            set_cmd=self._enable_auto_sweep_type,\n            val_mapping=create_on_off_val_mapping(on_val=\"ON\", off_val=\"OFF\"),\n            docstring=\"enables auto sweep type\",\n        )\n\n        self.add_parameter(\n            name=\"sweep_type\",\n            get_cmd=\":SENSe:SWEep:TYPE?\",\n            set_cmd=self._set_sweep_type,\n            val_mapping={\n                \"fft\": \"FFT\",\n                \"sweep\": \"SWE\",\n            },\n            docstring=\"Sets up sweep type. Possible options are 'fft' and 'sweep'.\",\n        )\n\n        self.add_parameter(\n            name=\"freq_axis\",\n            label=\"Frequency\",\n            unit=\"Hz\",\n            start=self.start,\n            stop=self.stop,\n            npts=self.npts,\n            vals=Arrays(shape=(self.npts.get_latest,)),\n            parameter_class=FrequencyAxis,\n            docstring=\"Creates frequency axis for the sweep from start, \"\n            \"stop and npts values.\",\n        )\n\n        self.add_parameter(\n            name=\"trace\",\n            label=\"Trace\",\n            unit=\"dB\",\n            number=1,\n            vals=Arrays(shape=(self.npts.get_latest,)),\n            setpoints=(self.freq_axis,),\n            parameter_class=Trace,\n            docstring=\"Gets trace data.\",\n        )\n\n    def _set_average_count(self, val: int) -&gt; None:\n        \"\"\"\n        Sets the total average count for the trace\n        \"\"\"\n        self.write(f\":SENS:AVER:COUN {val}\")\n\n    def _set_start(self, val: float) -&gt; None:\n        \"\"\"\n        Sets start frequency\n        \"\"\"\n        stop = self.stop()\n        if val &gt;= stop:\n            raise ValueError(\n                f\"Start frequency must be smaller than stop \"\n                f\"frequency. Provided start freq is: {val} Hz and \"\n                f\"set stop freq is: {stop} Hz\"\n            )\n\n        self.write(f\":SENSe:FREQuency:STARt {val}\")\n\n        start = self.start()\n        if abs(val - start) &gt;= 1:\n            self.log.warning(f\"Could not set start to {val} setting it to {start}\")\n\n    def _set_stop(self, val: float) -&gt; None:\n        \"\"\"\n        Sets stop frequency\n        \"\"\"\n        start = self.start()\n        if val &lt;= start:\n            raise ValueError(\n                f\"Stop frequency must be larger than start \"\n                f\"frequency. Provided stop freq is: {val} Hz and \"\n                f\"set start freq is: {start} Hz\"\n            )\n\n        self.write(f\":SENSe:FREQuency:STOP {val}\")\n\n        stop = self.stop()\n        if abs(val - stop) &gt;= 1:\n            self.log.warning(f\"Could not set stop to {val} setting it to {stop}\")\n\n    def _set_center(self, val: float) -&gt; None:\n        \"\"\"\n        Sets center frequency and updates start and stop frequencies if they\n        change.\n        \"\"\"\n        self.write(f\":SENSe:FREQuency:CENTer {val}\")\n        self.update_trace()\n\n    def _set_span(self, val: float) -&gt; None:\n        \"\"\"\n        Sets frequency span and updates start and stop frequencies if they\n        change.\n        \"\"\"\n        self.write(f\":SENSe:FREQuency:SPAN {val}\")\n        self.update_trace()\n\n    def _set_npts(self, val: int) -&gt; None:\n        \"\"\"\n        Sets number of points for sweep\n        \"\"\"\n        self.write(f\":SENSe:SWEep:POINts {val}\")\n\n    def _enable_auto_sweep_time(self, val: str) -&gt; None:\n        \"\"\"\n        Enables auto sweep time\n        \"\"\"\n        self.write(f\":SENSe:SWEep:TIME:AUTO {val}\")\n\n    def _enable_auto_sweep_type(self, val: str) -&gt; None:\n        \"\"\"\n        Enables auto sweep type\n        \"\"\"\n        self.write(f\":SENSe:SWEep:TYPE:AUTO {val}\")\n\n    def _set_sweep_type(self, val: str) -&gt; None:\n        \"\"\"\n        Sets sweep type\n        \"\"\"\n        self.write(f\":SENSe:SWEep:TYPE {val}\")\n\n    def _get_data(self, trace_num: int) -&gt; ParamRawDataType:\n        \"\"\"\n        Gets data from the measurement.\n        \"\"\"\n        self.root_instrument.timeout.set_to(1000)\n        data_str = self.ask(\n            f\":READ:{self.root_instrument.measurement()}{trace_num}?\"\n        )\n        data = np.array(data_str.rstrip().split(\",\")).astype(\"float64\")\n        trace_data = data[1::2]\n        return trace_data\n\n    def update_trace(self) -&gt; None:\n        \"\"\"\n        Updates start and stop frequencies whenever span of/or center frequency\n        is updated.\n        \"\"\"\n        self.start()\n        self.stop()\n\n    def setup_swept_sa_sweep(self, start: float, stop: float, npts: int) -&gt; None:\n        \"\"\"\n        Sets up the Swept SA measurement sweep for Spectrum Analyzer Mode.\n        \"\"\"\n        self.root_instrument.mode(\"SA\")\n        if \"SAN\" in self.root_instrument._available_meas():\n            self.root_instrument.measurement(\"SAN\")\n        else:\n            raise RuntimeError(\n                \"Swept SA measurement is not available on your \"\n                \"Keysight N9030B instrument with Spectrum \"\n                \"Analyzer mode.\"\n            )\n        self.start(start)\n        self.stop(stop)\n        self.npts(npts)\n\n    def autotune(self) -&gt; None:\n        \"\"\"\n        Autotune quickly get to the most likely signal of interest, and\n        position it optimally on the display.\n        \"\"\"\n        self.write(\":SENS:FREQuency:TUNE:IMMediate\")\n        self.center()\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030BSpectrumAnalyzerMode.autotune","title":"<code>autotune()</code>","text":"<p>Autotune quickly get to the most likely signal of interest, and position it optimally on the display.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def autotune(self) -&gt; None:\n    \"\"\"\n    Autotune quickly get to the most likely signal of interest, and\n    position it optimally on the display.\n    \"\"\"\n    self.write(\":SENS:FREQuency:TUNE:IMMediate\")\n    self.center()\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030BSpectrumAnalyzerMode.setup_swept_sa_sweep","title":"<code>setup_swept_sa_sweep(start, stop, npts)</code>","text":"<p>Sets up the Swept SA measurement sweep for Spectrum Analyzer Mode.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def setup_swept_sa_sweep(self, start: float, stop: float, npts: int) -&gt; None:\n    \"\"\"\n    Sets up the Swept SA measurement sweep for Spectrum Analyzer Mode.\n    \"\"\"\n    self.root_instrument.mode(\"SA\")\n    if \"SAN\" in self.root_instrument._available_meas():\n        self.root_instrument.measurement(\"SAN\")\n    else:\n        raise RuntimeError(\n            \"Swept SA measurement is not available on your \"\n            \"Keysight N9030B instrument with Spectrum \"\n            \"Analyzer mode.\"\n        )\n    self.start(start)\n    self.stop(stop)\n    self.npts(npts)\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030BSpectrumAnalyzerMode.update_trace","title":"<code>update_trace()</code>","text":"<p>Updates start and stop frequencies whenever span of/or center frequency is updated.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>def update_trace(self) -&gt; None:\n    \"\"\"\n    Updates start and stop frequencies whenever span of/or center frequency\n    is updated.\n    \"\"\"\n    self.start()\n    self.stop()\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_N9030B.KeysightN9030BSpectrumAnalyzerModeMarkers","title":"<code>KeysightN9030BSpectrumAnalyzerModeMarkers</code>","text":"<p>             Bases: <code>InstrumentChannel</code></p> <p>Controls the marker commands in the Spectrum Analyzer Mode for Keysight N9030B instrument.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_N9030B.py</code> <pre><code>class KeysightN9030BSpectrumAnalyzerModeMarkers(InstrumentChannel):\n    \"\"\"\n    Controls the marker commands in the\n    Spectrum Analyzer Mode for Keysight N9030B instrument.\n    \"\"\"\n\n    def __init__(self, parent: KeysightN9030B, name: str, marker_channel: str, *arg: Any, **kwargs: Any):\n        super().__init__(parent, name, *arg, **kwargs)\n\n        if marker_channel not in list(np.arange(1,13,1)):\n            raise ValueError('only markers 1 through 12 are available')\n\n        self.add_parameter(\n            name='mode',\n            get_cmd=f':CALC:MARK{marker_channel}:MODE?',\n            set_cmd=f':CALC:MARK{marker_channel}:MODE {{}}',\n            get_parser=str,\n            docstring=\"get and set current marker mode\",   \n        )\n        self.add_parameter(\n            name='freq',\n            label=\"Frequency\",\n            unit=\"Hz\",\n            get_cmd=f':CALC:MARK{marker_channel}:X?',\n            set_cmd=f':CALC:MARK{marker_channel}:X {{}}',\n            get_parser=float,\n            docstring=\"get and set current marker frequency\\\n                if marker mode is POS or FIX, will return markers freq position; \\\n                if marker mode is DELT, will return the freq difference between the current \\\n                marker and the following numbered marker\",   \n        )\n        self.add_parameter(\n            name='amp',\n            label='Power',\n            unit='dBm',\n            get_cmd=f':CALC:MARK{marker_channel}:Y?',\n            set_cmd=f':CALC:MARK{marker_channel}:Y {{}}',\n            get_parser=float,\n            docstring=\"get and set current marker amplitude; \\\n                if marker mode is POS or FIX, will return markers amp position; \\\n                if marker mode is DELT, will return the amp difference between the current \\\n                marker and the following numbered marker\",   \n        )\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A","title":"<code>Keysight_P937A</code>","text":"<p>A driver to control the Keysight VNA P9374A using pyVISA and qcodes</p> <p>@author: Hatlab: Ryan Kaufman; UIUC: Wolfgang Pfaff</p>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.FrequencyData","title":"<code>FrequencyData</code>","text":"<p>             Bases: <code>Parameter</code></p> <p>FrequencyData(Parameter)</p> <p>Qcodes parameter that can be used to get the frequency data of this measurment.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>class FrequencyData(Parameter):\n    \"\"\"\n    FrequencyData(Parameter)\n\n    Qcodes parameter that can be used to get the frequency data of this measurment.\n    \"\"\"\n\n    def __init__(self, trace_number: int, *args: Any, **kwargs: Any) -&gt; None:\n        super().__init__(*args, **kwargs)\n        self.trace_number = trace_number\n\n    def get_raw(self) -&gt; ParamRawDataType:\n        _, traces, _ = self.root_instrument.get_existing_traces()\n        if self.instrument.npts() == 0 or self.trace_number not in traces:\n            return np.array([])\n\n        data = self.root_instrument.ask(f\"CALC:MEAS{self.trace_number}:X?\")\n        return np.array(data.split(',')).astype(float)\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel","title":"<code>Keysight_P9374A_SingleChannel</code>","text":"<p>             Bases: <code>VisaInstrument</code></p> <p>This is a very simple driver for the Keysight_P9374A Vector Network Analyzer Performs basic manipulations of parameters and data acquisition</p> <p>Note: this version does not include a way of averaging via a BUS trigger</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>class Keysight_P9374A_SingleChannel(VisaInstrument):\n    \"\"\"\n    This is a very simple driver for the Keysight_P9374A Vector Network Analyzer\n    Performs basic manipulations of parameters and data acquisition\n\n    Note: this version does not include a way of averaging via a BUS trigger\n\n    \"\"\"\n\n    def __init__(self, name, address=None, **kwargs):\n\n        \"\"\"\n        Initializes the Keysight_P9374A, and communicates with the wrapper.\n\n        Input:\n          name (string)    : name of the instrument\n          address (string) : GPIB address\n          reset (bool)     : resets to default values, default=False\n        \"\"\"\n        if address is None:\n            raise Exception('TCP IP address needed')\n        logging.info(__name__ + ' : Initializing instrument Keysight PNA')\n\n        super().__init__(name, address, terminator='\\n', **kwargs)\n\n        self.write('CALC1:PAR:MNUM 1')  # sets the active msmt to the first channel/trace\n\n        # Add in parameters\n        self.add_parameter('fstart',\n                           get_cmd=':SENS1:FREQ:STAR?',\n                           set_cmd=':SENS1:FREQ:STAR {}',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           unit='Hz'\n                           )\n        self.add_parameter('fstop',\n                           get_cmd=':SENS1:FREQ:STOP?',\n                           set_cmd=':SENS1:FREQ:STOP {}',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           unit='Hz'\n                           )\n        self.add_parameter('fcenter',\n                           get_cmd=':SENS1:FREQ:CENT?',\n                           set_cmd=':SENS1:FREQ:CENT {}',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           unit='Hz'\n                           )\n        self.add_parameter('fspan',\n                           get_cmd=':SENS1:FREQ:SPAN?',\n                           set_cmd=':SENS1:FREQ:SPAN {}',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           unit='Hz'\n                           )\n        self.add_parameter('rfout',\n                           get_cmd=':OUTP?',\n                           set_cmd=':OUTP {}',\n                           vals=vals.Ints(0, 1),\n                           get_parser=int\n                           )\n        self.add_parameter('num_points',\n                           get_cmd=':SENS1:SWE:POIN?',\n                           set_cmd=':SENS1:SWE:POIN {}',\n                           vals=vals.Ints(1, 100000),\n                           get_parser=int\n                           )\n        self.add_parameter('ifbw',\n                           get_cmd=':SENS1:BWID?',\n                           set_cmd=':SENS1:BWID {}',\n                           vals=vals.Numbers(10, 1.5e6),\n                           get_parser=float)\n        self.add_parameter('power',\n                           get_cmd=\":SOUR1:POW?\",\n                           set_cmd=\":SOUR1:POW {}\",\n                           unit='dBm',\n                           get_parser=float,\n                           vals=vals.Numbers(-85, 20)\n                           )\n        self.add_parameter('power_start',\n                           get_cmd=':SOUR1:POW:STAR?',\n                           set_cmd=':SOUR1:POW:STAR {}',\n                           unit='dBm',\n                           get_parser=float,\n                           vals=vals.Numbers(-85, 10)\n                           )\n        self.add_parameter('power_stop',\n                           get_cmd=':SOUR:POW:STOP?',\n                           set_cmd=':SOUR1:POW:STOP {}',\n                           unit='dBm',\n                           get_parser=float,\n                           vals=vals.Numbers(-85, 10)),\n        self.add_parameter('averaging',\n                           get_cmd=':SENS1:AVER?',\n                           set_cmd=':SENS1:AVER {}',\n                           get_parser=int,\n                           vals=vals.Ints(0, 1)\n                           )\n        # TODO: this throws an error currently.\n        # self.add_parameter('average_trigger',\n        #                    get_cmd=':TRIG:AVER?',\n        #                    set_cmd=':TRIG:AVER {}',\n        #                    get_parser=int,\n        #                    vals=vals.Ints(0, 1)\n        #                    )\n\n        self.add_parameter('avg_num',\n                           get_cmd='SENS1:AVER:COUN?',\n                           set_cmd='SENS1:AVER:COUN {}',\n                           vals=vals.Ints(1),\n                           get_parser=int\n                           )\n        self.add_parameter('avg_type',\n                           get_cmd='SENS1:AVER:MODE?',\n                           set_cmd='SENS1:AVER:MODE {}',\n                           vals=vals.Enum('POIN', 'SWEEP'),\n                           get_parser=str\n                           )\n        self.add_parameter('phase_offset',\n                           get_cmd='CALC1:CORR:OFFS:PHAS?',\n                           set_cmd='CALC1:CORR:OFFS:PHAS {}',\n                           get_parser=float,\n                           vals=vals.Numbers())\n        self.add_parameter('electrical_delay',\n                           get_cmd='CALC1:CORR:EDEL:TIME?',\n                           set_cmd='CALC1:CORR:EDEL:TIME {}',\n                           unit='s',\n                           get_parser=float,\n                           vals=vals.Numbers()\n                           )\n        self.add_parameter('trigger_source',\n                           get_cmd='TRIG:SOUR?',\n                           set_cmd='TRIG:SOUR {}',\n                           vals=vals.Enum('IMM', 'EXT', 'MAN')\n                           )\n        self.add_parameter('sweep_mode',\n                           get_cmd='SENS1:SWE:MODE?',\n                           set_cmd='SENS1:SWE:MODE {}',\n                           vals=vals.Enum('HOLD',\n                                          'CONT',\n                                          'GRO',\n                                          'SING'))\n        self.add_parameter('trigger_mode',\n                           get_cmd='SENS:SWE:TRIG:MODE?',\n                           set_cmd='SENS:SWE:TRIG:MODE {}',\n                           vals=vals.Enum('CHAN', 'SWE', 'POIN', 'TRAC')\n                           )\n        self.add_parameter('trform',\n                           get_cmd=':CALC1:FORM?',\n                           set_cmd=':CALC1:FORM {}',\n                           vals=vals.Enum('MLOG', 'PHAS',\n                                          'GDEL',\n                                          'SCOM', 'SMIT', 'SADM',\n                                          'POL', 'MLIN',\n                                          'SWR', 'REAL', 'IMAG',\n                                          'UPH', 'PPH', 'SLIN', 'SLOG', )\n                           )\n        self.add_parameter('math',\n                           get_cmd=':CALC1:MATH:FUNC?',\n                           set_cmd=':CALC1:MATH:FUNC {}',\n                           vals=vals.Enum('ADD', 'SUBT', 'DIV', 'MULT', 'NORM')\n                           )\n        self.add_parameter('sweep_type',\n                           get_cmd=':SENS1:SWE:TYPE?',\n                           set_cmd=':SENS1:SWE:TYPE {}',\n                           vals=vals.Enum('LIN', 'LOG', 'SEGM', 'POW')\n                           )\n        self.add_parameter('correction',\n                           get_cmd=':SENS1:CORR:STAT?',\n                           set_cmd=':SENS1:CORR:STAT {}',\n                           get_parser=int)\n        self.add_parameter('smoothing',\n                           get_cmd=':CALC1:SMO:STAT?',\n                           set_cmd=':CALC1:SMO:STAT {}',\n                           get_parser=float\n                           )\n        self.add_parameter('sweep_time',\n                           get_cmd=':SENS1:SWE:TIME?',\n                           set_cmd=None,  # generally just adjust ifbw and number of pts to change it,\n                           get_parser=float,\n                           unit='s'\n                           )\n\n        for i in range(1, 17):\n            trace = Trace(self, number=i, name=f\"trace_{i}\")\n            self.add_submodule(f\"trace_{i}\", trace)\n\n        self.connect_message()\n\n    def clear_all_traces(self):\n        \"\"\"remove all currently defined traces.\"\"\"\n        self.write(\"CALC:MEAS:DEL:ALL\")\n\n    def get_existing_traces_by_channel(self) -&gt; Dict[int, List[Tuple[int, str]]]:\n        \"\"\"Returns all currently available traces.\n        Assumes that traces/measurements do not have custom names not ending with the\n        measurement number.\n\n        Returns\n            A dictionary, with keys being the channel indices that have traces in them.\n            values are tuples of trace/measurement number and parameter measured.\n        \"\"\"\n        ret = {}\n        for i in range(1, 9):\n            traces = self.ask(f\"CALC{i}:PAR:CAT:EXT?\").strip('\"')\n            if traces == \"NO CATALOG\":\n                continue\n            else:\n                ret[i] = []\n            traces = traces.split(',')\n            names = traces[::2]\n            params = traces[1::2]\n            for n, p in zip(names, params):\n                ret[i].append((int(n.split('_')[-1]), p))\n        return ret\n\n    def get_existing_traces(self) -&gt; Tuple[List[int], List[int], List[str]]:\n        \"\"\"\n        Return three lists, with one item per current trace: channel, trace/measurement number, parameter\n        \"\"\"\n        chans, numbers, params = [], [], []\n        trace_dict = self.get_existing_traces_by_channel()\n        for chan, traces in trace_dict.items():\n            for number, param in traces:\n                chans.append(chan)\n                numbers.append(number)\n                params.append(param)\n        return chans, numbers, params\n\n    def get_sweep_data(self):\n        \"\"\"\n        Gets stimulus data in displayed range of active measurement, returns array\n        Will return different data depending on sweep type.\n\n        For example:\n            power sweep: 1xN array of powers in dBm\n            frequency sweep: 1xN array of freqs in Hz\n        Input:\n            None\n        Output:\n            sweep_values (Hz, dBm, etc...)\n        \"\"\"\n        logging.info(__name__ + ' : get stim data')\n        strdata = str(self.ask(':SENS1:X:VAL?'))\n        return np.array(list(map(float, strdata.split(','))))\n\n    def data_to_mem(self):\n        \"\"\"\n        Calls for data to be stored in memory\n        \"\"\"\n        logging.debug(__name__ + \": data to mem called\")\n        self.write(\":CALC1:MATH:MEM\")\n\n    def remove_trace(self, number: int):\n        \"\"\"\n        Remove selected trace\n\n        Note that when removing a new trace, vna will restart average.\n        \"\"\"\n        _, traces, _ = self.get_existing_traces()\n        if number not in traces:\n            print('Trace does not exist. Nothing happens.')\n        else:\n            logging.debug(__name__ + f\": remove trace{number}\")\n            self.write(f\"CALC1:MEAS{number}:DEL\")\n            print('Trace is successfully removed.')\n\n    def add_trace(self, number: int = 1, s_parameter: str = \"S21\"):\n        \"\"\"\n        Adds a trace with a specific s_parameter\n\n        Note that when adding a new trace, vna will restart average.\n        \"\"\"\n        _, traces, _ = self.get_existing_traces()\n        if number in traces:\n            print('Trace exist. Please use another trace number or remove the current one with remove_trace(number).')\n        else:\n            logging.debug(__name__ + f\": add trace{number} with S-parameter {s_parameter}\")\n            self.write(f\"CALC1:MEAS{number}:DEF '{s_parameter}'\")\n            self.write(f\"DISP:MEAS{number}:FEED 1\")  # always show this trace in the window 1 (FEED number).\n            print('Trace is successfully created.')\n\n    # TODO: add timout protection\n    def average(self) -&gt; Tuple[str, str, int]:\n        \"\"\"\n        Do the average self.avg_num() times.\n\n        Read the trigger settings (trigger source and mode) before doing the average and return them.\n        During the average the VNA will be in manual trigger source with single trigger mode.\n        A single trigger signal is generated with 'INIT:IMM' for self.avg_num() times to complete the whole average\n        process.\n\n        Note that after the average the VNA will remain in the trigger settings for the average process.\n        This is to give time for user to use another command to take the data from the trace/measurement.\n\n        The trace.data() will automatically take the old settings and put them back. But you can also just take the\n        return values of this function and reset by yourself.\n\n        Will check if VNA average type is in SWEEP. If not, a type error will be raised.\n        \"\"\"\n\n        if self.avg_type() == 'POIN':\n            raise TypeError(\n                'VNA average type is set to POINT, neeed to be SWEEP. Use vna.avg_type() function to change')\n        else:\n            prev_trigger_source = self.trigger_source()\n            prev_sweep_mode = self.sweep_mode()\n            prev_averaging = self.averaging()\n            # The following trigger settings are necessary for VNA to take the average\n            self.trigger_source('MAN')\n            self.sweep_mode('SING')\n            self.averaging(1)\n            self.write(\"SENS:AVER:CLE\")  # does not apply to point averaging\n            for i in range(self.avg_num()):\n                self.write('INIT:IMM')\n                averaged = 0\n                while averaged == 0:\n                    averaged = self.ask(\"*OPC?\")\n            print('Average completed')\n\n        return prev_trigger_source, prev_sweep_mode, prev_averaging\n\n    def clear_averages(self) -&gt; None:\n        \"\"\"Reset averaging and wait for new trigger to start over.\"\"\"\n        self.write('SENS:AVER:CLE')\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.__init__","title":"<code>__init__(name, address=None, **kwargs)</code>","text":"<p>Initializes the Keysight_P9374A, and communicates with the wrapper.</p> <p>Input:   name (string)    : name of the instrument   address (string) : GPIB address   reset (bool)     : resets to default values, default=False</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def __init__(self, name, address=None, **kwargs):\n\n    \"\"\"\n    Initializes the Keysight_P9374A, and communicates with the wrapper.\n\n    Input:\n      name (string)    : name of the instrument\n      address (string) : GPIB address\n      reset (bool)     : resets to default values, default=False\n    \"\"\"\n    if address is None:\n        raise Exception('TCP IP address needed')\n    logging.info(__name__ + ' : Initializing instrument Keysight PNA')\n\n    super().__init__(name, address, terminator='\\n', **kwargs)\n\n    self.write('CALC1:PAR:MNUM 1')  # sets the active msmt to the first channel/trace\n\n    # Add in parameters\n    self.add_parameter('fstart',\n                       get_cmd=':SENS1:FREQ:STAR?',\n                       set_cmd=':SENS1:FREQ:STAR {}',\n                       vals=vals.Numbers(),\n                       get_parser=float,\n                       unit='Hz'\n                       )\n    self.add_parameter('fstop',\n                       get_cmd=':SENS1:FREQ:STOP?',\n                       set_cmd=':SENS1:FREQ:STOP {}',\n                       vals=vals.Numbers(),\n                       get_parser=float,\n                       unit='Hz'\n                       )\n    self.add_parameter('fcenter',\n                       get_cmd=':SENS1:FREQ:CENT?',\n                       set_cmd=':SENS1:FREQ:CENT {}',\n                       vals=vals.Numbers(),\n                       get_parser=float,\n                       unit='Hz'\n                       )\n    self.add_parameter('fspan',\n                       get_cmd=':SENS1:FREQ:SPAN?',\n                       set_cmd=':SENS1:FREQ:SPAN {}',\n                       vals=vals.Numbers(),\n                       get_parser=float,\n                       unit='Hz'\n                       )\n    self.add_parameter('rfout',\n                       get_cmd=':OUTP?',\n                       set_cmd=':OUTP {}',\n                       vals=vals.Ints(0, 1),\n                       get_parser=int\n                       )\n    self.add_parameter('num_points',\n                       get_cmd=':SENS1:SWE:POIN?',\n                       set_cmd=':SENS1:SWE:POIN {}',\n                       vals=vals.Ints(1, 100000),\n                       get_parser=int\n                       )\n    self.add_parameter('ifbw',\n                       get_cmd=':SENS1:BWID?',\n                       set_cmd=':SENS1:BWID {}',\n                       vals=vals.Numbers(10, 1.5e6),\n                       get_parser=float)\n    self.add_parameter('power',\n                       get_cmd=\":SOUR1:POW?\",\n                       set_cmd=\":SOUR1:POW {}\",\n                       unit='dBm',\n                       get_parser=float,\n                       vals=vals.Numbers(-85, 20)\n                       )\n    self.add_parameter('power_start',\n                       get_cmd=':SOUR1:POW:STAR?',\n                       set_cmd=':SOUR1:POW:STAR {}',\n                       unit='dBm',\n                       get_parser=float,\n                       vals=vals.Numbers(-85, 10)\n                       )\n    self.add_parameter('power_stop',\n                       get_cmd=':SOUR:POW:STOP?',\n                       set_cmd=':SOUR1:POW:STOP {}',\n                       unit='dBm',\n                       get_parser=float,\n                       vals=vals.Numbers(-85, 10)),\n    self.add_parameter('averaging',\n                       get_cmd=':SENS1:AVER?',\n                       set_cmd=':SENS1:AVER {}',\n                       get_parser=int,\n                       vals=vals.Ints(0, 1)\n                       )\n    # TODO: this throws an error currently.\n    # self.add_parameter('average_trigger',\n    #                    get_cmd=':TRIG:AVER?',\n    #                    set_cmd=':TRIG:AVER {}',\n    #                    get_parser=int,\n    #                    vals=vals.Ints(0, 1)\n    #                    )\n\n    self.add_parameter('avg_num',\n                       get_cmd='SENS1:AVER:COUN?',\n                       set_cmd='SENS1:AVER:COUN {}',\n                       vals=vals.Ints(1),\n                       get_parser=int\n                       )\n    self.add_parameter('avg_type',\n                       get_cmd='SENS1:AVER:MODE?',\n                       set_cmd='SENS1:AVER:MODE {}',\n                       vals=vals.Enum('POIN', 'SWEEP'),\n                       get_parser=str\n                       )\n    self.add_parameter('phase_offset',\n                       get_cmd='CALC1:CORR:OFFS:PHAS?',\n                       set_cmd='CALC1:CORR:OFFS:PHAS {}',\n                       get_parser=float,\n                       vals=vals.Numbers())\n    self.add_parameter('electrical_delay',\n                       get_cmd='CALC1:CORR:EDEL:TIME?',\n                       set_cmd='CALC1:CORR:EDEL:TIME {}',\n                       unit='s',\n                       get_parser=float,\n                       vals=vals.Numbers()\n                       )\n    self.add_parameter('trigger_source',\n                       get_cmd='TRIG:SOUR?',\n                       set_cmd='TRIG:SOUR {}',\n                       vals=vals.Enum('IMM', 'EXT', 'MAN')\n                       )\n    self.add_parameter('sweep_mode',\n                       get_cmd='SENS1:SWE:MODE?',\n                       set_cmd='SENS1:SWE:MODE {}',\n                       vals=vals.Enum('HOLD',\n                                      'CONT',\n                                      'GRO',\n                                      'SING'))\n    self.add_parameter('trigger_mode',\n                       get_cmd='SENS:SWE:TRIG:MODE?',\n                       set_cmd='SENS:SWE:TRIG:MODE {}',\n                       vals=vals.Enum('CHAN', 'SWE', 'POIN', 'TRAC')\n                       )\n    self.add_parameter('trform',\n                       get_cmd=':CALC1:FORM?',\n                       set_cmd=':CALC1:FORM {}',\n                       vals=vals.Enum('MLOG', 'PHAS',\n                                      'GDEL',\n                                      'SCOM', 'SMIT', 'SADM',\n                                      'POL', 'MLIN',\n                                      'SWR', 'REAL', 'IMAG',\n                                      'UPH', 'PPH', 'SLIN', 'SLOG', )\n                       )\n    self.add_parameter('math',\n                       get_cmd=':CALC1:MATH:FUNC?',\n                       set_cmd=':CALC1:MATH:FUNC {}',\n                       vals=vals.Enum('ADD', 'SUBT', 'DIV', 'MULT', 'NORM')\n                       )\n    self.add_parameter('sweep_type',\n                       get_cmd=':SENS1:SWE:TYPE?',\n                       set_cmd=':SENS1:SWE:TYPE {}',\n                       vals=vals.Enum('LIN', 'LOG', 'SEGM', 'POW')\n                       )\n    self.add_parameter('correction',\n                       get_cmd=':SENS1:CORR:STAT?',\n                       set_cmd=':SENS1:CORR:STAT {}',\n                       get_parser=int)\n    self.add_parameter('smoothing',\n                       get_cmd=':CALC1:SMO:STAT?',\n                       set_cmd=':CALC1:SMO:STAT {}',\n                       get_parser=float\n                       )\n    self.add_parameter('sweep_time',\n                       get_cmd=':SENS1:SWE:TIME?',\n                       set_cmd=None,  # generally just adjust ifbw and number of pts to change it,\n                       get_parser=float,\n                       unit='s'\n                       )\n\n    for i in range(1, 17):\n        trace = Trace(self, number=i, name=f\"trace_{i}\")\n        self.add_submodule(f\"trace_{i}\", trace)\n\n    self.connect_message()\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.add_trace","title":"<code>add_trace(number=1, s_parameter='S21')</code>","text":"<p>Adds a trace with a specific s_parameter</p> <p>Note that when adding a new trace, vna will restart average.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def add_trace(self, number: int = 1, s_parameter: str = \"S21\"):\n    \"\"\"\n    Adds a trace with a specific s_parameter\n\n    Note that when adding a new trace, vna will restart average.\n    \"\"\"\n    _, traces, _ = self.get_existing_traces()\n    if number in traces:\n        print('Trace exist. Please use another trace number or remove the current one with remove_trace(number).')\n    else:\n        logging.debug(__name__ + f\": add trace{number} with S-parameter {s_parameter}\")\n        self.write(f\"CALC1:MEAS{number}:DEF '{s_parameter}'\")\n        self.write(f\"DISP:MEAS{number}:FEED 1\")  # always show this trace in the window 1 (FEED number).\n        print('Trace is successfully created.')\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.average","title":"<code>average()</code>","text":"<p>Do the average self.avg_num() times.</p> <p>Read the trigger settings (trigger source and mode) before doing the average and return them. During the average the VNA will be in manual trigger source with single trigger mode. A single trigger signal is generated with 'INIT:IMM' for self.avg_num() times to complete the whole average process.</p> <p>Note that after the average the VNA will remain in the trigger settings for the average process. This is to give time for user to use another command to take the data from the trace/measurement.</p> <p>The trace.data() will automatically take the old settings and put them back. But you can also just take the return values of this function and reset by yourself.</p> <p>Will check if VNA average type is in SWEEP. If not, a type error will be raised.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def average(self) -&gt; Tuple[str, str, int]:\n    \"\"\"\n    Do the average self.avg_num() times.\n\n    Read the trigger settings (trigger source and mode) before doing the average and return them.\n    During the average the VNA will be in manual trigger source with single trigger mode.\n    A single trigger signal is generated with 'INIT:IMM' for self.avg_num() times to complete the whole average\n    process.\n\n    Note that after the average the VNA will remain in the trigger settings for the average process.\n    This is to give time for user to use another command to take the data from the trace/measurement.\n\n    The trace.data() will automatically take the old settings and put them back. But you can also just take the\n    return values of this function and reset by yourself.\n\n    Will check if VNA average type is in SWEEP. If not, a type error will be raised.\n    \"\"\"\n\n    if self.avg_type() == 'POIN':\n        raise TypeError(\n            'VNA average type is set to POINT, neeed to be SWEEP. Use vna.avg_type() function to change')\n    else:\n        prev_trigger_source = self.trigger_source()\n        prev_sweep_mode = self.sweep_mode()\n        prev_averaging = self.averaging()\n        # The following trigger settings are necessary for VNA to take the average\n        self.trigger_source('MAN')\n        self.sweep_mode('SING')\n        self.averaging(1)\n        self.write(\"SENS:AVER:CLE\")  # does not apply to point averaging\n        for i in range(self.avg_num()):\n            self.write('INIT:IMM')\n            averaged = 0\n            while averaged == 0:\n                averaged = self.ask(\"*OPC?\")\n        print('Average completed')\n\n    return prev_trigger_source, prev_sweep_mode, prev_averaging\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.clear_all_traces","title":"<code>clear_all_traces()</code>","text":"<p>remove all currently defined traces.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def clear_all_traces(self):\n    \"\"\"remove all currently defined traces.\"\"\"\n    self.write(\"CALC:MEAS:DEL:ALL\")\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.clear_averages","title":"<code>clear_averages()</code>","text":"<p>Reset averaging and wait for new trigger to start over.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def clear_averages(self) -&gt; None:\n    \"\"\"Reset averaging and wait for new trigger to start over.\"\"\"\n    self.write('SENS:AVER:CLE')\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.data_to_mem","title":"<code>data_to_mem()</code>","text":"<p>Calls for data to be stored in memory</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def data_to_mem(self):\n    \"\"\"\n    Calls for data to be stored in memory\n    \"\"\"\n    logging.debug(__name__ + \": data to mem called\")\n    self.write(\":CALC1:MATH:MEM\")\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.get_existing_traces","title":"<code>get_existing_traces()</code>","text":"<p>Return three lists, with one item per current trace: channel, trace/measurement number, parameter</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def get_existing_traces(self) -&gt; Tuple[List[int], List[int], List[str]]:\n    \"\"\"\n    Return three lists, with one item per current trace: channel, trace/measurement number, parameter\n    \"\"\"\n    chans, numbers, params = [], [], []\n    trace_dict = self.get_existing_traces_by_channel()\n    for chan, traces in trace_dict.items():\n        for number, param in traces:\n            chans.append(chan)\n            numbers.append(number)\n            params.append(param)\n    return chans, numbers, params\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.get_existing_traces_by_channel","title":"<code>get_existing_traces_by_channel()</code>","text":"<p>Returns all currently available traces. Assumes that traces/measurements do not have custom names not ending with the measurement number.</p> <p>Returns     A dictionary, with keys being the channel indices that have traces in them.     values are tuples of trace/measurement number and parameter measured.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def get_existing_traces_by_channel(self) -&gt; Dict[int, List[Tuple[int, str]]]:\n    \"\"\"Returns all currently available traces.\n    Assumes that traces/measurements do not have custom names not ending with the\n    measurement number.\n\n    Returns\n        A dictionary, with keys being the channel indices that have traces in them.\n        values are tuples of trace/measurement number and parameter measured.\n    \"\"\"\n    ret = {}\n    for i in range(1, 9):\n        traces = self.ask(f\"CALC{i}:PAR:CAT:EXT?\").strip('\"')\n        if traces == \"NO CATALOG\":\n            continue\n        else:\n            ret[i] = []\n        traces = traces.split(',')\n        names = traces[::2]\n        params = traces[1::2]\n        for n, p in zip(names, params):\n            ret[i].append((int(n.split('_')[-1]), p))\n    return ret\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.get_sweep_data","title":"<code>get_sweep_data()</code>","text":"<p>Gets stimulus data in displayed range of active measurement, returns array Will return different data depending on sweep type.</p> <p>For example:     power sweep: 1xN array of powers in dBm     frequency sweep: 1xN array of freqs in Hz Input:     None Output:     sweep_values (Hz, dBm, etc...)</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def get_sweep_data(self):\n    \"\"\"\n    Gets stimulus data in displayed range of active measurement, returns array\n    Will return different data depending on sweep type.\n\n    For example:\n        power sweep: 1xN array of powers in dBm\n        frequency sweep: 1xN array of freqs in Hz\n    Input:\n        None\n    Output:\n        sweep_values (Hz, dBm, etc...)\n    \"\"\"\n    logging.info(__name__ + ' : get stim data')\n    strdata = str(self.ask(':SENS1:X:VAL?'))\n    return np.array(list(map(float, strdata.split(','))))\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Keysight_P9374A_SingleChannel.remove_trace","title":"<code>remove_trace(number)</code>","text":"<p>Remove selected trace</p> <p>Note that when removing a new trace, vna will restart average.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>def remove_trace(self, number: int):\n    \"\"\"\n    Remove selected trace\n\n    Note that when removing a new trace, vna will restart average.\n    \"\"\"\n    _, traces, _ = self.get_existing_traces()\n    if number not in traces:\n        print('Trace does not exist. Nothing happens.')\n    else:\n        logging.debug(__name__ + f\": remove trace{number}\")\n        self.write(f\"CALC1:MEAS{number}:DEL\")\n        print('Trace is successfully removed.')\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.SParameterData","title":"<code>SParameterData</code>","text":"<p>             Bases: <code>Parameter</code></p> <p>SParameterData(Parameter)</p> <p>Qcodes parameter that can be used to set/get the S-parameter of this measurement.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>class SParameterData(Parameter):\n    \"\"\"\n    SParameterData(Parameter)\n\n    Qcodes parameter that can be used to set/get the S-parameter of this measurement.\n\n    \"\"\"\n\n    def __init__(self, trace_number: int, *args: Any, **kwargs: Any) -&gt; None:\n        super().__init__(*args, **kwargs)\n        self.trace_number = trace_number\n\n    def get_raw(self) -&gt; ParamRawDataType:\n        _, traces, _ = self.root_instrument.get_existing_traces()\n        if self.instrument.npts() == 0 or self.trace_number not in traces:\n            return 'Trace is not on'\n\n        data = self.root_instrument.ask(f\":CALC1:MEAS{self.trace_number}:PAR?\").strip('\"')\n        return data\n\n    def set_raw(self, S_parameter: str = 'S21') -&gt; None:\n        _, traces, _ = self.root_instrument.get_existing_traces()\n        if self.instrument.npts() == 0 or self.trace_number not in traces:\n            return 'Trace is not on'\n\n        self.root_instrument.write(f\":CALC1:MEAS{self.trace_number}:PAR {S_parameter}\")\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.Trace","title":"<code>Trace</code>","text":"<p>             Bases: <code>InstrumentChannel</code></p> <p>A Qcode InstrumentChannel creates from the parameter instrument: Keysight_P9374A_SingleChannel.</p> <p>This InstrumentChannel contains all the parameters and functions that are unique for each different trace/measurement.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>class Trace(InstrumentChannel):\n    \"\"\"\n    A Qcode InstrumentChannel creates from the parameter instrument: Keysight_P9374A_SingleChannel.\n\n    This InstrumentChannel contains all the parameters and functions that are unique for each different\n    trace/measurement.\n    \"\"\"\n\n    def __init__(self, parent: \"Keysight_P9374A_SingleChannel\", number: int, name: str, **kwargs: Any):\n        self._number = number\n        super().__init__(parent, name=name, **kwargs)\n\n        self.add_parameter(\n            name='npts',\n            unit='',\n            get_cmd=self._get_npts,\n            docstring='number of points in the trace',\n        )\n\n        self.add_parameter(\n            name='frequency',\n            unit='Hz',\n            parameter_class=FrequencyData,\n            trace_number=self._number,\n            vals=vals.Arrays(shape=(self.npts.get_latest,)),\n            snapshot_exclude=True,\n        )\n\n        self.add_parameter(\n            name='data',\n            unit='',\n            setpoints=(self.frequency,),\n            parameter_class=TraceData,\n            trace_number=self._number,\n            vals=vals.Arrays(shape=(self.npts.get_latest,),\n                             valid_types=(np.floating, np.complexfloating)),\n            snapshot_exclude=True,\n        )\n\n        self.add_parameter(\n            name='s_parameter',\n            unit='',\n            parameter_class=SParameterData,\n            trace_number=self._number,\n            vals=vals.Enum('S11', 'S12', 'S21', 'S22'),\n            get_parser=str\n        )\n\n    def _get_npts(self):\n        return len(self._get_xdata())\n\n    def _get_xdata(self) -&gt; np.ndarray:\n        _, traces, _ = self.root_instrument.get_existing_traces()\n        if self._number not in traces:\n            return np.array([])\n        data = self.ask(f\"CALC:MEAS{self._number}:X?\")\n        return np.array(data.split(',')).astype(float)\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Keysight.Keysight_P937A.TraceData","title":"<code>TraceData</code>","text":"<p>             Bases: <code>ParameterWithSetpoints</code></p> <p>TraceData(ParameterWithSetpoints)</p> <p>Qcodes ParameterWithSetpoints that can be used to get the data of this measurement. VNA will be set to polar format \"POL\" to acquire data by default. If the VNA is in a different measurement format, it will be reset to that format after measurement, other wise VNA will remain in format of self.data_fmt after the measurement.</p> Source code in <code>labcore/instruments/qcodes_drivers/Keysight/Keysight_P937A.py</code> <pre><code>class TraceData(ParameterWithSetpoints):\n    \"\"\"\n    TraceData(ParameterWithSetpoints)\n\n    Qcodes ParameterWithSetpoints that can be used to get the data of this measurement.\n    VNA will be set to polar format \"POL\" to acquire data by default.\n    If the VNA is in a different measurement format, it will be reset to that format after measurement, other wise VNA\n    will remain in format of self.data_fmt after the measurement.\n\n    \"\"\"\n\n    def __init__(self, trace_number: int, *args: Any, **kwargs: Any) -&gt; None:\n        super().__init__(*args, **kwargs)\n        self.trace_number = trace_number\n        self.data_fmt = \"POL\"\n\n    def get_raw(self) -&gt; ParamRawDataType:\n        _, traces, _ = self.root_instrument.get_existing_traces()\n        if self.instrument.npts() == 0 or self.trace_number not in traces:\n            return np.array([])\n\n        # get the values of relevant parameters before taking the trace\n        prev_fmt = None\n        if self.data_fmt is not None:\n            prev_fmt = self.root_instrument.ask(f\"CALC:MEAS{self.trace_number}:FORM?\")\n            self.root_instrument.write(f\"CALC:MEAS{self.trace_number}:FORM {self.data_fmt}\")\n\n        # Code will check if VNA average trpe is SWEEP.\n        # If not a type error will be raised.\n        try:\n            prev_trigger_source, prev_sweep_mode, prev_averaging = self.root_instrument.average()\n            data = self.root_instrument.ask(f\"CALC:MEAS{self.trace_number}:DATA:FDATA?\")\n            # set relevant parameters back to their old values\n            self.root_instrument.trigger_source(prev_trigger_source)\n            self.root_instrument.sweep_mode(prev_sweep_mode)\n            self.root_instrument.averaging(prev_averaging)\n            if prev_fmt is not None:\n                self.root_instrument.write(f\"CALC:MEAS{self.trace_number}:FORM {prev_fmt}\")\n\n            # process complex data correctly\n            data = np.array(data.split(',')).astype(float)\n            if self.data_fmt in ['POL'] and data.size % 2 == 0:\n                data = data.reshape((int(data.size / 2), 2))\n                data = data[:, 0] + 1j * data[:, 1]\n            return data\n\n        except Exception as e:\n            print(f\"Data taking failed. {type(e)}: {e.args}\")\n            return np.zeros(self.instrument.npts())\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore","title":"<code>SignalCore</code>","text":"<p>Created on Wed May 20 09:12:21 2020</p> <p>@author: Ryan K</p>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a","title":"<code>SignalCore_sc5511a</code>","text":"<p>Created on Fri Mar 19 14:11:31 2021</p> <p>@author: Chao Zhou</p> <p>A simple driver for SignalCore SC5511A to be used with QCoDes, transferred from the one written by Erick Brindock</p>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A","title":"<code>SignalCore_SC5511A</code>","text":"<p>             Bases: <code>Instrument</code></p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>class SignalCore_SC5511A(Instrument):\n\n    if platform.system() == 'Windows':\n        dllpath = r\"C:\\Program Files\\SignalCore\\SC5511A\\api\\c\\x64\\sc5511a.dll\"\n    else:\n        dllpath = r\"/home/pfafflab/Documents/drivers/Linux/libusb/lib/libsc55511a.so.1.0\"\n\n    def __init__(self, name: str, serial_number: str,\n                 dllpath: Optional[str] = None, debug=False, **kwargs: Any):\n        super().__init__(name, **kwargs)\n\n        logging.info(__name__ + f' : Initializing instrument SignalCore generator {serial_number}')\n        if dllpath is not None:\n            self._dll = ctypes.CDLL(dllpath)\n        else:\n            self._dll = ctypes.CDLL(self.dllpath)\n\n        if debug:\n            print(self._dll)\n\n        self._dll.sc5511a_open_device.restype = ctypes.c_uint64\n        self._handle = ctypes.c_void_p(\n            self._dll.sc5511a_open_device(ctypes.c_char_p(bytes(serial_number, 'utf-8'))))\n        self._serial_number = ctypes.c_char_p(bytes(serial_number, 'utf-8'))\n        self._rf_params = Device_rf_params_t(0, 0, 0, 0, 0, 0, 0, 0, 0)\n        self._status = Operate_status_t(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n        self._open = False\n        self._temperature = Device_temperature_t(0)\n\n        self._pll_status = Pll_status_t()\n        self._list_mode = List_mode_t()\n        self._device_status = Device_status_t(self._list_mode, self._status, self._pll_status)\n        if debug:\n            print(serial_number, self._handle)\n            self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n            status = self._device_status.operate_status_t.rf1_out_enable\n            print('check status', status)\n\n        self._dll.sc5511a_close_device(self._handle)\n        self._device_info = Device_info_t(0, 0, 0, 0)\n        self.get_idn()\n        self.do_set_auto_level_disable(0)  # setting this to 1 will lead to unstable output power\n\n        self.add_parameter('sweep_start_frequency',\n                           label='sweep_start_frequency',\n                           get_cmd=self.do_get_sweep_start_frequency,\n                           get_parser=float,\n                           set_cmd=self.do_set_sweep_start_frequency,\n                           set_parser=float,\n                           unit='Hz',\n                           vals=Numbers(min_value=0, max_value=20e9)\n                           )\n\n        self.add_parameter('sweep_stop_frequency',\n                           label='sweep_stop_frequency',\n                           get_cmd=self.do_get_sweep_stop_frequency,\n                           get_parser=float,\n                           set_cmd=self.do_set_sweep_stop_frequency,\n                           set_parser=float,\n                           unit='Hz',\n                           vals=Numbers(min_value=0, max_value=20e9)\n                           )\n\n        self.add_parameter('sweep_step_frequency',\n                           label='sweep_step_frequency',\n                           get_cmd=self.do_get_sweep_step_frequency,\n                           get_parser=float,\n                           set_cmd=self.do_set_sweep_step_frequency,\n                           set_parser=float,\n                           unit='Hz',\n                           vals=Numbers(min_value=0, max_value=20e9)\n                           )\n\n        self.add_parameter('sweep_dwell_time',\n                           label='sweep_dwell_time',\n                           get_cmd=self.do_get_sweep_dwell_time,\n                           get_parser=int,\n                           set_cmd=self.do_set_sweep_dwell_time,\n                           set_parser=int,\n                           unit='',\n                           vals=Numbers(min_value=1)\n                           )\n\n        self.add_parameter('sweep_cycles',\n                           label='sweep_cycles',\n                           get_cmd=self.do_get_sweep_cycles,\n                           get_parser=int,\n                           set_cmd=self.do_set_sweep_cycles,\n                           set_parser=int,\n                           unit='',\n                           vals=Numbers(min_value=0)\n                           )\n\n        self.add_parameter('trig_out_enable',\n                           label='trig_out_enable',\n                           get_cmd=self.do_get_trig_out_enable,\n                           set_cmd=self.do_set_trig_out_enable,\n                           unit='',\n                           vals=vals.Enum(0, 1)\n                           )\n\n        self.add_parameter('trig_out_on_cycle',\n                           label='trig_out_on_cycle',\n                           get_cmd=self.do_get_trig_out_on_cycle,\n                           set_cmd=self.do_set_trig_out_on_cycle,\n                           unit='',\n                           vals=vals.Enum(0, 1)\n                           )\n\n        self.add_parameter('step_on_hw_trig',\n                           label='step_on_hw_trig',\n                           get_cmd=self.do_get_step_on_hw_trig,\n                           set_cmd=self.do_set_step_on_hw_trig,\n                           unit='',\n                           vals=vals.Enum(0, 1)\n                           )\n\n        self.add_parameter('return_to_start',\n                           label='return_to_start',\n                           get_cmd=self.do_get_return_to_start,\n                           set_cmd=self.do_set_return_to_start,\n                           unit='',\n                           vals=vals.Enum(0, 1)\n                           )\n\n        self.add_parameter('hw_trigger',\n                           label='hw_trigger',\n                           get_cmd=self.do_get_hw_trig,\n                           set_cmd=self.do_set_hw_trig,\n                           unit='',\n                           vals=vals.Enum(0, 1)\n                           )\n\n        self.add_parameter('tri_waveform',\n                           label='tri_waveform',\n                           get_cmd=self.do_get_tri_waveform,\n                           set_cmd=self.do_set_tri_waveform,\n                           unit='',\n                           vals=vals.Enum(0, 1)\n                           )\n\n        self.add_parameter('sweep_dir',\n                           label='sweep_dir',\n                           get_cmd=self.do_get_sweep_dir,\n                           set_cmd=self.do_set_sweep_dir,\n                           unit='',\n                           vals=vals.Enum(0, 1)\n                           )\n\n        self.add_parameter('sss_mode',\n                           label='sss_mode',\n                           get_cmd=self.do_get_sss_mode,\n                           set_cmd=self.do_set_sss_mode,\n                           unit='',\n                           vals=vals.Enum(0, 1)\n                           )\n\n        self.add_parameter('rf1_mode',\n                           label='rf1_mode',\n                           get_cmd=self.do_get_rf1_mode,\n                           set_cmd=self.do_set_rf1_mode,\n                           unit='',\n                           )\n\n        self.add_parameter('power',\n                           label='power',\n                           get_cmd=self.do_get_power,\n                           get_parser=float,\n                           set_cmd=self.do_set_power,\n                           set_parser=float,\n                           unit='dBm',\n                           vals=Numbers(min_value=-144, max_value=19))\n\n        self.add_parameter('output_status',\n                           label='output_status',\n                           get_cmd=self.do_get_output_status,\n                           get_parser=int,\n                           set_cmd=self.do_set_output_status,\n                           set_parser=int,\n                           vals=Numbers(min_value=0, max_value=1))\n\n        self.add_parameter('frequency',\n                           label='frequency',\n                           get_cmd=self.do_get_frequency,\n                           get_parser=float,\n                           set_cmd=self.do_set_frequency,\n                           set_parser=float,\n                           unit='Hz',\n                           vals=Numbers(min_value=0, max_value=20e9))\n\n        self.add_parameter('reference_source',\n                           label='reference_source',\n                           get_cmd=self.do_get_reference_source,\n                           get_parser=int,\n                           set_cmd=self.do_set_reference_source,\n                           set_parser=int,\n                           vals=Numbers(min_value=0, max_value=1))\n\n        self.add_parameter('auto_level_disable',\n                           label='0 = power is leveled on frequency change',\n                           get_cmd=self.do_get_auto_level_disable,\n                           get_parser=int,\n                           set_cmd=self.do_set_auto_level_disable,\n                           set_parser=int,\n                           vals=Numbers(min_value=0, max_value=1))\n\n        self.add_parameter('temperature',\n                           label='temperature',\n                           get_cmd=self.do_get_device_temp,\n                           get_parser=float,\n                           unit=\"C\",\n                           vals=Numbers(min_value=0, max_value=200))\n\n        if self._device_status.operate_status_t.ext_ref_lock_enable == 0:\n            self.do_set_reference_source(1)\n\n    @classmethod\n    def connected_instruments(cls, max_n_gens: int = 100, sn_len: int = 100) -&gt; List[str]:\n        \"\"\"\n        Return the serial numbers of the connected generators.\n\n        The parameters are very unlikely to be needed, and are just for making sure\n        we allocated the right amount of memory when calling the SignalCore DLL.\n        Parameters:\n            max_n_gens: maximum number of generators expected\n            sn_len: max length of serial numbers.\n        \"\"\"\n        dll = ctypes.CDLL(cls.dllpath)\n        search = dll.sc5511a_search_devices\n\n        # generate and allocate string memory\n        mem_type = (ctypes.c_char_p * max_n_gens)\n        mem = mem_type()\n        for i in range(max_n_gens):\n            mem[i] = b' ' * sn_len\n\n        search.argtypes = [mem_type]\n        n_gens_found = search(mem)\n        return [sn.decode('utf-8') for sn in mem[:n_gens_found]]\n\n    def set_open(self, open) -&gt; bool:\n        if open and not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            self._open = True\n        elif not open and self._open:\n            self._dll.sc5511a_close_device(self._handle)\n            self._open = False\n        return True\n\n    def soft_trigger(self) -&gt; None:\n        \"\"\"\n        Send out a soft trigger, so that the we can start the sweep\n        Generator need to be configured for list mode and soft trigger is selected as the trigger source\n        \"\"\"\n        logging.info(__name__ + ' : Send a soft trigger to the generator')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_list_soft_trigger(self._handle)\n        self._dll.sc5511a_close_device(self._handle)\n        return None\n\n    def do_set_output_status(self, enable) -&gt; None:\n        \"\"\"\n        Turns the output of RF1 on or off.\n            Input:\n                enable (int) = OFF = 0 ; ON = 1\n        \"\"\"\n        logging.info(__name__ + ' : Setting output to %s' % enable)\n        c_enable = ctypes.c_ubyte(enable)\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        completed = self._dll.sc5511a_set_output(self._handle, c_enable)\n        self._dll.sc5511a_close_device(self._handle)\n        return completed\n\n    def do_get_output_status(self) -&gt; int:\n        \"\"\"\n        Reads the output status of RF1\n            Output:\n                status (int) : OFF = 0 ; ON = 1\n        \"\"\"\n        logging.info(__name__ + ' : Getting output')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        status = self._device_status.operate_status_t.rf1_out_enable\n        self._dll.sc5511a_close_device(self._handle)\n        return status\n\n    def do_set_sweep_start_frequency(self, sweep_start_frequency) -&gt; None:\n        \"\"\"\n        Set the sweep start frequency of RF1 in the unit of Hz\n        \"\"\"\n        c_sweep_start_freq = ctypes.c_ulonglong(int(sweep_start_frequency))\n        logging.info(__name__ + ' : Setting sweep start frequency to %s' % sweep_start_frequency)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n        if_set = self._dll.sc5511a_list_start_freq(self._handle, c_sweep_start_freq)\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_sweep_start_frequency(self) -&gt; float:\n        \"\"\"\n        Get the sweep start frequency that is used in the sweep mode\n        The frequency returned is in the unit of Hz\n        \"\"\"\n        logging.info(__name__ + 'Getting sweep start frequency')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n        sweep_start_frequency = self._rf_params.start_freq\n        self._dll.sc5511a_close_device(self._handle)\n        return sweep_start_frequency\n\n    def do_set_sweep_stop_frequency(self, sweep_stop_frequency) -&gt; None:\n        \"\"\"\n        Set the sweep stop frequency of RF1 in the unit of Hz\n        \"\"\"\n        c_sweep_stop_frequency = ctypes.c_ulonglong(int(sweep_stop_frequency))\n        logging.info(__name__ + ' : Setting sweep stop frequency to %s' % sweep_stop_frequency)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n        if_set = self._dll.sc5511a_list_stop_freq(self._handle, c_sweep_stop_frequency)\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_sweep_stop_frequency(self) -&gt; float:\n        \"\"\"\n        Get the sweep stop frequency that is used in the sweep mode\n        The frequency returned is in the unit of Hz\n        \"\"\"\n        logging.info(__name__ + 'Getting sweep stop frequency')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n        sweep_stop_frequency = self._rf_params.stop_freq\n        self._dll.sc5511a_close_device(self._handle)\n        return sweep_stop_frequency\n\n    def do_set_sweep_step_frequency(self, sweep_step_frequency) -&gt; None:\n        \"\"\"\n        Set the sweep step frequency of RF1 in the unit of Hz\n        \"\"\"\n        c_sweep_step_frequency = ctypes.c_ulonglong(int(sweep_step_frequency))\n        logging.info(__name__ + ' : Setting sweep step frequency to %s' % sweep_step_frequency)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n        if_set = self._dll.sc5511a_list_step_freq(self._handle, c_sweep_step_frequency)\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_sweep_step_frequency(self) -&gt; float:\n        \"\"\"\n        Get the sweep step frequency that is used in the sweep mode\n        The frequency returned is in the unit of Hz\n        \"\"\"\n        logging.info(__name__ + 'Getting sweep step frequency')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n        sweep_step_frequency = self._rf_params.step_freq\n        self._dll.sc5511a_close_device(self._handle)\n        return sweep_step_frequency\n\n    def do_set_sweep_dwell_time(self, sweep_dwell_time) -&gt; None:\n        \"\"\"\n        Set the sweep/list time at each frequency point.\n        Note that the dwell time is set as multiple of 500 us.\n        The input value is an unsigned int, it means how many multiple of 500 us.\n        \"\"\"\n        c_sweep_dwell_time = ctypes.c_uint(int(sweep_dwell_time))\n        logging.info(__name__ + ': Setting sweep dwell time to %s' % sweep_dwell_time)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n        if_set = self._dll.sc5511a_list_dwell_time(self._handle, c_sweep_dwell_time)\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_sweep_dwell_time(self) -&gt; int:\n        \"\"\"\n        Get the dwell time of the sweep mode.\n        Return value is the unit multiple of 500 us, e.g. a return value 3 means the dwell time is 1500 us.\n        \"\"\"\n        logging.info(__name__ + 'Getting sweep dwell time in the unit of how many multiple of 500 us')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n        sweep_dwell_time = self._rf_params.sweep_dwell_time\n        self._dll.sc5511a_close_device(self._handle)\n        return sweep_dwell_time\n\n    def do_set_sweep_cycles(self, sweep_cycles) -&gt; None:\n        \"\"\"\n        Set the number of sweep cycles to perform before stopping.\n        To repeat the sweep continuously, set the value to 0.\n        \"\"\"\n        c_sweep_cycles = ctypes.c_uint(int(sweep_cycles))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % sweep_cycles)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n        if_set = self._dll.sc5511a_list_cycle_count(self._handle, c_sweep_cycles)\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_sweep_cycles(self) -&gt; int:\n        \"\"\"\n        Get the number of sweep cycles to perform before stopping.\n        To repeat the sweep continuously, the value is 0.\n        \"\"\"\n        logging.info(__name__ + 'Getting number of sweep cycles')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n        sweep_cycles = self._rf_params.sweep_cycles\n        self._dll.sc5511a_close_device(self._handle)\n        return sweep_cycles\n\n    def do_set_trig_out_enable(self, trig_out_enable) -&gt; None:\n        \"\"\"\n        Set the trigger output status.\n        It does not send out the trigger, just enable the generator to send out the trigger\n        0 = No trigger output\n        1 = Puts a trigger pulse on the TRIGOUT pin\n        \"\"\"\n        c_trig_out_enable = ctypes.c_ubyte(int(trig_out_enable))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % trig_out_enable)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        self._device_status.list_mode.trig_out_enable = c_trig_out_enable\n        if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_trig_out_enable(self) -&gt; int:\n        \"\"\"\n        Get the status of the trigger output status\n        0 = No trigger output\n        1 = Puts a trigger pulse on the TRIGOUT pin\n        \"\"\"\n        logging.info(__name__ + 'Getting trigger output status')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        trig_out_enable = self._device_status.list_mode.trig_out_enable\n        self._dll.sc5511a_close_device(self._handle)\n        return trig_out_enable\n\n    def do_set_trig_out_on_cycle(self, trig_out_on_cycle) -&gt; None:\n        \"\"\"\n        Set the trigger output mode\n        0 = Puts out a trigger pulse at each frequency change\n        1 = Puts out a trigger pulse at the completion of each sweep/list cycle\n        \"\"\"\n        c_trig_out_on_cycle = ctypes.c_ubyte(int(trig_out_on_cycle))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % trig_out_on_cycle)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        self._device_status.list_mode.trig_out_on_cycle = c_trig_out_on_cycle\n        if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_trig_out_on_cycle(self) -&gt; int:\n        \"\"\"\n        Get the trigger output mode\n        0 = Puts out a trigger pulse at each frequency change\n        1 = Puts out a trigger pulse at the completion of each sweep/list cycle\n        \"\"\"\n        logging.info(__name__ + 'Getting trigger output mode ')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        trig_out_enable = self._device_status.list_mode.trig_out_on_cycle\n        self._dll.sc5511a_close_device(self._handle)\n        return trig_out_enable\n\n    def do_set_step_on_hw_trig(self, step_on_hw_trig) -&gt; None:\n        \"\"\"\n        Set the behavior of the sweep/list mode when receiving a trigger.\n        0 = Start/Stop behavior. The sweep starts and continues to step through the list for the number of cycles set,\n            dwelling at each step frequency for a period set by the dwell time. The sweep/list will end on a consecutive\n            trigger.\n        1 = Step-on-trigger. This is only available if hardware triggering is selected. The device will step to the next\n            frequency on a trigger.Upon completion of the number of cycles, the device will exit from the stepping state\n            and stop.\n        \"\"\"\n        c_step_on_hw_trig = ctypes.c_ubyte(int(step_on_hw_trig))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % step_on_hw_trig)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        self._device_status.list_mode.step_on_hw_trig = c_step_on_hw_trig\n        if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_step_on_hw_trig(self) -&gt; int:\n        \"\"\"\n        Set the behavior of the sweep/list mode when receiving a trigger.\n        0 = Start/Stop behavior\n        1 = Step-on-trigger\n        \"\"\"\n        logging.info(__name__ + 'Getting status of step on trigger mode ')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        step_on_hw_trig = self._device_status.list_mode.step_on_hw_trig\n        self._dll.sc5511a_close_device(self._handle)\n        return step_on_hw_trig\n\n    def do_set_return_to_start(self, return_to_start) -&gt; None:\n        \"\"\"\n        Set how the frequency will change at the end of the list/sweep\n        0 = Stop at end of sweep/list. The frequency will stop at the last point of the sweep/list\n        1 = Return to start. The frequency will return and stop at the beginning point of the sweep or list after a\n            cycle.\n        \"\"\"\n        c_return_to_start = ctypes.c_ubyte(int(return_to_start))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % return_to_start)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        self._device_status.list_mode.return_to_start = c_return_to_start\n        if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_return_to_start(self) -&gt; int:\n        \"\"\"\n        Get the status of how the frequency will change at the end of the list/sweep\n        0 = Stop at end of sweep/list. The frequency will stop at the last point of the sweep/list\n        1 = Return to start. The frequency will return and stop at the beginning point of the sweep or list after a\n            cycle.\n        \"\"\"\n        logging.info(__name__ + 'Getting status of return to start ')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        return_to_start = self._device_status.list_mode.return_to_start\n        self._dll.sc5511a_close_device(self._handle)\n        return return_to_start\n\n    def do_set_hw_trig(self, hw_trigger) -&gt; None:\n        \"\"\"\n        Set the status of hardware trigger\n        0 = Software trigger. Softtrigger can only be used to start and stop a sweep/list cycle. It does not work for\n            step-on-trigger mode.\n        1 = Hardware trigger. A high-to-low transition on the TRIGIN pin will trigger the device. It can be used for\n            both start/stop or step-on-trigger functions.\n        \"\"\"\n        c_hw_trigger = ctypes.c_ubyte(int(hw_trigger))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % hw_trigger)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        self._device_status.list_mode.hw_trigger = c_hw_trigger\n        if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_hw_trig(self) -&gt; int:\n        \"\"\"\n        Get the status of hardware trigger\n        0 = Software trigger. Softtrigger can only be used to start and stop a sweep/list cycle. It does not work for\n            step-on-trigger mode.\n        1 = Hardware trigger. A high-to-low transition on the TRIGIN pin will trigger the device. It can be used for\n            both start/stop or step-on-trigger functions.\n        \"\"\"\n        logging.info(__name__ + 'Getting status of hardware trigger ')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        hw_trigger = self._device_status.list_mode.hw_trigger\n        self._dll.sc5511a_close_device(self._handle)\n        return hw_trigger\n\n    def do_set_tri_waveform(self, tri_waveform) -&gt; None:\n        \"\"\"\n        Set the triangular waveform of the generator\n        0 = Sawtooth waveform. Frequency returns to the beginning frequency upon reaching the end of a sweep cycle\n        1 = Triangular waveform. Frequency reverses direction at the end of the list and steps back towards the\n            beginning to complete a cycle\n        \"\"\"\n        c_tri_waveform = ctypes.c_ubyte(int(tri_waveform))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % tri_waveform)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        self._device_status.list_mode.tri_waveform = c_tri_waveform\n        if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_tri_waveform(self) -&gt; int:\n        \"\"\"\n        Get the triangular waveform of the generator\n        0 = Sawtooth waveform. Frequency returns to the beginning frequency upon reaching the end of a sweep cycle\n        1 = Triangular waveform. Frequency reverses direction at the end of the list and steps back towards the\n            beginning to complete a cycle\n        \"\"\"\n        logging.info(__name__ + 'Getting status of triangular waveform ')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        hw_trigger = self._device_status.list_mode.tri_waveform\n        self._dll.sc5511a_close_device(self._handle)\n        return hw_trigger\n\n    def do_set_sweep_dir(self, sweep_dir) -&gt; None:\n        \"\"\"\n        Set the sweep direction of the generator\n        0 = Forward. Sweeps start from the lowest start frequency or starts at the beginning of the list buffer\n        1 = Reverse. Sweeps start from the stop frequency and steps down toward the start frequency or starts at the\n            end and steps toward the beginning of the buffer\n        \"\"\"\n        c_sweep_dir = ctypes.c_ubyte(int(sweep_dir))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % sweep_dir)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        self._device_status.list_mode.sweep_dir = c_sweep_dir\n        if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_sweep_dir(self) -&gt; int:\n        \"\"\"\n        Get the sweep direction of the generator\n        0 = Forward. Sweeps start from the lowest start frequency or starts at the beginning of the list buffer\n        1 = Reverse. Sweeps start from the stop frequency and steps down toward the start frequency or starts at the\n            end and steps toward the beginning of the buffer\n        \"\"\"\n        logging.info(__name__ + 'Getting status of sweep direction ')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        hw_trigger = self._device_status.list_mode.sweep_dir\n        self._dll.sc5511a_close_device(self._handle)\n        return hw_trigger\n\n    def do_set_sss_mode(self, sss_mode) -&gt; None:\n        \"\"\"\n        Set the list/sweep mode of the generator\n        0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register\n        1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies\n        \"\"\"\n        c_sss_mode = ctypes.c_ubyte(int(sss_mode))\n        logging.info(__name__ + ': Setting sweep cycle number to %s ' % sss_mode)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        self._device_status.list_mode.sss_mode = c_sss_mode\n        if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_sss_mode(self) -&gt; int:\n        \"\"\"\n        Get the list/sweep mode of the generator\n        0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register\n        1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies\n        \"\"\"\n        logging.info(__name__ + 'Getting status of sss mode')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        sss_mode = self._device_status.list_mode.sss_mode\n        self._dll.sc5511a_close_device(self._handle)\n        return sss_mode\n\n    def do_set_rf1_mode(self, rf1_mode) -&gt; None:\n        \"\"\"\n        Set the RF mode for rf1\n        0 = single fixed tone mode\n        1 = sweep/list mode\n        \"\"\"\n        c_rf1_mode = ctypes.c_ubyte(rf1_mode)\n        logging.info(__name__ + ' : Setting frequency to %s' % rf1_mode)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n        if_set = self._dll.sc5511a_set_rf_mode(self._handle, c_rf1_mode)\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_rf1_mode(self) -&gt; int:\n        \"\"\"\n        Get the RF mode for rf1\n        0 = single fixed tone mode\n        1 = sweep/list mode\n        \"\"\"\n        logging.info(__name__ + 'Getting the RF mode for rf1')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        rf1_mode = self._device_status.operate_status_t.rf1_mode\n        self._dll.sc5511a_close_device(self._handle)\n        return rf1_mode\n\n    def do_set_frequency(self, frequency) -&gt; None:\n        \"\"\"\n        Sets RF1 frequency in the unit of Hz. Valid between 100MHz and 20GHz\n            Args:\n                frequency (int) = frequency in Hz\n        \"\"\"\n        c_freq = ctypes.c_ulonglong(int(frequency))\n        logging.info(__name__ + ' : Setting frequency to %s' % frequency)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n        if_set = self._dll.sc5511a_set_freq(self._handle, c_freq)\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return if_set\n\n    def do_get_frequency(self) -&gt; float:\n        \"\"\"\n        Gets RF1 frequency in the unit of Hz.\n        \"\"\"\n        logging.info(__name__ + ' : Getting frequency')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n        frequency = self._rf_params.rf1_freq\n        self._dll.sc5511a_close_device(self._handle)\n        return frequency\n\n    def do_set_reference_source(self, lock_to_external) -&gt; None:\n        \"\"\"\n        Set the generator reference source\n        0 = internal source\n        1 = external source\n\n        Note here high is set to 0, means we always use 10 MHz clock when use external lock\n        \"\"\"\n        logging.info(__name__ + ' : Setting reference source to %s' % lock_to_external)\n        high = ctypes.c_ubyte(0)\n        lock = ctypes.c_ubyte(lock_to_external)\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        source = self._dll.sc5511a_set_clock_reference(self._handle, high, lock)\n        self._dll.sc5511a_close_device(self._handle)\n        return source\n\n    def do_get_reference_source(self) -&gt; int:\n        \"\"\"\n        Get the generator reference source\n        0 = internal source\n        1 = external source\n        \"\"\"\n        logging.info(__name__ + ' : Getting reference source')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        enabled = self._device_status.operate_status_t.ext_ref_lock_enable\n        self._dll.sc5511a_close_device(self._handle)\n        return enabled\n\n    def do_set_power(self, power) -&gt; None:\n        \"\"\"\n        Set the power of the generator in the unit of dBm\n        \"\"\"\n        logging.info(__name__ + ' : Setting power to %s' % power)\n        c_power = ctypes.c_float(power)\n        close = False\n        if not self._open:\n            self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n            close = True\n        completed = self._dll.sc5511a_set_level(self._handle, c_power)\n        if close:\n            self._dll.sc5511a_close_device(self._handle)\n        return completed\n\n    def do_get_power(self) -&gt; float:\n        \"\"\"\n        Get the power of the generator in the unit of dBm\n        \"\"\"\n        logging.info(__name__ + ' : Getting Power')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n        rf_level = self._rf_params.rf_level\n        self._dll.sc5511a_close_device(self._handle)\n        return rf_level\n\n    def do_set_auto_level_disable(self, enable) -&gt; None:\n        \"\"\"\n        Set if we want to disable the auto level\n        \"\"\"\n        logging.info(__name__ + ' : Settingalc auto to %s' % enable)\n        if enable == 1:\n            enable = 0\n        elif enable == 0:\n            enable = 1\n        c_enable = ctypes.c_ubyte(enable)\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        completed = self._dll.sc5511a_set_auto_level_disable(self._handle, c_enable)\n        self._dll.sc5511a_close_device(self._handle)\n        return completed\n\n    def do_get_auto_level_disable(self) -&gt; int:\n        \"\"\"\n        Get if we disable to auto level\n        \"\"\"\n        logging.info(__name__ + ' : Getting alc auto status')\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n        enabled = self._device_status.operate_status_t.auto_pwr_disable\n        self._dll.sc5511a_close_device(self._handle)\n        if enabled == 1:\n            enabled = 0\n        elif enabled == 0:\n            enabled = 1\n        return enabled\n\n    def do_get_device_temp(self)  -&gt; float:\n        \"\"\"\n        Get the device temperature in unit of C\n        \"\"\"\n        logging.info(__name__ + \" : Getting device temperature\")\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_temperature(self._handle, ctypes.byref(self._temperature))\n        device_temp = self._temperature.device_temp\n        self._dll.sc5511a_close_device(self._handle)\n        return device_temp\n\n    def get_idn(self) -&gt; Dict[str, Optional[str]]:\n        \"\"\"\n        Get the identification information of the current device\n        \"\"\"\n        logging.info(__name__ + \" : Getting device info\")\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        self._dll.sc5511a_get_device_info(self._handle, ctypes.byref(self._device_info))\n        device_info = self._device_info\n        self._dll.sc5511a_close_device(self._handle)\n\n        def date_decode(date_int: int):\n            date_str = f\"{date_int:032b}\"\n            yr = f\"20{int(date_str[:8], 2)}\"\n            month = f\"{int(date_str[16:24], 2)}\"\n            day = f\"{int(date_str[8:16], 2)}\"\n            return f\"{month}/{day}/{yr}\"\n\n        IDN: Dict[str, Optional[str]] = {\n            'vendor': \"SignalCore\",\n            'model': \"SC5511A\",\n            'serial_number': self._serial_number.value.decode(\"utf-8\"),\n            'firmware_revision': device_info.firmware_revision,\n            'hardware_revision': device_info.hardware_revision,\n            'manufacture_date': date_decode(device_info.manufacture_date)\n        }\n        return IDN\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.connected_instruments","title":"<code>connected_instruments(max_n_gens=100, sn_len=100)</code>  <code>classmethod</code>","text":"<p>Return the serial numbers of the connected generators.</p> <p>The parameters are very unlikely to be needed, and are just for making sure we allocated the right amount of memory when calling the SignalCore DLL. Parameters:     max_n_gens: maximum number of generators expected     sn_len: max length of serial numbers.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>@classmethod\ndef connected_instruments(cls, max_n_gens: int = 100, sn_len: int = 100) -&gt; List[str]:\n    \"\"\"\n    Return the serial numbers of the connected generators.\n\n    The parameters are very unlikely to be needed, and are just for making sure\n    we allocated the right amount of memory when calling the SignalCore DLL.\n    Parameters:\n        max_n_gens: maximum number of generators expected\n        sn_len: max length of serial numbers.\n    \"\"\"\n    dll = ctypes.CDLL(cls.dllpath)\n    search = dll.sc5511a_search_devices\n\n    # generate and allocate string memory\n    mem_type = (ctypes.c_char_p * max_n_gens)\n    mem = mem_type()\n    for i in range(max_n_gens):\n        mem[i] = b' ' * sn_len\n\n    search.argtypes = [mem_type]\n    n_gens_found = search(mem)\n    return [sn.decode('utf-8') for sn in mem[:n_gens_found]]\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_auto_level_disable","title":"<code>do_get_auto_level_disable()</code>","text":"<p>Get if we disable to auto level</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_auto_level_disable(self) -&gt; int:\n    \"\"\"\n    Get if we disable to auto level\n    \"\"\"\n    logging.info(__name__ + ' : Getting alc auto status')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    enabled = self._device_status.operate_status_t.auto_pwr_disable\n    self._dll.sc5511a_close_device(self._handle)\n    if enabled == 1:\n        enabled = 0\n    elif enabled == 0:\n        enabled = 1\n    return enabled\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_device_temp","title":"<code>do_get_device_temp()</code>","text":"<p>Get the device temperature in unit of C</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_device_temp(self)  -&gt; float:\n    \"\"\"\n    Get the device temperature in unit of C\n    \"\"\"\n    logging.info(__name__ + \" : Getting device temperature\")\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_temperature(self._handle, ctypes.byref(self._temperature))\n    device_temp = self._temperature.device_temp\n    self._dll.sc5511a_close_device(self._handle)\n    return device_temp\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_frequency","title":"<code>do_get_frequency()</code>","text":"<p>Gets RF1 frequency in the unit of Hz.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_frequency(self) -&gt; float:\n    \"\"\"\n    Gets RF1 frequency in the unit of Hz.\n    \"\"\"\n    logging.info(__name__ + ' : Getting frequency')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n    frequency = self._rf_params.rf1_freq\n    self._dll.sc5511a_close_device(self._handle)\n    return frequency\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_hw_trig","title":"<code>do_get_hw_trig()</code>","text":"<p>Get the status of hardware trigger 0 = Software trigger. Softtrigger can only be used to start and stop a sweep/list cycle. It does not work for     step-on-trigger mode. 1 = Hardware trigger. A high-to-low transition on the TRIGIN pin will trigger the device. It can be used for     both start/stop or step-on-trigger functions.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_hw_trig(self) -&gt; int:\n    \"\"\"\n    Get the status of hardware trigger\n    0 = Software trigger. Softtrigger can only be used to start and stop a sweep/list cycle. It does not work for\n        step-on-trigger mode.\n    1 = Hardware trigger. A high-to-low transition on the TRIGIN pin will trigger the device. It can be used for\n        both start/stop or step-on-trigger functions.\n    \"\"\"\n    logging.info(__name__ + 'Getting status of hardware trigger ')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    hw_trigger = self._device_status.list_mode.hw_trigger\n    self._dll.sc5511a_close_device(self._handle)\n    return hw_trigger\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_output_status","title":"<code>do_get_output_status()</code>","text":"<p>Reads the output status of RF1     Output:         status (int) : OFF = 0 ; ON = 1</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_output_status(self) -&gt; int:\n    \"\"\"\n    Reads the output status of RF1\n        Output:\n            status (int) : OFF = 0 ; ON = 1\n    \"\"\"\n    logging.info(__name__ + ' : Getting output')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    status = self._device_status.operate_status_t.rf1_out_enable\n    self._dll.sc5511a_close_device(self._handle)\n    return status\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_power","title":"<code>do_get_power()</code>","text":"<p>Get the power of the generator in the unit of dBm</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_power(self) -&gt; float:\n    \"\"\"\n    Get the power of the generator in the unit of dBm\n    \"\"\"\n    logging.info(__name__ + ' : Getting Power')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n    rf_level = self._rf_params.rf_level\n    self._dll.sc5511a_close_device(self._handle)\n    return rf_level\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_reference_source","title":"<code>do_get_reference_source()</code>","text":"<p>Get the generator reference source 0 = internal source 1 = external source</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_reference_source(self) -&gt; int:\n    \"\"\"\n    Get the generator reference source\n    0 = internal source\n    1 = external source\n    \"\"\"\n    logging.info(__name__ + ' : Getting reference source')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    enabled = self._device_status.operate_status_t.ext_ref_lock_enable\n    self._dll.sc5511a_close_device(self._handle)\n    return enabled\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_return_to_start","title":"<code>do_get_return_to_start()</code>","text":"<p>Get the status of how the frequency will change at the end of the list/sweep 0 = Stop at end of sweep/list. The frequency will stop at the last point of the sweep/list 1 = Return to start. The frequency will return and stop at the beginning point of the sweep or list after a     cycle.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_return_to_start(self) -&gt; int:\n    \"\"\"\n    Get the status of how the frequency will change at the end of the list/sweep\n    0 = Stop at end of sweep/list. The frequency will stop at the last point of the sweep/list\n    1 = Return to start. The frequency will return and stop at the beginning point of the sweep or list after a\n        cycle.\n    \"\"\"\n    logging.info(__name__ + 'Getting status of return to start ')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    return_to_start = self._device_status.list_mode.return_to_start\n    self._dll.sc5511a_close_device(self._handle)\n    return return_to_start\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_rf1_mode","title":"<code>do_get_rf1_mode()</code>","text":"<p>Get the RF mode for rf1 0 = single fixed tone mode 1 = sweep/list mode</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_rf1_mode(self) -&gt; int:\n    \"\"\"\n    Get the RF mode for rf1\n    0 = single fixed tone mode\n    1 = sweep/list mode\n    \"\"\"\n    logging.info(__name__ + 'Getting the RF mode for rf1')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    rf1_mode = self._device_status.operate_status_t.rf1_mode\n    self._dll.sc5511a_close_device(self._handle)\n    return rf1_mode\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_sss_mode","title":"<code>do_get_sss_mode()</code>","text":"<p>Get the list/sweep mode of the generator 0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register 1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_sss_mode(self) -&gt; int:\n    \"\"\"\n    Get the list/sweep mode of the generator\n    0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register\n    1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies\n    \"\"\"\n    logging.info(__name__ + 'Getting status of sss mode')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    sss_mode = self._device_status.list_mode.sss_mode\n    self._dll.sc5511a_close_device(self._handle)\n    return sss_mode\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_step_on_hw_trig","title":"<code>do_get_step_on_hw_trig()</code>","text":"<p>Set the behavior of the sweep/list mode when receiving a trigger. 0 = Start/Stop behavior 1 = Step-on-trigger</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_step_on_hw_trig(self) -&gt; int:\n    \"\"\"\n    Set the behavior of the sweep/list mode when receiving a trigger.\n    0 = Start/Stop behavior\n    1 = Step-on-trigger\n    \"\"\"\n    logging.info(__name__ + 'Getting status of step on trigger mode ')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    step_on_hw_trig = self._device_status.list_mode.step_on_hw_trig\n    self._dll.sc5511a_close_device(self._handle)\n    return step_on_hw_trig\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_sweep_cycles","title":"<code>do_get_sweep_cycles()</code>","text":"<p>Get the number of sweep cycles to perform before stopping. To repeat the sweep continuously, the value is 0.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_sweep_cycles(self) -&gt; int:\n    \"\"\"\n    Get the number of sweep cycles to perform before stopping.\n    To repeat the sweep continuously, the value is 0.\n    \"\"\"\n    logging.info(__name__ + 'Getting number of sweep cycles')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n    sweep_cycles = self._rf_params.sweep_cycles\n    self._dll.sc5511a_close_device(self._handle)\n    return sweep_cycles\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_sweep_dir","title":"<code>do_get_sweep_dir()</code>","text":"<p>Get the sweep direction of the generator 0 = Forward. Sweeps start from the lowest start frequency or starts at the beginning of the list buffer 1 = Reverse. Sweeps start from the stop frequency and steps down toward the start frequency or starts at the     end and steps toward the beginning of the buffer</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_sweep_dir(self) -&gt; int:\n    \"\"\"\n    Get the sweep direction of the generator\n    0 = Forward. Sweeps start from the lowest start frequency or starts at the beginning of the list buffer\n    1 = Reverse. Sweeps start from the stop frequency and steps down toward the start frequency or starts at the\n        end and steps toward the beginning of the buffer\n    \"\"\"\n    logging.info(__name__ + 'Getting status of sweep direction ')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    hw_trigger = self._device_status.list_mode.sweep_dir\n    self._dll.sc5511a_close_device(self._handle)\n    return hw_trigger\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_sweep_dwell_time","title":"<code>do_get_sweep_dwell_time()</code>","text":"<p>Get the dwell time of the sweep mode. Return value is the unit multiple of 500 us, e.g. a return value 3 means the dwell time is 1500 us.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_sweep_dwell_time(self) -&gt; int:\n    \"\"\"\n    Get the dwell time of the sweep mode.\n    Return value is the unit multiple of 500 us, e.g. a return value 3 means the dwell time is 1500 us.\n    \"\"\"\n    logging.info(__name__ + 'Getting sweep dwell time in the unit of how many multiple of 500 us')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n    sweep_dwell_time = self._rf_params.sweep_dwell_time\n    self._dll.sc5511a_close_device(self._handle)\n    return sweep_dwell_time\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_sweep_start_frequency","title":"<code>do_get_sweep_start_frequency()</code>","text":"<p>Get the sweep start frequency that is used in the sweep mode The frequency returned is in the unit of Hz</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_sweep_start_frequency(self) -&gt; float:\n    \"\"\"\n    Get the sweep start frequency that is used in the sweep mode\n    The frequency returned is in the unit of Hz\n    \"\"\"\n    logging.info(__name__ + 'Getting sweep start frequency')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n    sweep_start_frequency = self._rf_params.start_freq\n    self._dll.sc5511a_close_device(self._handle)\n    return sweep_start_frequency\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_sweep_step_frequency","title":"<code>do_get_sweep_step_frequency()</code>","text":"<p>Get the sweep step frequency that is used in the sweep mode The frequency returned is in the unit of Hz</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_sweep_step_frequency(self) -&gt; float:\n    \"\"\"\n    Get the sweep step frequency that is used in the sweep mode\n    The frequency returned is in the unit of Hz\n    \"\"\"\n    logging.info(__name__ + 'Getting sweep step frequency')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n    sweep_step_frequency = self._rf_params.step_freq\n    self._dll.sc5511a_close_device(self._handle)\n    return sweep_step_frequency\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_sweep_stop_frequency","title":"<code>do_get_sweep_stop_frequency()</code>","text":"<p>Get the sweep stop frequency that is used in the sweep mode The frequency returned is in the unit of Hz</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_sweep_stop_frequency(self) -&gt; float:\n    \"\"\"\n    Get the sweep stop frequency that is used in the sweep mode\n    The frequency returned is in the unit of Hz\n    \"\"\"\n    logging.info(__name__ + 'Getting sweep stop frequency')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_rf_parameters(self._handle, ctypes.byref(self._rf_params))\n    sweep_stop_frequency = self._rf_params.stop_freq\n    self._dll.sc5511a_close_device(self._handle)\n    return sweep_stop_frequency\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_tri_waveform","title":"<code>do_get_tri_waveform()</code>","text":"<p>Get the triangular waveform of the generator 0 = Sawtooth waveform. Frequency returns to the beginning frequency upon reaching the end of a sweep cycle 1 = Triangular waveform. Frequency reverses direction at the end of the list and steps back towards the     beginning to complete a cycle</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_tri_waveform(self) -&gt; int:\n    \"\"\"\n    Get the triangular waveform of the generator\n    0 = Sawtooth waveform. Frequency returns to the beginning frequency upon reaching the end of a sweep cycle\n    1 = Triangular waveform. Frequency reverses direction at the end of the list and steps back towards the\n        beginning to complete a cycle\n    \"\"\"\n    logging.info(__name__ + 'Getting status of triangular waveform ')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    hw_trigger = self._device_status.list_mode.tri_waveform\n    self._dll.sc5511a_close_device(self._handle)\n    return hw_trigger\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_trig_out_enable","title":"<code>do_get_trig_out_enable()</code>","text":"<p>Get the status of the trigger output status 0 = No trigger output 1 = Puts a trigger pulse on the TRIGOUT pin</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_trig_out_enable(self) -&gt; int:\n    \"\"\"\n    Get the status of the trigger output status\n    0 = No trigger output\n    1 = Puts a trigger pulse on the TRIGOUT pin\n    \"\"\"\n    logging.info(__name__ + 'Getting trigger output status')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    trig_out_enable = self._device_status.list_mode.trig_out_enable\n    self._dll.sc5511a_close_device(self._handle)\n    return trig_out_enable\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_get_trig_out_on_cycle","title":"<code>do_get_trig_out_on_cycle()</code>","text":"<p>Get the trigger output mode 0 = Puts out a trigger pulse at each frequency change 1 = Puts out a trigger pulse at the completion of each sweep/list cycle</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_get_trig_out_on_cycle(self) -&gt; int:\n    \"\"\"\n    Get the trigger output mode\n    0 = Puts out a trigger pulse at each frequency change\n    1 = Puts out a trigger pulse at the completion of each sweep/list cycle\n    \"\"\"\n    logging.info(__name__ + 'Getting trigger output mode ')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    trig_out_enable = self._device_status.list_mode.trig_out_on_cycle\n    self._dll.sc5511a_close_device(self._handle)\n    return trig_out_enable\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_auto_level_disable","title":"<code>do_set_auto_level_disable(enable)</code>","text":"<p>Set if we want to disable the auto level</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_auto_level_disable(self, enable) -&gt; None:\n    \"\"\"\n    Set if we want to disable the auto level\n    \"\"\"\n    logging.info(__name__ + ' : Settingalc auto to %s' % enable)\n    if enable == 1:\n        enable = 0\n    elif enable == 0:\n        enable = 1\n    c_enable = ctypes.c_ubyte(enable)\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    completed = self._dll.sc5511a_set_auto_level_disable(self._handle, c_enable)\n    self._dll.sc5511a_close_device(self._handle)\n    return completed\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_frequency","title":"<code>do_set_frequency(frequency)</code>","text":"<p>Sets RF1 frequency in the unit of Hz. Valid between 100MHz and 20GHz     Args:         frequency (int) = frequency in Hz</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_frequency(self, frequency) -&gt; None:\n    \"\"\"\n    Sets RF1 frequency in the unit of Hz. Valid between 100MHz and 20GHz\n        Args:\n            frequency (int) = frequency in Hz\n    \"\"\"\n    c_freq = ctypes.c_ulonglong(int(frequency))\n    logging.info(__name__ + ' : Setting frequency to %s' % frequency)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n    if_set = self._dll.sc5511a_set_freq(self._handle, c_freq)\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_hw_trig","title":"<code>do_set_hw_trig(hw_trigger)</code>","text":"<p>Set the status of hardware trigger 0 = Software trigger. Softtrigger can only be used to start and stop a sweep/list cycle. It does not work for     step-on-trigger mode. 1 = Hardware trigger. A high-to-low transition on the TRIGIN pin will trigger the device. It can be used for     both start/stop or step-on-trigger functions.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_hw_trig(self, hw_trigger) -&gt; None:\n    \"\"\"\n    Set the status of hardware trigger\n    0 = Software trigger. Softtrigger can only be used to start and stop a sweep/list cycle. It does not work for\n        step-on-trigger mode.\n    1 = Hardware trigger. A high-to-low transition on the TRIGIN pin will trigger the device. It can be used for\n        both start/stop or step-on-trigger functions.\n    \"\"\"\n    c_hw_trigger = ctypes.c_ubyte(int(hw_trigger))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % hw_trigger)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    self._device_status.list_mode.hw_trigger = c_hw_trigger\n    if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_output_status","title":"<code>do_set_output_status(enable)</code>","text":"<p>Turns the output of RF1 on or off.     Input:         enable (int) = OFF = 0 ; ON = 1</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_output_status(self, enable) -&gt; None:\n    \"\"\"\n    Turns the output of RF1 on or off.\n        Input:\n            enable (int) = OFF = 0 ; ON = 1\n    \"\"\"\n    logging.info(__name__ + ' : Setting output to %s' % enable)\n    c_enable = ctypes.c_ubyte(enable)\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    completed = self._dll.sc5511a_set_output(self._handle, c_enable)\n    self._dll.sc5511a_close_device(self._handle)\n    return completed\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_power","title":"<code>do_set_power(power)</code>","text":"<p>Set the power of the generator in the unit of dBm</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_power(self, power) -&gt; None:\n    \"\"\"\n    Set the power of the generator in the unit of dBm\n    \"\"\"\n    logging.info(__name__ + ' : Setting power to %s' % power)\n    c_power = ctypes.c_float(power)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n    completed = self._dll.sc5511a_set_level(self._handle, c_power)\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return completed\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_reference_source","title":"<code>do_set_reference_source(lock_to_external)</code>","text":"<p>Set the generator reference source 0 = internal source 1 = external source</p> <p>Note here high is set to 0, means we always use 10 MHz clock when use external lock</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_reference_source(self, lock_to_external) -&gt; None:\n    \"\"\"\n    Set the generator reference source\n    0 = internal source\n    1 = external source\n\n    Note here high is set to 0, means we always use 10 MHz clock when use external lock\n    \"\"\"\n    logging.info(__name__ + ' : Setting reference source to %s' % lock_to_external)\n    high = ctypes.c_ubyte(0)\n    lock = ctypes.c_ubyte(lock_to_external)\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    source = self._dll.sc5511a_set_clock_reference(self._handle, high, lock)\n    self._dll.sc5511a_close_device(self._handle)\n    return source\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_return_to_start","title":"<code>do_set_return_to_start(return_to_start)</code>","text":"<p>Set how the frequency will change at the end of the list/sweep 0 = Stop at end of sweep/list. The frequency will stop at the last point of the sweep/list 1 = Return to start. The frequency will return and stop at the beginning point of the sweep or list after a     cycle.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_return_to_start(self, return_to_start) -&gt; None:\n    \"\"\"\n    Set how the frequency will change at the end of the list/sweep\n    0 = Stop at end of sweep/list. The frequency will stop at the last point of the sweep/list\n    1 = Return to start. The frequency will return and stop at the beginning point of the sweep or list after a\n        cycle.\n    \"\"\"\n    c_return_to_start = ctypes.c_ubyte(int(return_to_start))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % return_to_start)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    self._device_status.list_mode.return_to_start = c_return_to_start\n    if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_rf1_mode","title":"<code>do_set_rf1_mode(rf1_mode)</code>","text":"<p>Set the RF mode for rf1 0 = single fixed tone mode 1 = sweep/list mode</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_rf1_mode(self, rf1_mode) -&gt; None:\n    \"\"\"\n    Set the RF mode for rf1\n    0 = single fixed tone mode\n    1 = sweep/list mode\n    \"\"\"\n    c_rf1_mode = ctypes.c_ubyte(rf1_mode)\n    logging.info(__name__ + ' : Setting frequency to %s' % rf1_mode)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n    if_set = self._dll.sc5511a_set_rf_mode(self._handle, c_rf1_mode)\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_sss_mode","title":"<code>do_set_sss_mode(sss_mode)</code>","text":"<p>Set the list/sweep mode of the generator 0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register 1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_sss_mode(self, sss_mode) -&gt; None:\n    \"\"\"\n    Set the list/sweep mode of the generator\n    0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register\n    1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies\n    \"\"\"\n    c_sss_mode = ctypes.c_ubyte(int(sss_mode))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % sss_mode)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    self._device_status.list_mode.sss_mode = c_sss_mode\n    if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_step_on_hw_trig","title":"<code>do_set_step_on_hw_trig(step_on_hw_trig)</code>","text":"<p>Set the behavior of the sweep/list mode when receiving a trigger. 0 = Start/Stop behavior. The sweep starts and continues to step through the list for the number of cycles set,     dwelling at each step frequency for a period set by the dwell time. The sweep/list will end on a consecutive     trigger. 1 = Step-on-trigger. This is only available if hardware triggering is selected. The device will step to the next     frequency on a trigger.Upon completion of the number of cycles, the device will exit from the stepping state     and stop.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_step_on_hw_trig(self, step_on_hw_trig) -&gt; None:\n    \"\"\"\n    Set the behavior of the sweep/list mode when receiving a trigger.\n    0 = Start/Stop behavior. The sweep starts and continues to step through the list for the number of cycles set,\n        dwelling at each step frequency for a period set by the dwell time. The sweep/list will end on a consecutive\n        trigger.\n    1 = Step-on-trigger. This is only available if hardware triggering is selected. The device will step to the next\n        frequency on a trigger.Upon completion of the number of cycles, the device will exit from the stepping state\n        and stop.\n    \"\"\"\n    c_step_on_hw_trig = ctypes.c_ubyte(int(step_on_hw_trig))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % step_on_hw_trig)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    self._device_status.list_mode.step_on_hw_trig = c_step_on_hw_trig\n    if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_sweep_cycles","title":"<code>do_set_sweep_cycles(sweep_cycles)</code>","text":"<p>Set the number of sweep cycles to perform before stopping. To repeat the sweep continuously, set the value to 0.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_sweep_cycles(self, sweep_cycles) -&gt; None:\n    \"\"\"\n    Set the number of sweep cycles to perform before stopping.\n    To repeat the sweep continuously, set the value to 0.\n    \"\"\"\n    c_sweep_cycles = ctypes.c_uint(int(sweep_cycles))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % sweep_cycles)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n    if_set = self._dll.sc5511a_list_cycle_count(self._handle, c_sweep_cycles)\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_sweep_dir","title":"<code>do_set_sweep_dir(sweep_dir)</code>","text":"<p>Set the sweep direction of the generator 0 = Forward. Sweeps start from the lowest start frequency or starts at the beginning of the list buffer 1 = Reverse. Sweeps start from the stop frequency and steps down toward the start frequency or starts at the     end and steps toward the beginning of the buffer</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_sweep_dir(self, sweep_dir) -&gt; None:\n    \"\"\"\n    Set the sweep direction of the generator\n    0 = Forward. Sweeps start from the lowest start frequency or starts at the beginning of the list buffer\n    1 = Reverse. Sweeps start from the stop frequency and steps down toward the start frequency or starts at the\n        end and steps toward the beginning of the buffer\n    \"\"\"\n    c_sweep_dir = ctypes.c_ubyte(int(sweep_dir))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % sweep_dir)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    self._device_status.list_mode.sweep_dir = c_sweep_dir\n    if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_sweep_dwell_time","title":"<code>do_set_sweep_dwell_time(sweep_dwell_time)</code>","text":"<p>Set the sweep/list time at each frequency point. Note that the dwell time is set as multiple of 500 us. The input value is an unsigned int, it means how many multiple of 500 us.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_sweep_dwell_time(self, sweep_dwell_time) -&gt; None:\n    \"\"\"\n    Set the sweep/list time at each frequency point.\n    Note that the dwell time is set as multiple of 500 us.\n    The input value is an unsigned int, it means how many multiple of 500 us.\n    \"\"\"\n    c_sweep_dwell_time = ctypes.c_uint(int(sweep_dwell_time))\n    logging.info(__name__ + ': Setting sweep dwell time to %s' % sweep_dwell_time)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n    if_set = self._dll.sc5511a_list_dwell_time(self._handle, c_sweep_dwell_time)\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_sweep_start_frequency","title":"<code>do_set_sweep_start_frequency(sweep_start_frequency)</code>","text":"<p>Set the sweep start frequency of RF1 in the unit of Hz</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_sweep_start_frequency(self, sweep_start_frequency) -&gt; None:\n    \"\"\"\n    Set the sweep start frequency of RF1 in the unit of Hz\n    \"\"\"\n    c_sweep_start_freq = ctypes.c_ulonglong(int(sweep_start_frequency))\n    logging.info(__name__ + ' : Setting sweep start frequency to %s' % sweep_start_frequency)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n    if_set = self._dll.sc5511a_list_start_freq(self._handle, c_sweep_start_freq)\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_sweep_step_frequency","title":"<code>do_set_sweep_step_frequency(sweep_step_frequency)</code>","text":"<p>Set the sweep step frequency of RF1 in the unit of Hz</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_sweep_step_frequency(self, sweep_step_frequency) -&gt; None:\n    \"\"\"\n    Set the sweep step frequency of RF1 in the unit of Hz\n    \"\"\"\n    c_sweep_step_frequency = ctypes.c_ulonglong(int(sweep_step_frequency))\n    logging.info(__name__ + ' : Setting sweep step frequency to %s' % sweep_step_frequency)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n    if_set = self._dll.sc5511a_list_step_freq(self._handle, c_sweep_step_frequency)\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_sweep_stop_frequency","title":"<code>do_set_sweep_stop_frequency(sweep_stop_frequency)</code>","text":"<p>Set the sweep stop frequency of RF1 in the unit of Hz</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_sweep_stop_frequency(self, sweep_stop_frequency) -&gt; None:\n    \"\"\"\n    Set the sweep stop frequency of RF1 in the unit of Hz\n    \"\"\"\n    c_sweep_stop_frequency = ctypes.c_ulonglong(int(sweep_stop_frequency))\n    logging.info(__name__ + ' : Setting sweep stop frequency to %s' % sweep_stop_frequency)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n    if_set = self._dll.sc5511a_list_stop_freq(self._handle, c_sweep_stop_frequency)\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_tri_waveform","title":"<code>do_set_tri_waveform(tri_waveform)</code>","text":"<p>Set the triangular waveform of the generator 0 = Sawtooth waveform. Frequency returns to the beginning frequency upon reaching the end of a sweep cycle 1 = Triangular waveform. Frequency reverses direction at the end of the list and steps back towards the     beginning to complete a cycle</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_tri_waveform(self, tri_waveform) -&gt; None:\n    \"\"\"\n    Set the triangular waveform of the generator\n    0 = Sawtooth waveform. Frequency returns to the beginning frequency upon reaching the end of a sweep cycle\n    1 = Triangular waveform. Frequency reverses direction at the end of the list and steps back towards the\n        beginning to complete a cycle\n    \"\"\"\n    c_tri_waveform = ctypes.c_ubyte(int(tri_waveform))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % tri_waveform)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    self._device_status.list_mode.tri_waveform = c_tri_waveform\n    if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_trig_out_enable","title":"<code>do_set_trig_out_enable(trig_out_enable)</code>","text":"<p>Set the trigger output status. It does not send out the trigger, just enable the generator to send out the trigger 0 = No trigger output 1 = Puts a trigger pulse on the TRIGOUT pin</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_trig_out_enable(self, trig_out_enable) -&gt; None:\n    \"\"\"\n    Set the trigger output status.\n    It does not send out the trigger, just enable the generator to send out the trigger\n    0 = No trigger output\n    1 = Puts a trigger pulse on the TRIGOUT pin\n    \"\"\"\n    c_trig_out_enable = ctypes.c_ubyte(int(trig_out_enable))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % trig_out_enable)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    self._device_status.list_mode.trig_out_enable = c_trig_out_enable\n    if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.do_set_trig_out_on_cycle","title":"<code>do_set_trig_out_on_cycle(trig_out_on_cycle)</code>","text":"<p>Set the trigger output mode 0 = Puts out a trigger pulse at each frequency change 1 = Puts out a trigger pulse at the completion of each sweep/list cycle</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def do_set_trig_out_on_cycle(self, trig_out_on_cycle) -&gt; None:\n    \"\"\"\n    Set the trigger output mode\n    0 = Puts out a trigger pulse at each frequency change\n    1 = Puts out a trigger pulse at the completion of each sweep/list cycle\n    \"\"\"\n    c_trig_out_on_cycle = ctypes.c_ubyte(int(trig_out_on_cycle))\n    logging.info(__name__ + ': Setting sweep cycle number to %s ' % trig_out_on_cycle)\n    close = False\n    if not self._open:\n        self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n        close = True\n\n    self._dll.sc5511a_get_device_status(self._handle, ctypes.byref(self._device_status))\n    self._device_status.list_mode.trig_out_on_cycle = c_trig_out_on_cycle\n    if_set = self._dll.sc5511a_list_mode_config(self._handle, ctypes.byref(self._device_status.list_mode))\n\n    if close:\n        self._dll.sc5511a_close_device(self._handle)\n    return if_set\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.get_idn","title":"<code>get_idn()</code>","text":"<p>Get the identification information of the current device</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def get_idn(self) -&gt; Dict[str, Optional[str]]:\n    \"\"\"\n    Get the identification information of the current device\n    \"\"\"\n    logging.info(__name__ + \" : Getting device info\")\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_get_device_info(self._handle, ctypes.byref(self._device_info))\n    device_info = self._device_info\n    self._dll.sc5511a_close_device(self._handle)\n\n    def date_decode(date_int: int):\n        date_str = f\"{date_int:032b}\"\n        yr = f\"20{int(date_str[:8], 2)}\"\n        month = f\"{int(date_str[16:24], 2)}\"\n        day = f\"{int(date_str[8:16], 2)}\"\n        return f\"{month}/{day}/{yr}\"\n\n    IDN: Dict[str, Optional[str]] = {\n        'vendor': \"SignalCore\",\n        'model': \"SC5511A\",\n        'serial_number': self._serial_number.value.decode(\"utf-8\"),\n        'firmware_revision': device_info.firmware_revision,\n        'hardware_revision': device_info.hardware_revision,\n        'manufacture_date': date_decode(device_info.manufacture_date)\n    }\n    return IDN\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5511a.SignalCore_SC5511A.soft_trigger","title":"<code>soft_trigger()</code>","text":"<p>Send out a soft trigger, so that the we can start the sweep Generator need to be configured for list mode and soft trigger is selected as the trigger source</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5511a.py</code> <pre><code>def soft_trigger(self) -&gt; None:\n    \"\"\"\n    Send out a soft trigger, so that the we can start the sweep\n    Generator need to be configured for list mode and soft trigger is selected as the trigger source\n    \"\"\"\n    logging.info(__name__ + ' : Send a soft trigger to the generator')\n    self._handle = ctypes.c_void_p(self._dll.sc5511a_open_device(self._serial_number))\n    self._dll.sc5511a_list_soft_trigger(self._handle)\n    self._dll.sc5511a_close_device(self._handle)\n    return None\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5521a","title":"<code>SignalCore_sc5521a</code>","text":"<p>Made by jenshnielse. Edited to add more functions by Randy Owen</p>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5521a.SC5521A","title":"<code>SC5521A</code>","text":"<p>             Bases: <code>Instrument</code></p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5521a.py</code> <pre><code>class SC5521A(Instrument):\n    __doc__ = 'QCoDeS python driver for the Signal Core SC5521A.'\n\n    def __init__(self, name: str, #name the intsrument\n                        serial_number:str,\n                       dll_path: str='SignalCore\\\\SC5520A\\\\api\\\\c\\\\scipci\\\\x64\\\\sc5520a_uhfs.dll', \n                       #a path to the DLL of the device, which is the C program that actually drives the device\n                       #note, that this works for SC5521A despite the name\n                       **kwargs):\n        \"\"\"\n        QCoDeS driver for the Signal Core SC5521A.\n        This driver has been tested when only one SignalCore is connected to the\n        computer.\n\n        Args:\n        name (str): Name of the instrument.\n        dll_path (str): Path towards the instrument DLL.\n        \"\"\"\n\n        (super().__init__)(name, **kwargs)\n\n        self._devices_number = ctypes.c_uint() #setting the d\n        self._pxi10Enable = 0 #I don't know what this does\n        self._lock_external = 0 #This might set the default to internal clock refrence \n        self._clock_frequency = 10 #sets the clock frequency to 10 MHz\n\n        self._serial_number = ctypes.c_char_p(bytes(serial_number, 'utf-8'))\n\n        buffers = [ctypes.create_string_buffer(MAXDESCRIPTORSIZE + 1) for bid in range(MAXDEVICES)]\n        #this line creates a buffer (mutable memory) object for all the potential devices\n        self.buffer_pointer_array = (ctypes.c_char_p * MAXDEVICES)()\n        #c_char_p creates an array of C char types with null pointers of the size MAXDEVICES \n        for device in range(MAXDEVICES):\n            self.buffer_pointer_array[device] = ctypes.cast(buffers[device], ctypes.c_char_p)\n        #turning the elements of the buffer_pointer_array into char_p, which are pointers to strings\n        self._buffer_pointer_array_p = ctypes.cast(self.buffer_pointer_array, ctypes.POINTER(ctypes.c_char_p))\n        # This defines the pointers of the buffer_pointer_array. I think\n        # Adapt the path to the computer language\n        if sys.platform == 'win32': #checks the OS \n            dll_path = os.path.join(os.environ['PROGRAMFILES'], dll_path)#adding the c:\\ProgramFiles to the DLL path\n            self._dll = ctypes.WinDLL(dll_path)\n            print(dll_path)\n            print(self._dll)\n        else:\n            raise EnvironmentError(f\"{self.__class__.__name__} is supported only on Windows platform\")\n\n        found = self._dll.sc5520a_uhfsSearchDevices(COMMINTERFACE, self._buffer_pointer_array_p, ctypes.byref(self._devices_number))\n\n        #runs the SearchDevices command with the ouput being the pointer to the serial numbers located in _buffer_pointer_array_p\n        if found:\n            raise RuntimeError('Failed to find any device')\n        self._open(serial_number)\n        #setting up retrieving the device status, required for changing just one of the elements of the ListModeT\n        self._list_mode = ListModeT()\n        self._status = OperateStatusT()\n        self._pll_status = PLLStatusT()\n        self._device_status = DeviceStatusT(self._list_mode, self._status, self._pll_status)\n\n        self.add_parameter(name='temperature',\n                           docstring='Return the microwave source internal temperature.',\n                           label='Device temperature',\n                           unit='celsius',\n                           get_cmd=self._get_temperature)\n\n        self.add_parameter(name='output_status',\n                           docstring='.',\n                           vals=Enum(0, 1),\n                           set_cmd=self._set_status,\n                           get_cmd=self._get_status)\n\n        self.add_parameter(name='power',\n                           docstring='.',\n                           label='Power',\n                           unit='dbm',\n                           set_cmd=self._set_power,\n                           get_cmd=self._get_power)\n\n        self.add_parameter(name='frequency',\n                           docstring='.',\n                           label='Frequency',\n                           unit='Hz',\n                           set_cmd=self._set_frequency,\n                           get_cmd=self._get_frequency)\n\n        self.add_parameter(name='rf1_mode',\n                           docstring='0=single tone. 1=sweep',\n                           vals=Enum(0,1),\n                        #    initial_value=0,\n                           set_cmd=self._set_rf_mode,\n                           get_cmd=self._get_rf_mode)\n\n        self.add_parameter(name='clock_frequency',\n                           docstring='Select the internal clock frequency, 10 or 100MHz.',\n                           unit='MHz',\n                           vals=Enum(10, 100),\n                        #    initial_value=10,\n                           set_cmd=self._set_clock_frequency,\n                           get_cmd=self._get_clock_frequency)\n\n        self.add_parameter(name='clock_reference',\n                           docstring='Select the clock reference, internal or external.',\n                           vals=Enum('internal', 'external'),\n                        #    initial_value='internal',\n                           set_cmd=self._set_clock_reference,\n                           get_cmd=self._get_clock_reference)\n\n        ##Things Randy Wrote Start point\n\n        self.add_parameter(name='sweep_start_frequency',\n                           label='sweep_start_frequency',\n                           docstring='Frequency at the start of sweep. Hz',\n                           get_cmd=self._get_sweep_start_frequency,\n                           set_cmd=self._set_sweep_start_frequency,\n                           unit='Hz',\n                           vals=Numbers(min_value=160E6,max_value=40E9)\n                           )\n        self.add_parameter(name='sweep_stop_frequency',\n                           label='sweep_stop_frequency',\n                           docstring='Frequency at the end of sweep.',\n                           get_cmd=self._get_sweep_stop_frequency,\n                           set_cmd=self._set_sweep_stop_frequency,\n                           unit='Hz',\n                           vals=Numbers(min_value=160E6,max_value=40E9)\n                           )                                      \n        self.add_parameter(name='sweep_step_frequency',\n                           label='sweep_step_frequency',\n                           docstring='Frequency at the end of sweep.',\n                           get_cmd=self._get_sweep_step_frequency,\n                           set_cmd=self._set_sweep_step_frequency,\n                           unit='Hz',\n                           vals=Numbers(min_value=0,max_value=40E9)\n                           )\n        self.add_parameter(name='sweep_dwell_time',\n                           label='sweep_dwell_time',\n                           docstring='time in between sweep points. Units of 500us',\n                           get_cmd=self._get_sweep_dwell_time,\n                           get_parser=int,\n                           set_cmd=self._set_sweep_dwell_time,\n                           set_parser=int,\n                           unit='',\n                           vals=Numbers(min_value=1)\n                           )\n        self.add_parameter(name='sweep_cycles',\n                           label='sweep_cycles',\n                           docstring='how many times sweep is repeated. 0 is infinite',\n                           get_cmd=self._get_sweep_cycles,\n                           get_parser=int,\n                           set_cmd=self._set_sweep_cycles,\n                           set_parser=int,\n                           unit='',\n                           vals=Ints(min_value=0),\n                        #    initial_value=1,\n                           )\n        self.add_parameter(name='rf_phase_ouput',\n                           label='rf_phase_output',\n                           docstring='Ajust the phase of signal on the output. Must be multiples of 0.1 degree',\n                           get_cmd=self._get_rf_phase_output,\n                           set_cmd=self._set_rf_phase_output,\n                           unit='degrees',\n                           vals=PermissiveMultiples(0.1),\n                           )\n        self.add_parameter(name='sss_mode',\n                           label='sss_mode',\n                           docstring='0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register. 1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies',\n                           get_cmd=self._get_sweep_mode,\n                           set_cmd=self._set_sweep_mode,\n                           unit='',\n                           vals=Enum(0,1),\n                        #    initial_value=1,\n                           )\n        self.add_parameter(name='sweep_dir',\n                           label='sweep_dir',\n                           docstring='0 = forwards sweep. 1 = Backwards sweep',\n                           get_cmd=self._get_sweep_dir,\n                           set_cmd=self._set_sweep_dir,\n                           unit='',\n                           vals=Enum(0,1),\n                        #    initial_value=0,\n                           )\n        self.add_parameter(name='tri_waveform',\n                           label='tri_waveform',\n                           docstring='0 = Sawtooth waveform. 1 = Triangular waveform',\n                           get_cmd=self._get_tri_waveform,\n                           set_cmd=self._set_tri_waveform,\n                           unit='',\n                           vals=Enum(0,1),\n                        #    initial_value=0,\n                           )\n        self.add_parameter(name='hw_trigger',\n                           label='hw_trigger',\n                           docstring='0 = software trigger. 1 = hardware trigger',\n                           get_cmd=self._get_hw_trigger,\n                           set_cmd=self._set_hw_trigger,\n                           unit='',\n                           vals=Enum(0,1),\n                        #    initial_value=0,\n                           )                                                  \n        self.add_parameter(name='step_on_hw_trig',\n                           label='step_on_hw_trig',\n                           docstring='0 = start/stop. 1 =step to next freq. with hardware trigger',\n                           get_cmd=self._get_step_on_hw_trig,\n                           set_cmd=self._set_step_on_hw_trig,\n                           unit='',\n                           vals=Enum(0,1),\n                        #    initial_value=0,\n                           )\n        self.add_parameter(name='return_to_start',\n                           label='return_to_start',\n                           docstring='0=stops at end of list. 1=return to start of list at end',\n                           get_cmd=self._get_return_to_start,\n                           set_cmd=self._set_return_to_start,\n                           unit='',\n                           vals=Enum(0,1),\n                        #    initial_value=0,\n                           )\n        self.add_parameter(name='trig_out_enable',\n                           label='trig_out_enable',\n                           docstring='0=no trigger output. 1=trigger on TRIGOUT pin',\n                           get_cmd=self._get_trig_out_enable,\n                           set_cmd=self._set_trig_out_enable,\n                           unit='',\n                           vals=Enum(0,1),\n                        #    initial_value=1,\n                           )\n        self.add_parameter(name='trig_out_on_cycle',\n                           label='trig_out_on_cycle',\n                           docstring='0=trigger on frequency change. 1=trigger on cycle end',\n                           get_cmd=self._get_trig_out_on_cycle,\n                           set_cmd=self._set_trig_out_on_cycle,\n                           unit='',\n                           vals=Enum(0,1),\n                        #    initial_value=1,\n                           )                    \n\n        self.connect_message() #Sends out a message that things have been connected\n\n    def _open(self, serial_number) -&gt; None:\n        if sys.platform == \"win32\":\n            self._handle = ctypes.wintypes.HANDLE()\n        else:\n            raise EnvironmentError(f\"{self.__class__.__name__} is supported only on Windows platform\")\n\n        msg=self._dll.sc5520a_uhfsOpenDevice(COMMINTERFACE, self.buffer_pointer_array[0], ctypes.c_uint8(1), ctypes.byref(self._handle))\n        # msg=self._dll.sc5520a_uhfsOpenDevice(COMMINTERFACE, #which communication interface we are using\n        # ctypes.c_char_p(bytes(serial_number, 'utf-8')), #serial number?\n        # ctypes.c_uint8(1), \n        # ctypes.byref(self._handle))\n        self._error_handler(msg)\n        print(self._handle)\n\n    def _close(self) -&gt; None:\n        msg=self._dll.sc5520a_uhfsCloseDevice(self._handle) #closes the device\n        self._error_handler(msg)\n    def _error_handler(self, msg: int) -&gt; None:\n        \"\"\"Display error when setting the device fail.\n\n        Args:\n            msg (int): error key, see error_dict dict.\n\n        Raises:\n            BaseException\n        \"\"\"\n\n        if msg!=0:\n            raise BaseException(\"Couldn't set the devise due to {}.\".format(error_dict[str(msg)]))\n        else:\n            pass\n\n    def soft_trigger(self) -&gt; None:\n        \"\"\"\n        Send out a soft trigger, so that the we can start the sweep\n        Generator need to be configured for list mode and soft trigger is selected as the trigger source\n        \"\"\"\n        # logging.info(__name__ + ' : Send a soft trigger to the generator')\n        self._dll.sc5520a_uhfsListSoftTrigger(self._handle)\n        return None\n\n\n    def _get_temperature(self) -&gt; float:\n        temperature = ctypes.c_float()\n        self._dll.sc5520a_uhfsFetchTemperature(self._handle, ctypes.byref(temperature))\n        return temperature.value\n\n    def _set_status(self, status_: int) -&gt; None:\n        msg = self._dll.sc5520a_uhfsSetOutputEnable(self._handle, ctypes.c_int(status_))\n        self._error_handler(msg)\n\n    def _get_status(self) -&gt; str:\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(device_status_t))\n        return device_status_t.operate_status_t.output_enable\n\n    def _set_power(self, power: float) -&gt; None:\n        msg = self._dll.sc5520a_uhfsSetPowerLevel(self._handle, ctypes.c_float(power))\n        self._error_handler(msg)\n\n    def _get_power(self) -&gt; float:\n        self._dll.sc5520a_uhfsFetchRfParameters(self._handle, ctypes.byref(device_rf_params_t))\n        return device_rf_params_t.power_level\n\n    def _set_frequency(self, frequency: float) -&gt; None:\n        msg = self._dll.sc5520a_uhfsSetFrequency(self._handle, ctypes.c_double(frequency))\n        self._error_handler(msg)\n\n    def _get_frequency(self) -&gt; float:\n        device_rf_params_t = DeviceRFParamsT()\n        self._dll.sc5520a_uhfsFetchRfParameters(self._handle, ctypes.byref(device_rf_params_t))\n        return float(device_rf_params_t.frequency)\n\n    def _set_clock_frequency(self, clock_frequency: float) -&gt; None:\n        if clock_frequency == 10:\n            self._select_high = 0\n        else:\n            self._select_high = 1\n        msg = self._dll.sc5520a_uhfsSetReferenceMode(self._handle, ctypes.c_int(self._pxi10Enable), ctypes.c_int(self._select_high), ctypes.c_int(self._lock_external))\n        self._error_handler(msg)\n\n    def _get_clock_frequency(self) -&gt; float:\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(device_status_t))\n        ref_out_select = device_status_t.operate_status_t.ref_out_select\n        if ref_out_select == 1:\n            return 100\n        return 10\n\n    def _set_clock_reference(self, clock_reference: str) -&gt; None:\n        if clock_reference.lower() == 'internal':\n            self._lock_external = 0\n        else:\n            self._lock_external = 1\n        msg = self._dll.sc5520a_uhfsSetReferenceMode(self._handle, ctypes.c_int(self._pxi10Enable), ctypes.c_int(self._select_high), ctypes.c_int(self._lock_external))\n        self._error_handler(msg)\n\n    def _get_clock_reference(self) -&gt; str:\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(device_status_t))\n        ext_ref_detect = device_status_t.operate_status_t.ext_ref_detect\n        if ext_ref_detect == 1:\n            return 'external'\n        return 'internal'\n\n    def _set_rf_mode(self, rf_mode: int) -&gt; None:\n        c_rf_mode = ctypes.c_ubyte(int(rf_mode))\n        msg = self._dll.sc5520a_uhfsSetRfMode(self._handle, c_rf_mode)\n        self._error_handler(msg)\n\n    def _get_rf_mode(self) -&gt; str:\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(device_status_t))\n        rf_mode = device_status_t.operate_status_t.rf_mode\n        return int(rf_mode)\n\n    #Methods I, peasant Randy, have defined, so probably don't work\n    def _set_sweep_start_frequency(self, sweep_start_freq: float) -&gt; None:\n        \"\"\"\n        Set the start frequency of a sweep. Units of Hz.\n        \"\"\"\n        c_sweep_start_freq = ctypes.c_double(int(sweep_start_freq))\n        msg = self._dll.sc5520a_uhfsSweepStartFreq(self._handle, c_sweep_start_freq)\n        self._error_handler(msg)\n    def _get_sweep_start_frequency(self) -&gt; str:\n        \"\"\"\n        Set the start frequency of a sweep. Units of Hz.\n        \"\"\"\n        device_rf_params_t = DeviceRFParamsT()\n        self._dll.sc5520a_uhfsFetchRfParameters(self._handle, ctypes.byref(device_rf_params_t))\n        return float(device_rf_params_t.sweep_start_freq)\n\n    def _set_sweep_stop_frequency(self, sweep_stop_freq: float) -&gt; None:\n        \"\"\"\n        Set the stop frequency of a sweep. Units of Hz.\n        \"\"\"\n        c_sweep_stop_freq = ctypes.c_double(int(sweep_stop_freq))\n        msg = self._dll.sc5520a_uhfsSweepStopFreq(self._handle, c_sweep_stop_freq)\n        self._error_handler(msg)\n    def _get_sweep_stop_frequency(self) -&gt; str:\n        \"\"\"\n        Set the start frequency of a sweep. Units of Hz.\n        \"\"\"\n        device_rf_params_t = DeviceRFParamsT()\n        self._dll.sc5520a_uhfsFetchRfParameters(self._handle, ctypes.byref(device_rf_params_t))\n        return float(device_rf_params_t.sweep_stop_freq)\n\n    def _set_sweep_step_frequency(self, sweep_step_freq: float) -&gt; None:\n        \"\"\"\n        Set the frequency steps of a sweep. Units of Hz.\n        \"\"\"\n        c_sweep_step_freq = ctypes.c_double(int(sweep_step_freq))\n        msg = self._dll.sc5520a_uhfsSweepStepFreq(self._handle, c_sweep_step_freq)\n        self._error_handler(msg)\n    def _get_sweep_step_frequency(self) -&gt; str:\n        \"\"\"\n        Set the frequency steps of a sweep. Units of Hz.\n        \"\"\"\n        device_rf_params_t = DeviceRFParamsT()\n        self._dll.sc5520a_uhfsFetchRfParameters(self._handle, ctypes.byref(device_rf_params_t))\n        return float(device_rf_params_t.sweep_step_freq)\n\n    def _set_sweep_dwell_time(self, dwell_unit: int) -&gt; None:\n        \"\"\"\n        Set the sweep/list time at each frequency point.\n        Note that the dwell time is set as multiple of 500 us.\n        The input value is an unsigned int, it means how many multiple of 500 us.\n        \"\"\"\n        c_dwell_unit = ctypes.c_uint(int(dwell_unit))\n        msg = self._dll.sc5520a_uhfsSweepDwellTime(self._handle, c_dwell_unit)\n        self._error_handler(msg)\n    def _get_sweep_dwell_time(self) -&gt; str:\n        \"\"\"\n        Get the sweep/list time at each frequency point.\n        Note that the dwell time is set as multiple of 500 us.\n        \"\"\"\n        device_rf_params_t = DeviceRFParamsT()\n        self._dll.sc5520a_uhfsFetchRfParameters(self._handle, ctypes.byref(device_rf_params_t))\n        return float(device_rf_params_t.sweep_dwell_time)\n\n    def _set_sweep_cycles(self, sweep_cycles: int) -&gt; None:\n        \"\"\"\n        Set the number of times the sweep will cycle before stopping.\n        0 corresponds to a an infinite loop \n        \"\"\"\n        c_sweep_cycles = ctypes.c_uint(int(sweep_cycles)) #making this a python int should be redudant\n        msg = self._dll.sc5520a_uhfsListCycleCount(self._handle, c_sweep_cycles)\n        self._error_handler(msg)\n    def _get_sweep_cycles(self) -&gt; str:\n        \"\"\"\n        Get the number of times the sweep will cycle before stopping.\n        0 corresponds to a an infinite loop \n        \"\"\"\n        device_rf_params_t = DeviceRFParamsT()\n        self._dll.sc5520a_uhfsFetchRfParameters(self._handle, ctypes.byref(device_rf_params_t))\n        return int(device_rf_params_t.sweep_cycles)\n\n    def _set_rf_phase_output(self, rf_phase_output:float) -&gt; None:\n        \"\"\"\n        Sets the phase of the output RF signal. 0.1 degree steps\n        \"\"\"\n        c_rf_phase_output = ctypes.cfloat(rf_phase_output)\n        msg = self._dll.sc5520a_uhfsSetSignalPhase(self._handle, c_rf_phase_output)\n        self._error_handler(msg)\n    def _get_rf_phase_output(self) -&gt; str:\n        \"\"\"\n        Sets the phase of the output RF signal.\n        \"\"\"\n        device_rf_params_t = DeviceRFParamsT()\n        self._dll.sc5520a_uhfsFetchRfParameters(self._handle, ctypes.byref(device_rf_params_t))\n        return float(device_rf_params_t.rf_phase_offset)\n\n    def _set_sweep_mode(self, sweep_mode:int) -&gt; None:\n        \"\"\"\n        Set the list/sweep mode of the generator\n        0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register\n        1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies\n        \"\"\"\n        c_sweep_mode = ctypes.c_ubyte(int(sweep_mode)) #convert the Python Int into C byte \n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        self._device_status.list_mode_t.sweep_mode = c_sweep_mode \n        # change the dictonary value of \"sweep mode\" in the internally stored list mode dictionary\n        msg = self._dll.sc5520a_uhfsListModeConfig(self._handle, ctypes.byref(self._device_status.list_mode_t))\n\n\n        self._error_handler(msg)\n    def _get_sweep_mode(self) -&gt; str:\n        \"\"\"\n        Get the list/sweep mode of the generator\n        0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register\n        1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies\n        \"\"\"\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        sweep_mode = self._device_status.list_mode_t.sweep_mode \n        return sweep_mode\n    def _set_sweep_dir(self, sweep_dir:int) -&gt; None:\n        \"\"\"\n        Defines the sweep direction.\n        0: Forewards sweep.\n        1: Backwards sweep.\n        \"\"\"\n        c_sweep_dir = ctypes.c_ubyte(int(sweep_dir)) #convert the Python Int into C byte \n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        self._device_status.list_mode_t.sweep_dir = c_sweep_dir \n        # change the dictonary value of \"sweep mode\" in the internally stored list mode dictionary\n        msg = self._dll.sc5520a_uhfsListModeConfig(self._handle, ctypes.byref(self._device_status.list_mode_t))\n        self._error_handler(msg)\n    def _get_sweep_dir(self) -&gt; str:\n        \"\"\"\n        Defines the sweep direction.\n        0: Forewards sweep.\n        1: Backwards sweep.\n        \"\"\"\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        sweep_dir = self._device_status.list_mode_t.sweep_dir \n        return sweep_dir\n\n    def _set_tri_waveform(self, tri_waveform:int) -&gt; None:\n        \"\"\"\n        Set the triangular waveform of the generator\n        0 = Sawtooth waveform. Frequency returns to the beginning frequency upon reaching the end of a sweep cycle\n        1 = Triangular waveform. Frequency reverses direction at the end of the list and steps back towards the\n            beginning to complete a cycle\n        \"\"\"\n        c_tri_waveform = ctypes.c_ubyte(int(tri_waveform)) #convert the Python Int into C byte \n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        self._device_status.list_mode_t.tri_waveform = c_tri_waveform \n        # change the dictonary value of \"sweep mode\" in the internally stored list mode dictionary\n        msg = self._dll.sc5520a_uhfsListModeConfig(self._handle, ctypes.byref(self._device_status.list_mode_t))\n        self._error_handler(msg)\n    def _get_tri_waveform(self) -&gt; str:\n        \"\"\"\n        Get the triangular waveform of the generator\n        0 = Sawtooth waveform. Frequency returns to the beginning frequency upon reaching the end of a sweep cycle\n        1 = Triangular waveform. Frequency reverses direction at the end of the list and steps back towards the\n            beginning to complete a cycle\n        \"\"\"\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        tri_waveform = self._device_status.list_mode_t.tri_waveform \n        return tri_waveform\n\n    def _set_hw_trigger(self, hw_trigger:int) -&gt; None:\n        \"\"\"\n        Set the status of hardware trigger\n        0 = Software trigger. Softtrigger can only be used to start and stop a sweep/list cycle. It does not work for\n            step-on-trigger mode.\n        1 = Hardware trigger. A high-to-low transition on the TRIGIN pin will trigger the device. It can be used for\n            both start/stop or step-on-trigger functions.\n        \"\"\"\n        c_hw_trigger = ctypes.c_ubyte(int(hw_trigger)) #convert the Python Int into C byte \n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        self._device_status.list_mode_t.hw_trigger = c_hw_trigger \n        # change the dictonary value of \"sweep mode\" in the internally stored list mode dictionary\n        msg = self._dll.sc5520a_uhfsListModeConfig(self._handle, ctypes.byref(self._device_status.list_mode_t))\n        self._error_handler(msg)\n    def _get_hw_trigger(self) -&gt; str:\n        \"\"\"\n        Get the status of hardware trigger\n        0 = Software trigger. Softtrigger can only be used to start and stop a sweep/list cycle. It does not work for\n            step-on-trigger mode.\n        1 = Hardware trigger. A high-to-low transition on the TRIGIN pin will trigger the device. It can be used for\n            both start/stop or step-on-trigger functions.\n        \"\"\"\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        hw_trigger = self._device_status.list_mode_t.hw_trigger \n        return hw_trigger\n\n    def _set_step_on_hw_trig(self, step_on_hw_trig:int) -&gt; None:\n        \"\"\"\n        Set the behavior of the sweep/list mode when receiving a trigger.\n        0 = Start/Stop behavior. The sweep starts and continues to step through the list for the number of cycles set,\n            dwelling at each step frequency for a period set by the dwell time. The sweep/list will end on a consecutive\n            trigger.\n        1 = Step-on-trigger. This is only available if hardware triggering is selected. The device will step to the next\n            frequency on a trigger.Upon completion of the number of cycles, the device will exit from the stepping state\n            and stop.\n        \"\"\"\n        c_step_on_hw_trig = ctypes.c_ubyte(int(step_on_hw_trig)) #convert the Python Int into C byte \n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        self._device_status.list_mode_t.step_on_hw_trig = c_step_on_hw_trig \n        # change the dictonary value of \"sweep mode\" in the internally stored list mode dictionary\n        msg = self._dll.sc5520a_uhfsListModeConfig(self._handle, ctypes.byref(self._device_status.list_mode_t))\n        self._error_handler(msg)\n    def _get_step_on_hw_trig(self) -&gt; str:\n        \"\"\"\n        Get the behavior of the sweep/list mode when receiving a trigger.\n        0 = Start/Stop behavior\n        1 = Step-on-trigger\n        \"\"\"\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        step_on_hw_trig = self._device_status.list_mode_t.step_on_hw_trig \n        return step_on_hw_trig\n\n    def _set_return_to_start(self, return_to_start:int) -&gt; None:\n        \"\"\"\n        Set how the frequency will change at the end of the list/sweep\n        0 = Stop at end of sweep/list. The frequency will stop at the last point of the sweep/list\n        1 = Return to start. The frequency will return and stop at the beginning point of the sweep or list after a\n            cycle.\n        \"\"\"\n        c_return_to_start = ctypes.c_ubyte(int(return_to_start)) #convert the Python Int into C byte \n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        self._device_status.list_mode_t.return_to_start = c_return_to_start \n        # change the dictonary value of \"sweep mode\" in the internally stored list mode dictionary\n        msg = self._dll.sc5520a_uhfsListModeConfig(self._handle, ctypes.byref(self._device_status.list_mode_t))\n        self._error_handler(msg)\n    def _get_return_to_start(self) -&gt; str:\n        \"\"\"\n        Get how the frequency will change at the end of the list/sweep\n        0 = Stop at end of sweep/list. The frequency will stop at the last point of the sweep/list\n        1 = Return to start. The frequency will return and stop at the beginning point of the sweep or list after a\n            cycle.\n        \"\"\"\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        return_to_start = self._device_status.list_mode_t.return_to_start \n        return return_to_start\n\n    def _set_trig_out_enable(self, trig_out_enable:int) -&gt; None:\n        \"\"\"\n        Set the trigger output status.\n        It does not send out the trigger, just enable the generator to send out the trigger\n        0 = No trigger output\n        1 = Puts a trigger pulse on the TRIGOUT pin\n        \"\"\"\n        c_trig_out_enable = ctypes.c_ubyte(int(trig_out_enable)) #convert the Python Int into C byte \n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        self._device_status.list_mode_t.trig_out_enable = c_trig_out_enable \n        # change the dictonary value of \"sweep mode\" in the internally stored list mode dictionary\n        msg = self._dll.sc5520a_uhfsListModeConfig(self._handle, ctypes.byref(self._device_status.list_mode_t))\n        self._error_handler(msg)\n    def _get_trig_out_enable(self) -&gt; str:\n        \"\"\"\n        Get the trigger output status.\n        It does not send out the trigger, just enable the generator to send out the trigger\n        0 = No trigger output\n        1 = Puts a trigger pulse on the TRIGOUT pin\n        \"\"\"\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        trig_out_enable = self._device_status.list_mode_t.trig_out_enable \n        return trig_out_enable\n\n    def _set_trig_out_on_cycle(self, trig_out_on_cycle:int) -&gt; None:\n        \"\"\"\n        Set the trigger output mode\n        0 = Puts out a trigger pulse at each frequency change\n        1 = Puts out a trigger pulse at the completion of each sweep/list cycle\n        \"\"\"\n        c_trig_out_on_cycle = ctypes.c_ubyte(int(trig_out_on_cycle)) #convert the Python Int into C byte \n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        self._device_status.list_mode_t.trig_out_on_cycle = c_trig_out_on_cycle \n        # change the dictonary value of \"sweep mode\" in the internally stored list mode dictionary\n        msg = self._dll.sc5520a_uhfsListModeConfig(self._handle, ctypes.byref(self._device_status.list_mode_t))\n        self._error_handler(msg)\n    def _get_trig_out_on_cycle(self) -&gt; str:\n        \"\"\"\n        Get the trigger output mode\n        0 = Puts out a trigger pulse at each frequency change\n        1 = Puts out a trigger pulse at the completion of each sweep/list cycle\n        \"\"\"\n        self._dll.sc5520a_uhfsFetchDeviceStatus(self._handle, ctypes.byref(self._device_status))\n        #fetch the device status, which contains the list_mode_t values\n        trig_out_on_cycle = self._device_status.list_mode_t.trig_out_on_cycle \n        return trig_out_on_cycle\n\n    def get_idn(self) -&gt; Dict[str, Optional[str]]:\n        self._dll.sc5520a_uhfsFetchDeviceInfo(self._handle, ctypes.byref(device_info_t))\n\n        return {'vendor':'SignalCore',\n                'model':'SC5521A',\n                'serial':device_info_t.product_serial_number,\n                'firmware':device_info_t.firmware_revision,\n                'hardware':device_info_t.hardware_revision,\n                'manufacture_date':'20{}-{}-{} at {}h'.format(device_info_t.man_date.year, device_info_t.man_date.month, device_info_t.man_date.day, device_info_t.man_date.hour)}\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5521a.SC5521A.__init__","title":"<code>__init__(name, serial_number, dll_path='SignalCore\\\\SC5520A\\\\api\\\\c\\\\scipci\\\\x64\\\\sc5520a_uhfs.dll', **kwargs)</code>","text":"<p>QCoDeS driver for the Signal Core SC5521A. This driver has been tested when only one SignalCore is connected to the computer.</p> <p>Args: name (str): Name of the instrument. dll_path (str): Path towards the instrument DLL.</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5521a.py</code> <pre><code>def __init__(self, name: str, #name the intsrument\n                    serial_number:str,\n                   dll_path: str='SignalCore\\\\SC5520A\\\\api\\\\c\\\\scipci\\\\x64\\\\sc5520a_uhfs.dll', \n                   #a path to the DLL of the device, which is the C program that actually drives the device\n                   #note, that this works for SC5521A despite the name\n                   **kwargs):\n    \"\"\"\n    QCoDeS driver for the Signal Core SC5521A.\n    This driver has been tested when only one SignalCore is connected to the\n    computer.\n\n    Args:\n    name (str): Name of the instrument.\n    dll_path (str): Path towards the instrument DLL.\n    \"\"\"\n\n    (super().__init__)(name, **kwargs)\n\n    self._devices_number = ctypes.c_uint() #setting the d\n    self._pxi10Enable = 0 #I don't know what this does\n    self._lock_external = 0 #This might set the default to internal clock refrence \n    self._clock_frequency = 10 #sets the clock frequency to 10 MHz\n\n    self._serial_number = ctypes.c_char_p(bytes(serial_number, 'utf-8'))\n\n    buffers = [ctypes.create_string_buffer(MAXDESCRIPTORSIZE + 1) for bid in range(MAXDEVICES)]\n    #this line creates a buffer (mutable memory) object for all the potential devices\n    self.buffer_pointer_array = (ctypes.c_char_p * MAXDEVICES)()\n    #c_char_p creates an array of C char types with null pointers of the size MAXDEVICES \n    for device in range(MAXDEVICES):\n        self.buffer_pointer_array[device] = ctypes.cast(buffers[device], ctypes.c_char_p)\n    #turning the elements of the buffer_pointer_array into char_p, which are pointers to strings\n    self._buffer_pointer_array_p = ctypes.cast(self.buffer_pointer_array, ctypes.POINTER(ctypes.c_char_p))\n    # This defines the pointers of the buffer_pointer_array. I think\n    # Adapt the path to the computer language\n    if sys.platform == 'win32': #checks the OS \n        dll_path = os.path.join(os.environ['PROGRAMFILES'], dll_path)#adding the c:\\ProgramFiles to the DLL path\n        self._dll = ctypes.WinDLL(dll_path)\n        print(dll_path)\n        print(self._dll)\n    else:\n        raise EnvironmentError(f\"{self.__class__.__name__} is supported only on Windows platform\")\n\n    found = self._dll.sc5520a_uhfsSearchDevices(COMMINTERFACE, self._buffer_pointer_array_p, ctypes.byref(self._devices_number))\n\n    #runs the SearchDevices command with the ouput being the pointer to the serial numbers located in _buffer_pointer_array_p\n    if found:\n        raise RuntimeError('Failed to find any device')\n    self._open(serial_number)\n    #setting up retrieving the device status, required for changing just one of the elements of the ListModeT\n    self._list_mode = ListModeT()\n    self._status = OperateStatusT()\n    self._pll_status = PLLStatusT()\n    self._device_status = DeviceStatusT(self._list_mode, self._status, self._pll_status)\n\n    self.add_parameter(name='temperature',\n                       docstring='Return the microwave source internal temperature.',\n                       label='Device temperature',\n                       unit='celsius',\n                       get_cmd=self._get_temperature)\n\n    self.add_parameter(name='output_status',\n                       docstring='.',\n                       vals=Enum(0, 1),\n                       set_cmd=self._set_status,\n                       get_cmd=self._get_status)\n\n    self.add_parameter(name='power',\n                       docstring='.',\n                       label='Power',\n                       unit='dbm',\n                       set_cmd=self._set_power,\n                       get_cmd=self._get_power)\n\n    self.add_parameter(name='frequency',\n                       docstring='.',\n                       label='Frequency',\n                       unit='Hz',\n                       set_cmd=self._set_frequency,\n                       get_cmd=self._get_frequency)\n\n    self.add_parameter(name='rf1_mode',\n                       docstring='0=single tone. 1=sweep',\n                       vals=Enum(0,1),\n                    #    initial_value=0,\n                       set_cmd=self._set_rf_mode,\n                       get_cmd=self._get_rf_mode)\n\n    self.add_parameter(name='clock_frequency',\n                       docstring='Select the internal clock frequency, 10 or 100MHz.',\n                       unit='MHz',\n                       vals=Enum(10, 100),\n                    #    initial_value=10,\n                       set_cmd=self._set_clock_frequency,\n                       get_cmd=self._get_clock_frequency)\n\n    self.add_parameter(name='clock_reference',\n                       docstring='Select the clock reference, internal or external.',\n                       vals=Enum('internal', 'external'),\n                    #    initial_value='internal',\n                       set_cmd=self._set_clock_reference,\n                       get_cmd=self._get_clock_reference)\n\n    ##Things Randy Wrote Start point\n\n    self.add_parameter(name='sweep_start_frequency',\n                       label='sweep_start_frequency',\n                       docstring='Frequency at the start of sweep. Hz',\n                       get_cmd=self._get_sweep_start_frequency,\n                       set_cmd=self._set_sweep_start_frequency,\n                       unit='Hz',\n                       vals=Numbers(min_value=160E6,max_value=40E9)\n                       )\n    self.add_parameter(name='sweep_stop_frequency',\n                       label='sweep_stop_frequency',\n                       docstring='Frequency at the end of sweep.',\n                       get_cmd=self._get_sweep_stop_frequency,\n                       set_cmd=self._set_sweep_stop_frequency,\n                       unit='Hz',\n                       vals=Numbers(min_value=160E6,max_value=40E9)\n                       )                                      \n    self.add_parameter(name='sweep_step_frequency',\n                       label='sweep_step_frequency',\n                       docstring='Frequency at the end of sweep.',\n                       get_cmd=self._get_sweep_step_frequency,\n                       set_cmd=self._set_sweep_step_frequency,\n                       unit='Hz',\n                       vals=Numbers(min_value=0,max_value=40E9)\n                       )\n    self.add_parameter(name='sweep_dwell_time',\n                       label='sweep_dwell_time',\n                       docstring='time in between sweep points. Units of 500us',\n                       get_cmd=self._get_sweep_dwell_time,\n                       get_parser=int,\n                       set_cmd=self._set_sweep_dwell_time,\n                       set_parser=int,\n                       unit='',\n                       vals=Numbers(min_value=1)\n                       )\n    self.add_parameter(name='sweep_cycles',\n                       label='sweep_cycles',\n                       docstring='how many times sweep is repeated. 0 is infinite',\n                       get_cmd=self._get_sweep_cycles,\n                       get_parser=int,\n                       set_cmd=self._set_sweep_cycles,\n                       set_parser=int,\n                       unit='',\n                       vals=Ints(min_value=0),\n                    #    initial_value=1,\n                       )\n    self.add_parameter(name='rf_phase_ouput',\n                       label='rf_phase_output',\n                       docstring='Ajust the phase of signal on the output. Must be multiples of 0.1 degree',\n                       get_cmd=self._get_rf_phase_output,\n                       set_cmd=self._set_rf_phase_output,\n                       unit='degrees',\n                       vals=PermissiveMultiples(0.1),\n                       )\n    self.add_parameter(name='sss_mode',\n                       label='sss_mode',\n                       docstring='0 = List mode. Device gets its frequency points from the list buffer uploaded via LIST_BUFFER_WRITE register. 1 = Sweep mode. The device computes the frequency points using the Start, Stop and Step frequencies',\n                       get_cmd=self._get_sweep_mode,\n                       set_cmd=self._set_sweep_mode,\n                       unit='',\n                       vals=Enum(0,1),\n                    #    initial_value=1,\n                       )\n    self.add_parameter(name='sweep_dir',\n                       label='sweep_dir',\n                       docstring='0 = forwards sweep. 1 = Backwards sweep',\n                       get_cmd=self._get_sweep_dir,\n                       set_cmd=self._set_sweep_dir,\n                       unit='',\n                       vals=Enum(0,1),\n                    #    initial_value=0,\n                       )\n    self.add_parameter(name='tri_waveform',\n                       label='tri_waveform',\n                       docstring='0 = Sawtooth waveform. 1 = Triangular waveform',\n                       get_cmd=self._get_tri_waveform,\n                       set_cmd=self._set_tri_waveform,\n                       unit='',\n                       vals=Enum(0,1),\n                    #    initial_value=0,\n                       )\n    self.add_parameter(name='hw_trigger',\n                       label='hw_trigger',\n                       docstring='0 = software trigger. 1 = hardware trigger',\n                       get_cmd=self._get_hw_trigger,\n                       set_cmd=self._set_hw_trigger,\n                       unit='',\n                       vals=Enum(0,1),\n                    #    initial_value=0,\n                       )                                                  \n    self.add_parameter(name='step_on_hw_trig',\n                       label='step_on_hw_trig',\n                       docstring='0 = start/stop. 1 =step to next freq. with hardware trigger',\n                       get_cmd=self._get_step_on_hw_trig,\n                       set_cmd=self._set_step_on_hw_trig,\n                       unit='',\n                       vals=Enum(0,1),\n                    #    initial_value=0,\n                       )\n    self.add_parameter(name='return_to_start',\n                       label='return_to_start',\n                       docstring='0=stops at end of list. 1=return to start of list at end',\n                       get_cmd=self._get_return_to_start,\n                       set_cmd=self._set_return_to_start,\n                       unit='',\n                       vals=Enum(0,1),\n                    #    initial_value=0,\n                       )\n    self.add_parameter(name='trig_out_enable',\n                       label='trig_out_enable',\n                       docstring='0=no trigger output. 1=trigger on TRIGOUT pin',\n                       get_cmd=self._get_trig_out_enable,\n                       set_cmd=self._set_trig_out_enable,\n                       unit='',\n                       vals=Enum(0,1),\n                    #    initial_value=1,\n                       )\n    self.add_parameter(name='trig_out_on_cycle',\n                       label='trig_out_on_cycle',\n                       docstring='0=trigger on frequency change. 1=trigger on cycle end',\n                       get_cmd=self._get_trig_out_on_cycle,\n                       set_cmd=self._set_trig_out_on_cycle,\n                       unit='',\n                       vals=Enum(0,1),\n                    #    initial_value=1,\n                       )                    \n\n    self.connect_message() #Sends out a message that things have been connected\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalCore.SignalCore_sc5521a.SC5521A.soft_trigger","title":"<code>soft_trigger()</code>","text":"<p>Send out a soft trigger, so that the we can start the sweep Generator need to be configured for list mode and soft trigger is selected as the trigger source</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalCore/SignalCore_sc5521a.py</code> <pre><code>def soft_trigger(self) -&gt; None:\n    \"\"\"\n    Send out a soft trigger, so that the we can start the sweep\n    Generator need to be configured for list mode and soft trigger is selected as the trigger source\n    \"\"\"\n    # logging.info(__name__ + ' : Send a soft trigger to the generator')\n    self._dll.sc5520a_uhfsListSoftTrigger(self._handle)\n    return None\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalHound","title":"<code>SignalHound</code>","text":""},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalHound.Spike","title":"<code>Spike</code>","text":"<p>Basic driver to communicate with the SPIKE program through SCPI.</p>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.SignalHound.Spike.Spike","title":"<code>Spike</code>","text":"<p>             Bases: <code>VisaInstrument</code></p> <p>Pfafflab SignalHound Driver using the qcodes package</p> Source code in <code>labcore/instruments/qcodes_drivers/SignalHound/Spike.py</code> <pre><code>class Spike(VisaInstrument):\n    \"\"\"\n    Pfafflab SignalHound Driver using the qcodes package\n\n    \"\"\"\n\n    def __init__(self, name, address=None, **kwargs):\n        if address is None:\n            raise Exception('TCP IP address needed')\n        logging.info(__name__ + ' : Initializing instrument Spike')\n\n        super().__init__(name, address, terminator='\\n', **kwargs)\n\n        # Checks and changes the mode\n        self.add_parameter('mode',\n                           get_cmd=':INSTRUMENT?',\n                           set_cmd='INSTRUMENT {}',\n                           vals=vals.Anything(),\n                           get_parser=str,\n                           )\n\n\n        # Zero-span mode\n        # Changes the reference level in zero span mode\n        self.add_parameter('zs_ref_level',\n                           get_cmd=':ZS:CAPTURE:RLEVEL?',\n                           set_cmd=':ZS:CAPTURE:RLEVEL {}',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           unit='dB'\n                           )\n\n        # Changes the center frequency in zero span mode\n        self.add_parameter('zs_fcenter',\n                           get_cmd=':ZS:CAPTURE:CENTER?',\n                           set_cmd=':ZS:CAPTURE:CENTER {}',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           unit='Hz'\n                           )\n\n        # Changes the sampling rate in zero span mode\n        self.add_parameter('zs_sample_rate',\n                           get_cmd=':ZS:CAPTURE:SRATE {}',\n                           set_cmd=':ZS:CAPTURE:SRATE?',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           )\n\n        # Changes the IF bandwidth in zero span mode, only works when AUTO is off\n        self.add_parameter('zs_ifbw',\n                           get_cmd=':ZS:CAPTURE:IFBWIDTH?',\n                           set_cmd=':ZS:CAPTURE:IFBWIDTH {}',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           unit='Hz'\n                           )\n\n        # Enables the AUTO IF bandwidth option in zero span mode\n        self.add_parameter('zs_ifbw_auto',\n                           get_cmd=':ZS:CAPTURE:IFBWIDTH:AUTO?',\n                           set_cmd=':ZS:CAPTURE:IFBWIDTH:AUTO {}',\n                           vals=vals.Anything()\n                           )\n\n        # Changes the sweep time in zero span mode\n        self.add_parameter('zs_sweep_time',\n                           get_cmd=':ZS:CAPTURE:SWEEP:TIME?',\n                           set_cmd=':ZS:CAPTURE:SWEEP:TIME {}',\n                           vals=vals.Numbers(),\n                           get_parser=float,\n                           unit='s'\n                           )\n\n        self.add_parameter('zs_power',\n                           get_cmd=self._measure_zs_power_dBm,\n                           set_cmd=False,\n                           unit='dBm')\n\n        self.add_parameter('zs_iq_values',\n                           get_cmd=self._measure_zs_iq_vals,\n                           set_cmd=False,\n                           unit='dBm^.5')\n\n        # setting defaults\n        self.mode('ZS')\n\n    def _measure_zs_iq_vals(self):\n        IQ_table = np.array(self.ask(':FETCH:ZS? 1').split(',')).astype(float).reshape(-1, 2)\n        return IQ_table\n\n    def _measure_zs_power_dBm(self):\n        IQ_table = np.array(self.ask(':FETCH:ZS? 1').split(',')).astype(float).reshape(-1, 2)\n        power = (IQ_table[:, 0] ** 2 + IQ_table[:, 1] ** 2).mean()\n        return 10 * np.log10(power)\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.ThorLabs","title":"<code>ThorLabs</code>","text":""},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.ThorLabs.TSP_01B","title":"<code>TSP_01B</code>","text":"<p>Basic driver to access the ThorLabs TSP-01B temperature sensor probe (TSP) via qcodes</p>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa","title":"<code>Yokogawa</code>","text":""},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200","title":"<code>GS200</code>","text":""},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200","title":"<code>GS200</code>","text":"<p>             Bases: <code>VisaInstrument</code></p> <p>This is the QCoDeS driver for the Yokogawa GS200 voltage and current source.</p> <p>Args:   name: What this instrument is called locally.   address: The GPIB or USB address of this instrument   kwargs: kwargs to be passed to VisaInstrument class   terminator: read terminator for reads/writes to the instrument.</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>class GS200(VisaInstrument):\n    \"\"\"\n    This is the QCoDeS driver for the Yokogawa GS200 voltage and current source.\n\n    Args:\n      name: What this instrument is called locally.\n      address: The GPIB or USB address of this instrument\n      kwargs: kwargs to be passed to VisaInstrument class\n      terminator: read terminator for reads/writes to the instrument.\n    \"\"\"\n\n    def __init__(self, name: str, address: str, terminator: str = \"\\n\",\n                 **kwargs: Any) -&gt; None:\n        super().__init__(name, address, terminator=terminator, **kwargs)\n\n        self.add_parameter('output',\n                           label='Output State',\n                           get_cmd=self.state,\n                           set_cmd=lambda x: self.on() if x else self.off(),\n                           val_mapping={\n                               'off': 0,\n                               'on': 1,\n                           })\n\n        self.add_parameter('source_mode',\n                           label='Source Mode',\n                           get_cmd=':SOUR:FUNC?',\n                           set_cmd=self._set_source_mode,\n                           vals=Enum('VOLT', 'CURR'))\n\n        # We need to get the source_mode value here as we cannot rely on the\n        # default value that may have been changed before we connect to the\n        # instrument (in a previous session or via the frontpanel).\n        self.source_mode()\n\n        self.add_parameter('voltage_range',\n                           label='Voltage Source Range',\n                           unit='V',\n                           get_cmd=partial(self._get_range, \"VOLT\"),\n                           set_cmd=partial(self._set_range, \"VOLT\"),\n                           vals=Enum(10e-3, 100e-3, 1e0, 10e0, 30e0),\n                           snapshot_exclude=self.source_mode() == 'CURR'\n                           )\n\n        self.add_parameter('current_range',\n                           label='Current Source Range',\n                           unit='I',\n                           get_cmd=partial(self._get_range, \"CURR\"),\n                           set_cmd=partial(self._set_range, \"CURR\"),\n                           vals=Enum(1e-3, 10e-3, 100e-3, 200e-3),\n                           snapshot_exclude=self.source_mode() == \"VOLT\"\n                           )\n\n        self.add_parameter('range',\n                           parameter_class=DelegateParameter,\n                           source=None\n                           )\n\n        # The instrument does not support auto range. The parameter\n        # auto_range is introduced to add this capability with\n        # setting the initial state at False mode.\n        self.add_parameter('auto_range',\n                           label='Auto Range',\n                           set_cmd=self._set_auto_range,\n                           get_cmd=None,\n                           initial_cache_value=False,\n                           vals=Bool()\n                           )\n\n        self.add_parameter('voltage',\n                           label='Voltage',\n                           unit='V',\n                           set_cmd=partial(self._get_set_output, \"VOLT\"),\n                           get_cmd=partial(self._get_set_output, \"VOLT\"),\n                           snapshot_exclude=self.source_mode() == \"CURR\"\n                           )\n\n        self.add_parameter('current',\n                           label='Current',\n                           unit='I',\n                           set_cmd=partial(self._get_set_output, \"CURR\"),\n                           get_cmd=partial(self._get_set_output, \"CURR\"),\n                           snapshot_exclude=self.source_mode() == 'VOLT'\n                           )\n\n        self.add_parameter('output_level',\n                           parameter_class=DelegateParameter,\n                           source=None\n                           )\n\n        # We need to pass the source parameter for delegate parameters\n        # (range and output_level) here according to the present\n        # source_mode.\n        if self.source_mode() == 'VOLT':\n            self.range.source = self.voltage_range\n            self.output_level.source = self.voltage\n        else:\n            self.range.source = self.current_range\n            self.output_level.source = self.current\n\n        self.add_parameter('voltage_limit',\n                           label='Voltage Protection Limit',\n                           unit='V',\n                           vals=Ints(1, 30),\n                           get_cmd=\":SOUR:PROT:VOLT?\",\n                           set_cmd=\":SOUR:PROT:VOLT {}\",\n                           get_parser=float_round,\n                           set_parser=int)\n\n        self.add_parameter('current_limit',\n                           label='Current Protection Limit',\n                           unit='I',\n                           vals=Numbers(1e-3, 200e-3),\n                           get_cmd=\":SOUR:PROT:CURR?\",\n                           set_cmd=\":SOUR:PROT:CURR {:.3f}\",\n                           get_parser=float,\n                           set_parser=float)\n\n        self.add_parameter('four_wire',\n                           label='Four Wire Sensing',\n                           get_cmd=':SENS:REM?',\n                           set_cmd=':SENS:REM {}',\n                           val_mapping={\n                              'off': 0,\n                              'on': 1,\n                           })\n\n        # Note: The guard feature can be used to remove common mode noise.\n        # Read the manual to see if you would like to use it\n        self.add_parameter('guard',\n                           label='Guard Terminal',\n                           get_cmd=':SENS:GUAR?',\n                           set_cmd=':SENS:GUAR {}',\n                           val_mapping={'off': 0,\n                                        'on': 1})\n\n        # Return measured line frequency\n        self.add_parameter(\"line_freq\",\n                           label='Line Frequency',\n                           unit=\"Hz\",\n                           get_cmd=\"SYST:LFR?\",\n                           get_parser=int)\n\n        # Check if monitor is present, and if so enable measurement\n        monitor_present = '/MON' in self.ask(\"*OPT?\")\n        measure = GS200_Monitor(self, 'measure', monitor_present)\n        self.add_submodule('measure', measure)\n\n        # Reset function\n        self.add_function('reset', call_cmd='*RST')\n\n        self.add_submodule('program', GS200Program(self, 'program'))\n\n        self.add_parameter(\"BNC_out\",\n                           label=\"BNC trigger out\",\n                           get_cmd=\":ROUT:BNCO?\",\n                           set_cmd=\":ROUT:BNCO {}\",\n                           vals=Enum(\"trigger\", \"output\", \"ready\"),\n                           docstring=\"Sets or queries the output BNC signal\")\n\n        self.add_parameter(\"BNC_in\",\n                           label=\"BNC trigger in\",\n                           get_cmd=\":ROUT:BNCI?\",\n                           set_cmd=\":ROUT:BNCI {}\",\n                           vals=Enum(\"trigger\", \"output\"),\n                           docstring=\"Sets or queries the input BNC signal\")\n\n        self.add_parameter(\n            \"system_errors\",\n            get_cmd=\":SYSTem:ERRor?\",\n            docstring=\"returns the oldest unread error message from the event \"\n                      \"log and removes it from the log.\"\n        )\n\n        self.connect_message()\n\n    def on(self) -&gt; None:\n        \"\"\"Turn output on\"\"\"\n        self.write('OUTPUT 1')\n        self.measure._output = True\n\n    def off(self) -&gt; None:\n        \"\"\"Turn output off\"\"\"\n        self.write('OUTPUT 0')\n        self.measure._output = False\n\n    def state(self) -&gt; int:\n        \"\"\"Check state\"\"\"\n        state = int(self.ask('OUTPUT?'))\n        self.measure._output = bool(state)\n        return state\n\n    def ramp_voltage(self, ramp_to: float, step: float, delay: float) -&gt; None:\n        \"\"\"\n        Ramp the voltage from the current level to the specified output.\n\n        Args:\n            ramp_to: The ramp target in Volt\n            step: The ramp steps in Volt\n            delay: The time between finishing one step and\n                starting another in seconds.\n        \"\"\"\n        self._assert_mode(\"VOLT\")\n        self._ramp_source(ramp_to, step, delay)\n\n    def ramp_current(self, ramp_to: float, step: float, delay: float) -&gt; None:\n        \"\"\"\n        Ramp the current from the current level to the specified output.\n\n        Args:\n            ramp_to: The ramp target in Ampere\n            step: The ramp steps in Ampere\n            delay: The time between finishing one step and starting\n                another in seconds.\n        \"\"\"\n        self._assert_mode(\"CURR\")\n        self._ramp_source(ramp_to, step, delay)\n\n    def _ramp_source(self, ramp_to: float, step: float, delay: float) -&gt; None:\n        \"\"\"\n        Ramp the output from the current level to the specified output\n\n        Args:\n            ramp_to: The ramp target in volts/amps\n            step: The ramp steps in volts/ampere\n            delay: The time between finishing one step and\n                starting another in seconds.\n        \"\"\"\n        saved_step = self.output_level.step\n        saved_inter_delay = self.output_level.inter_delay\n\n        self.output_level.step = step\n        self.output_level.inter_delay = delay\n        self.output_level(ramp_to)\n\n        self.output_level.step = saved_step\n        self.output_level.inter_delay = saved_inter_delay\n\n    def _get_set_output(self, mode: str,\n                        output_level: Optional[float] = None\n                        ) -&gt; Optional[float]:\n        \"\"\"\n        Get or set the output level.\n\n        Args:\n            mode: \"CURR\" or \"VOLT\"\n            output_level: If missing, we assume that we are getting the\n                current level. Else we are setting it\n        \"\"\"\n        self._assert_mode(mode)\n        if output_level is not None:\n            self._set_output(output_level)\n            return None\n        return float(self.ask(\":SOUR:LEV?\"))\n\n    def _set_output(self, output_level: float) -&gt; None:\n        \"\"\"\n        Set the output of the instrument.\n\n        Args:\n            output_level: output level in Volt or Ampere, depending\n                on the current mode.\n        \"\"\"\n        auto_enabled = self.auto_range()\n\n        if not auto_enabled:\n            self_range = self.range()\n            if self_range is None:\n                raise RuntimeError(\"Trying to set output but not in\"\n                                   \" auto mode and range is unknown.\")\n        else:\n            mode = self.source_mode.get_latest()\n            if mode == \"CURR\":\n                self_range = 200E-3\n            else:\n                self_range = 30.0\n\n        # Check we are not trying to set an out of range value\n        if self.range() is None or abs(output_level)\\\n                &gt; abs(self_range):\n            # Check that the range hasn't changed\n            if not auto_enabled:\n                self_range = self.range.get_latest()\n                if self_range is None:\n                    raise RuntimeError(\"Trying to set output but not in\"\n                                       \" auto mode and range is unknown.\")\n            # If we are still out of range, raise a value error\n            if abs(output_level) &gt; abs(self_range):\n                raise ValueError(\"Desired output level not in range\"\n                                 \" [-{self_range:.3}, {self_range:.3}]\".\n                                 format(self_range=self_range))\n\n        if auto_enabled:\n            auto_str = \":AUTO\"\n        else:\n            auto_str = \"\"\n        cmd_str = f\":SOUR:LEV{auto_str} {output_level:.5e}\"\n        self.write(cmd_str)\n\n    def _update_measurement_module(self, source_mode: Optional[str] = None,\n                                   source_range: Optional[float] = None\n                                   ) -&gt; None:\n        \"\"\"\n        Update validators/units as source mode/range changes.\n\n        Args:\n            source_mode: \"CURR\" or \"VOLT\"\n            source_range\n        \"\"\"\n        if not self.measure.present:\n            return\n\n        if source_mode is None:\n            source_mode = self.source_mode.get_latest()\n        # Get source range if auto-range is off\n        if source_range is None and not self.auto_range():\n            source_range = self.range()\n\n        self.measure.update_measurement_enabled(source_mode, source_range)\n\n    def _set_auto_range(self, val: bool) -&gt; None:\n        \"\"\"\n        Enable/disable auto range.\n\n        Args:\n            val: auto range on or off\n        \"\"\"\n        self._auto_range = val\n        # Disable measurement if auto range is on\n        if self.measure.present:\n            # Disable the measurement module if auto range is enabled,\n            # because the measurement does not work in the\n            # 10mV/100mV ranges.\n            self.measure._enabled &amp;= not val\n\n    def _assert_mode(self, mode: str) -&gt; None:\n        \"\"\"\n        Assert that we are in the correct mode to perform an operation.\n\n        Args:\n            mode: \"CURR\" or \"VOLT\"\n        \"\"\"\n        if self.source_mode.get_latest() != mode:\n            raise ValueError(\"Cannot get/set {} settings while in {} mode\".\n                             format(mode, self.source_mode.get_latest()))\n\n    def _set_source_mode(self, mode: str) -&gt; None:\n        \"\"\"\n        Set output mode and change delegate parameters' source accordingly.\n        Also, exclude/include the parameters from snapshot depending on the\n        mode. The instrument does not support 'current', 'current_range'\n        parameters in \"VOLT\" mode and 'voltage', 'voltage_range' parameters\n        in \"CURR\" mode.\n\n        Args:\n            mode: \"CURR\" or \"VOLT\"\n\n        \"\"\"\n        if self.output() == 'on':\n            raise GS200Exception(\"Cannot switch mode while source is on\")\n\n        if mode == \"VOLT\":\n            self.range.source = self.voltage_range\n            self.output_level.source = self.voltage\n            self.voltage_range.snapshot_exclude = False\n            self.voltage.snapshot_exclude = False\n            self.current_range.snapshot_exclude = True\n            self.current.snapshot_exclude = True\n        else:\n            self.range.source = self.current_range\n            self.output_level.source = self.current\n            self.voltage_range.snapshot_exclude = True\n            self.voltage.snapshot_exclude = True\n            self.current_range.snapshot_exclude = False\n            self.current.snapshot_exclude = False\n\n        self.write(f\"SOUR:FUNC {mode}\")\n        # We set the cache here since `_update_measurement_module`\n        # needs the current value which would otherwise only be set\n        # after this method exits\n        self.source_mode.cache.set(mode)\n        # Update the measurement mode\n        self._update_measurement_module(source_mode=mode)\n\n    def _set_range(self, mode: str, output_range: float) -&gt; None:\n        \"\"\"\n        Update range\n\n        Args:\n            mode: \"CURR\" or \"VOLT\"\n            output_range: Range to set. For voltage, we have the ranges [10e-3,\n                100e-3, 1e0, 10e0, 30e0]. For current, we have the ranges [1e-3,\n                10e-3, 100e-3, 200e-3]. If auto_range = False, then setting the\n                output can only happen if the set value is smaller than the\n                present range.\n        \"\"\"\n        self._assert_mode(mode)\n        output_range = float(output_range)\n        self._update_measurement_module(source_mode=mode,\n                                        source_range=output_range)\n        self.write(f':SOUR:RANG {output_range}')\n\n    def _get_range(self, mode: str) -&gt; float:\n        \"\"\"\n        Query the present range.\n\n        Args:\n            mode: \"CURR\" or \"VOLT\"\n\n        Returns:\n            range: For voltage, we have the ranges [10e-3, 100e-3, 1e0, 10e0,\n                30e0]. For current, we have the ranges [1e-3, 10e-3, 100e-3,\n                200e-3]. If auto_range = False, then setting the output can only\n                happen if the set value is smaller than the present range.\n        \"\"\"\n        self._assert_mode(mode)\n        return float(self.ask(\":SOUR:RANG?\"))\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200.off","title":"<code>off()</code>","text":"<p>Turn output off</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def off(self) -&gt; None:\n    \"\"\"Turn output off\"\"\"\n    self.write('OUTPUT 0')\n    self.measure._output = False\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200.on","title":"<code>on()</code>","text":"<p>Turn output on</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def on(self) -&gt; None:\n    \"\"\"Turn output on\"\"\"\n    self.write('OUTPUT 1')\n    self.measure._output = True\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200.ramp_current","title":"<code>ramp_current(ramp_to, step, delay)</code>","text":"<p>Ramp the current from the current level to the specified output.</p> <p>Args:     ramp_to: The ramp target in Ampere     step: The ramp steps in Ampere     delay: The time between finishing one step and starting         another in seconds.</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def ramp_current(self, ramp_to: float, step: float, delay: float) -&gt; None:\n    \"\"\"\n    Ramp the current from the current level to the specified output.\n\n    Args:\n        ramp_to: The ramp target in Ampere\n        step: The ramp steps in Ampere\n        delay: The time between finishing one step and starting\n            another in seconds.\n    \"\"\"\n    self._assert_mode(\"CURR\")\n    self._ramp_source(ramp_to, step, delay)\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200.ramp_voltage","title":"<code>ramp_voltage(ramp_to, step, delay)</code>","text":"<p>Ramp the voltage from the current level to the specified output.</p> <p>Args:     ramp_to: The ramp target in Volt     step: The ramp steps in Volt     delay: The time between finishing one step and         starting another in seconds.</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def ramp_voltage(self, ramp_to: float, step: float, delay: float) -&gt; None:\n    \"\"\"\n    Ramp the voltage from the current level to the specified output.\n\n    Args:\n        ramp_to: The ramp target in Volt\n        step: The ramp steps in Volt\n        delay: The time between finishing one step and\n            starting another in seconds.\n    \"\"\"\n    self._assert_mode(\"VOLT\")\n    self._ramp_source(ramp_to, step, delay)\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200.state","title":"<code>state()</code>","text":"<p>Check state</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def state(self) -&gt; int:\n    \"\"\"Check state\"\"\"\n    state = int(self.ask('OUTPUT?'))\n    self.measure._output = bool(state)\n    return state\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200_Monitor","title":"<code>GS200_Monitor</code>","text":"<p>             Bases: <code>InstrumentChannel</code></p> <p>Monitor part of the GS200. This is only enabled if it is installed in the GS200 (it is an optional extra).</p> <p>The units will be automatically updated as required.</p> <p>To measure: <code>GS200.measure.measure()</code></p> <p>Args:     parent (GS200)     name: instrument name     present</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>class GS200_Monitor(InstrumentChannel):\n    \"\"\"\n    Monitor part of the GS200. This is only enabled if it is\n    installed in the GS200 (it is an optional extra).\n\n    The units will be automatically updated as required.\n\n    To measure:\n    `GS200.measure.measure()`\n\n    Args:\n        parent (GS200)\n        name: instrument name\n        present\n    \"\"\"\n    def __init__(self, parent: 'GS200', name: str, present: bool) -&gt; None:\n        super().__init__(parent, name)\n\n        self.present = present\n\n        # Start off with all disabled\n        self._enabled = False\n        self._output = False\n\n        # Set up mode cache. These will be filled in once the parent\n        # is fully initialized.\n        self._range: Union[None, float] = None\n        self._unit: Union[None, str] = None\n\n        # Set up monitoring parameters\n        if present:\n            self.add_parameter('enabled',\n                               label='Measurement Enabled',\n                               get_cmd=self.state,\n                               set_cmd=lambda x: self.on() if x else self.off(),\n                               val_mapping={\n                                    'off': 0,\n                                    'on': 1,\n                               })\n\n            # Note: Measurement will only run if source and\n            # measurement is enabled.\n            self.add_parameter('measure',\n                               label='&lt;unset&gt;', unit='V/I',\n                               get_cmd=self._get_measurement,\n                               snapshot_get=False)\n\n            self.add_parameter('NPLC',\n                               label='NPLC',\n                               unit='1/LineFreq',\n                               vals=Ints(1, 25),\n                               set_cmd=':SENS:NPLC {}',\n                               set_parser=int,\n                               get_cmd=':SENS:NPLC?',\n                               get_parser=float_round)\n            self.add_parameter('delay',\n                               label='Measurement Delay',\n                               unit='ms',\n                               vals=Ints(0, 999999),\n                               set_cmd=':SENS:DEL {}',\n                               set_parser=int,\n                               get_cmd=':SENS:DEL?',\n                               get_parser=float_round)\n            self.add_parameter('trigger',\n                               label='Trigger Source',\n                               set_cmd=':SENS:TRIG {}',\n                               get_cmd=':SENS:TRIG?',\n                               val_mapping={\n                                    'READY': 'READ',\n                                    'READ': 'READ',\n                                    'TIMER': 'TIM',\n                                    'TIM': 'TIM',\n                                    'COMMUNICATE': 'COMM',\n                                    'IMMEDIATE': 'IMM',\n                                    'IMM': 'IMM'\n                               })\n            self.add_parameter('interval',\n                               label='Measurement Interval',\n                               unit='s',\n                               vals=Numbers(0.1, 3600),\n                               set_cmd=':SENS:INT {}',\n                               set_parser=float,\n                               get_cmd=':SENS:INT?',\n                               get_parser=float)\n\n    def off(self) -&gt; None:\n        \"\"\"Turn measurement off\"\"\"\n        self.write(':SENS 0')\n        self._enabled = False\n\n    def on(self) -&gt; None:\n        \"\"\"Turn measurement on\"\"\"\n        self.write(':SENS 1')\n        self._enabled = True\n\n    def state(self) -&gt; int:\n        \"\"\"Check measurement state\"\"\"\n        state = int(self.ask(':SENS?'))\n        self._enabled = bool(state)\n        return state\n\n    def _get_measurement(self) -&gt; float:\n        if self._unit is None or self._range is None:\n            raise GS200Exception(\"Measurement module not initialized.\")\n        if self._parent.auto_range.get() or (self._unit == 'VOLT'\n                                             and self._range &lt; 1):\n            # Measurements will not work with autorange, or when\n            # range is &lt;1V.\n            self._enabled = False\n            raise GS200Exception(\"Measurements will not work when range is &lt;1V\"\n                                 \"or when in auto range mode.\")\n        if not self._output:\n            raise GS200Exception(\"Output is off.\")\n        if not self._enabled:\n            raise GS200Exception(\"Measurements are disabled.\")\n        # If enabled and output is on, then we can perform a measurement.\n        return float(self.ask(':MEAS?'))\n\n    def update_measurement_enabled(self, unit: str,\n                                   output_range: float) -&gt; None:\n        \"\"\"\n        Args:\n            unit\n            output_range\n        \"\"\"\n        # Recheck measurement state next time we do a measurement\n        self._enabled = False\n\n        # Update units\n        self._range = output_range\n        self._unit = unit\n        if self._unit == 'VOLT':\n            self.measure.label = 'Source Current'\n            self.measure.unit = 'I'\n        else:\n            self.measure.label = 'Source Voltage'\n            self.measure.unit = 'V'\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200_Monitor.off","title":"<code>off()</code>","text":"<p>Turn measurement off</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def off(self) -&gt; None:\n    \"\"\"Turn measurement off\"\"\"\n    self.write(':SENS 0')\n    self._enabled = False\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200_Monitor.on","title":"<code>on()</code>","text":"<p>Turn measurement on</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def on(self) -&gt; None:\n    \"\"\"Turn measurement on\"\"\"\n    self.write(':SENS 1')\n    self._enabled = True\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200_Monitor.state","title":"<code>state()</code>","text":"<p>Check measurement state</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def state(self) -&gt; int:\n    \"\"\"Check measurement state\"\"\"\n    state = int(self.ask(':SENS?'))\n    self._enabled = bool(state)\n    return state\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.GS200_Monitor.update_measurement_enabled","title":"<code>update_measurement_enabled(unit, output_range)</code>","text":"<p>Args:     unit     output_range</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def update_measurement_enabled(self, unit: str,\n                               output_range: float) -&gt; None:\n    \"\"\"\n    Args:\n        unit\n        output_range\n    \"\"\"\n    # Recheck measurement state next time we do a measurement\n    self._enabled = False\n\n    # Update units\n    self._range = output_range\n    self._unit = unit\n    if self._unit == 'VOLT':\n        self.measure.label = 'Source Current'\n        self.measure.unit = 'I'\n    else:\n        self.measure.label = 'Source Voltage'\n        self.measure.unit = 'V'\n</code></pre>"},{"location":"instruments/qcodes_instruments/instruments/#labcore.instruments.qcodes_drivers.Yokogawa.GS200.float_round","title":"<code>float_round(val)</code>","text":"<p>Rounds a floating number</p> <p>Args:     val: number to be rounded</p> <p>Returns:     Rounded integer</p> Source code in <code>labcore/instruments/qcodes_drivers/Yokogawa/GS200.py</code> <pre><code>def float_round(val: float) -&gt; int:\n    \"\"\"\n    Rounds a floating number\n\n    Args:\n        val: number to be rounded\n\n    Returns:\n        Rounded integer\n    \"\"\"\n    return round(float(val))\n</code></pre>"},{"location":"measurement/sweep/","title":"Sweeping","text":""},{"location":"measurement/sweep/#basic-example","title":"Basic Example","text":"<p>A Sweep is created out of two main components, an iterable pointer and a variable number of actions. Both pointer and actions may generate records.</p> <p>The most bare example would look like this:</p> <pre><code>&gt;&gt;&gt; for data in Sweep(range(3)):\n&gt;&gt;&gt;     print(data)\n{}\n{}\n{}\n</code></pre> <p>In this example, the <code>range(3)</code> iterable object is our pointer. This Sweep does not contain any actions or generate any records, but instead simply loops over the iterable pointer.</p>"},{"location":"measurement/sweep/#recording-data","title":"Recording Data","text":""},{"location":"measurement/sweep/#concepts","title":"Concepts","text":"<p>Even though the pointer in the previous example does generate data, we cannot see it when we iterate through the sweep. To have pointers and actions generate visible data, we need to annotate them so that they generate records.</p> <p>For a Sweep to know that either a pointer (an iterable object), or an action (a callable object) they need to be wrapped by an instance of <code>DataSpec</code>.  <code>DataSpec</code> is a data class that holds information about the variable itself. Understanding the inner workings are not necessary to fully utilize Sweeps, however, it is good to know they exists and what information they hold.</p> <p>Annotating a function or generator does not change what they do, it gets the values generated by them and places them inside a dictionary with the key for those values being the name of the variable we assign.</p> <p>The important fields of a <code>DataSpec</code> are its <code>name</code> and <code>depends_on</code> fields. <code>name</code>, simply indicates the name of the variable, e.i. the key that the sweep will have for the value of this variable. <code>depends_on</code> indicates whether the variable is an independent variable (we control) or a dependent variable (the things we are trying to measure). If <code>depends_on=None</code> it means this variable is an independent variable. If <code>depends_on=['x']</code>, this variable is dependent on a separate variable with name <code>x</code>. If <code>depends_on=[]</code>, the variable will be automatically assigned as a dependent of all other independents in the same Sweep.</p> <p>Note</p> <p><code>DataSpec</code>, also contains two more fields: <code>unit</code> and <code>types</code>, these however, have no impact in the way the code behaves and are for adding extra metadata for the user.</p> <p>While this might seem like a lot of information, its use is very intuitive and easy to use once you get used to it.</p>"},{"location":"measurement/sweep/#implementation","title":"Implementation","text":"<p>To wrap functions we use the <code>recording</code> decorator on the function we want to annotate:</p> <pre><code>&gt;&gt;&gt; @recording(DataSpec('x'), DataSpec('y', depends_on=['x'], type='array'))\n&gt;&gt;&gt; def measure_stuff(n, *args, **kwargs):\n&gt;&gt;&gt;     return n, np.random.normal(size=n)\n&gt;&gt;&gt;\n&gt;&gt;&gt; measure_stuff(1)\n{'x': 1, 'y': array([0.70663348])}\n</code></pre> <p>In the example above we annotate the function <code>measure_stuff()</code> indicating that the first item it returns is <code>x</code>, an independent variable since it does not have a <code>depends_on</code> field, and the second item is <code>y</code>, a variable that depends on <code>x</code>.</p> <p>We can annotate generators in the same way:</p> <pre><code>&gt;&gt;&gt; @recording(DataSpec('a'))\n&gt;&gt;&gt; def make_sequence(n):\n&gt;&gt;&gt;     for i in range(n):\n&gt;&gt;&gt;         yield i\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in make_sequence(3):\n&gt;&gt;&gt;     print(data)\n{'a': 0}\n{'a': 1}\n{'a': 2}\n</code></pre> <p>A nicer way of creating <code>DataSpec</code> instances is to use the functions <code>independent</code> and <code>dependent</code>. This function just makes the recording of data easier to read. <code>independent</code> does not let you indicate the <code>depends_on</code> field while <code>dependent</code>, has an empty list (indicating that it depends an all other independents) as a default.</p> <pre><code>&gt;&gt;&gt; @recording(independent('x'), dependent('y', type='array'))\n&gt;&gt;&gt; def measure_stuff(n, *args, **kwargs):\n&gt;&gt;&gt;    return n, np.random.normal(size=n)\n&gt;&gt;&gt;\n&gt;&gt;&gt; measure_stuff(1)\n{'x': 1, 'y': array([1.60113794])}\n</code></pre> <p>Note</p> <p>You can also use the shorter versions of these functions:</p> <ul> <li><code>ds</code> for shorter <code>DataSpec</code></li> <li><code>indep</code> for shorter <code>independent</code></li> <li><code>dep</code> for shorter <code>dependent</code></li> </ul> <p>Sometimes we don't want to annotate a function or generator itself, but instead we want to annotate at the moment of execution. For this we can use the function <code>record_as()</code> to annotate any function or generator on the fly:</p> <p><pre><code>&gt;&gt;&gt; def get_some_data(n):\n&gt;&gt;&gt;     return np.random.normal(size=n)\n&gt;&gt;&gt;\n&gt;&gt;&gt; record_as(get_some_data, independent('random_var'))(3)\n{'random_var': array([0.16099358, 0.74873271, 0.01160423])}\n</code></pre> You can add multiple <code>DataSpec</code> with in a single <code>record_as()</code>:</p> <p><pre><code>&gt;&gt;&gt; for data in record_as(zip(np.linspace(0,1,3), np.arange(3)), indep('x'), dep('y')):\n&gt;&gt;&gt;     print(data)\n{'x': 0.0, 'y': 0}\n{'x': 0.2, 'y': 1}\n{'x': 0.4, 'y': 2}\n</code></pre> It will also make sure to add items for annotated records (by adding <code>None</code> items to any empty record) that do not have any values assigned to them:</p> <pre><code>&gt;&gt;&gt; for data in record_as(np.linspace(0,1,3), indep('x'), dep('y')):\n&gt;&gt;&gt;     print(data)\n{'x': 0.0, 'y': None}\n{'x': 0.5, 'y': None}\n{'x': 1.0, 'y': None}\n</code></pre> <p>And it will ignore any extra values that are not annotated:</p> <pre><code>&gt;&gt;&gt; for data in record_as(zip(np.linspace(0,1,3), np.arange(3)), indep('x')):\n&gt;&gt;&gt;     print(data)\n{'x': 0.0}\n{'x': 0.5}\n{'x': 1.0}\n</code></pre>"},{"location":"measurement/sweep/#construction-of-sweeps","title":"Construction of Sweeps","text":"<p>Now that we know how to annotate data so that it generates records, we can finally start creating Sweeps that creates some data. A Sweep is composed of two main parts: pointers and actions:</p> <ul> <li>Pointers are iterables that the Sweep iterates through, these usually represent the independent variables of our experiments.</li> <li>Actions are callables that get called after each iteration of our pointer and usually are in charge of performing anything that needs to happen at every iteration of the experiment. This can be either set up a instruments and usually includes measuring a dependent variable too.</li> </ul> <p>Both pointers and actions can generate records if annotated correctly, but it is not a requirement.</p>"},{"location":"measurement/sweep/#basic-sweeps","title":"Basic Sweeps","text":"<p>A basic annotated Sweep looks something like this:</p> <pre><code>def my_func():\n    return 0\n\nsweep = Sweep(\n    record_as(range(3), independent('x')), # This is the pointer. We specify 'x' as an independent (we control it).\n    record_as(my_func, dependent('y'))) # my_func is an action. We specify 'y' as a dependent.\n</code></pre> <p>Once the Sweep is created we can see the records it will produce by using the function method <code>get_data_specs()</code>:</p> <pre><code>&gt;&gt;&gt; sweep.get_data_specs()\n(x, y(x))\n</code></pre> <p>Printing a Sweep will also display more information about, specifying the pointers, the actions taken afterwards and the records it will produce:</p> <pre><code>&gt;&gt;&gt; print(sweep)\nrange(0, 3) as {x} &gt;&gt; my_func() as {y}\n==&gt; {x, y(x)}\n</code></pre> <p>Now to run the Sweep we just have to iterate through it:</p> <pre><code>&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(data)\n{'x': 0, 'y': 0}\n{'x': 1, 'y': 0}\n{'x': 2, 'y': 0}\n</code></pre> <p>If you are trying to sweep over a single parameter, a more convenient syntax for creating Sweep is to utilize the <code>sweep_parameter()</code> function:</p> <pre><code>&gt;&gt;&gt; sweep = sweep_parameter('x', range(3), record_as(my_func, 'y'))\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(data)\n{'x': 0, 'y': 0}\n{'x': 1, 'y': 0}\n{'x': 2, 'y': 0}\n</code></pre> <p>There is no restriction on how many parameters a pointer or an action can generate as long as each parameter is properly annotated.</p> <pre><code>&gt;&gt;&gt; def my_func():\n&gt;&gt;&gt;     return 1, 2\n&gt;&gt;&gt;\n&gt;&gt;&gt; sweep = Sweep(\n&gt;&gt;&gt;     record_as(zip(range(3), ['a', 'b', 'c']), independent('number'), independent('string')), # a pointer with two parameters\n&gt;&gt;&gt;     record_as(my_func, 'one', 'two')) # an action with two parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(sweep.get_data_specs())\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(data)\n(number, string, one(number, string), two(number, string))\n{'number': 0, 'string': 'a', 'one': 1, 'two': 2}\n{'number': 1, 'string': 'b', 'one': 1, 'two': 2}\n{'number': 2, 'string': 'c', 'one': 1, 'two': 2}\n</code></pre>"},{"location":"measurement/sweep/#specifying-options-before-executing-a-sweep","title":"Specifying Options Before Executing a Sweep","text":"<p>Many actions we are using take optional parameters that we only want to specify just before executing the Sweep (but are constant throughout the Sweep).</p> <p>If we don't want to resort to global variables we can do so by using the method <code>set_options()</code>. It accepts the names of any action function in that Sweep as keywords, and dictionaries containing keyword arguments to pass to those functions as values. Keywords specified in this way always override keywords that are passed around internally in the sweep (for more information see the Passing Parameters in a Sweep` section):</p> <pre><code>&gt;&gt;&gt; def test_fun(a_property=False, *args, **kwargs):\n&gt;&gt;&gt;     print('inside test_fun:')\n&gt;&gt;&gt;     print(f\"a_property: {a_property}\")\n&gt;&gt;&gt;     print(f\"other stuff:\", args, kwargs)\n&gt;&gt;&gt;     print('----')\n&gt;&gt;&gt;     return 0\n&gt;&gt;&gt;\n&gt;&gt;&gt; sweep = sweep_parameter('value', range(3), record_as(test_fun, dependent('data')))\n&gt;&gt;&gt; sweep.set_options(test_fun=dict(a_property=True, another_property='Hello'))\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(\"Data:\", data)\n&gt;&gt;&gt;     print('----')\ninside test_fun:\nproperty: True\nother stuff: () {'value': 0, 'another_property': 'Hello'}\n----\nData: {'value': 0, 'data': 0}\n----\ninside test_fun:\nproperty: True\nother stuff: () {'value': 1, 'data': 0, 'another_property': 'Hello'}\n----\nData: {'value': 1, 'data': 0}\n----\ninside test_fun:\nproperty: True\nother stuff: () {'value': 2, 'data': 0, 'another_property': 'Hello'}\n----\nData: {'value': 2, 'data': 0}\n</code></pre>"},{"location":"measurement/sweep/#a-qcodes-parameter-sweep","title":"A QCoDeS Parameter Sweep","text":"<p>If you are using QCoDeS to interact with hardware, it is very common to want to do a sweep over a QCoDeS parameter. In this minimal example we set a parameter (<code>x</code>) to a range of values, and get data from another parameter for each set value.</p> <pre><code>&gt;&gt;&gt; def measure_stuff():\n&gt;&gt;&gt;     return np.random.normal()\n&gt;&gt;&gt;\n&gt;&gt;&gt; x = Parameter('x', set_cmd=lambda x: print(f'setting x to {x}'), initial_value=0) # QCoDeS Parameter\n&gt;&gt;&gt; data = Parameter('data', get_cmd=lambda: np.random.normal()) # QCoDeS Parameter\n&gt;&gt;&gt;\n&gt;&gt;&gt; for record in sweep_parameter(x, range(3), get_parameter(data)):\n&gt;&gt;&gt;     print(record)\nsetting x to 0\nsetting x to 0\n{'x': 0, 'data': -0.4990053668503893}\nsetting x to 1\n{'x': 1, 'data': -0.5132204673887943}\nsetting x to 2\n{'x': 2, 'data': 1.8634243556469932}\n</code></pre>"},{"location":"measurement/sweep/#sweep-combinations","title":"Sweep Combinations","text":"<p>One of the most valuable features of Sweeps is their ability to be combined through the use of operators. This allows us to mix and match different aspects of an experiment without having to rewrite code. We can combine different Sweeps with each other or different annotated actions</p>"},{"location":"measurement/sweep/#appending","title":"Appending","text":"<p>The most basic combination of Sweeps is appending them. When appending two Sweeps, the resulting sweep will execute the first Sweep to completion followed by the second Sweep to completion. To append two Sweeps or actions we use the <code>+</code> symbol:</p> <pre><code>&gt;&gt;&gt; def get_random_number():\n&gt;&gt;&gt;     return np.random.rand()\n&gt;&gt;&gt;\n&gt;&gt;&gt; Sweep.record_none = False # See note on what this does.\n&gt;&gt;&gt;\n&gt;&gt;&gt; sweep_1 = sweep_parameter('x', range(3), record_as(get_random_number, dependent('y')))\n&gt;&gt;&gt; sweep_2 = sweep_parameter('a', range(4), record_as(get_random_number, dependent('b')))\n&gt;&gt;&gt; my_sweep = sweep_1 + sweep_2\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in my_sweep:\n&gt;&gt;&gt;     print(data)\n{'x': 0, 'y': 0.34404570192577155}\n{'x': 1, 'y': 0.02104831292457654}\n{'x': 2, 'y': 0.9006367857458307}\n{'a': 0, 'b': 0.10539935409724577}\n{'a': 1, 'b': 0.9368463758729733}\n{'a': 2, 'b': 0.9550070757291859}\n{'a': 3, 'b': 0.9812445448108895}\n</code></pre> <p>Note</p> <p><code>Sweep.return_none</code> controls whether we include data fields that have returned nothing during setting a pointer or executing an action. Setting it to true (the default) guarantees that each data spec of the sweep has an entry per sweep point, even if it is <code>None</code>. For more information see: Passing Parameters in a Sweep section.</p>"},{"location":"measurement/sweep/#multiplying","title":"Multiplying","text":"<p>By multiplying we refer to an inner product, i.e. the result is what you'd expect from <code>zip</code> two iterables. To multiply two Sweeps or actions we use the <code>*</code> symbol. A basic example is if we have a sweep and want to attach another action to each sweep point:</p> <pre><code>&gt;&gt;&gt; my_sweep = (\n&gt;&gt;&gt;     sweep_parameter('x', range(3), record_as(get_random_number, dependent('data_1')))\n&gt;&gt;&gt;     * record_as(get_random_number, dependent('data_2'))\n&gt;&gt;&gt; )\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(sweep.get_data_specs())\n&gt;&gt;&gt; print('----')\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in my_sweep:\n&gt;&gt;&gt;     print(data)\n(x, data_1(x), data_2(x))\n----\n{'x': 0, 'data_1': 0.12599818360565485, 'data_2': 0.09261266841087679}\n{'x': 1, 'data_1': 0.5665798938860637, 'data_2': 0.7493750740615404}\n{'x': 2, 'data_1': 0.9035085438172156, 'data_2': 0.5419023528195611}\n</code></pre> <p>If you are combining two different Sweeps, then we get zip-like behavior while maintain the dependency structure separate:</p> <pre><code>&gt;&gt;&gt; my_sweep = (\n&gt;&gt;&gt;     sweep_parameter('x', range(3), record_as(get_random_number, dependent('data_1')))\n&gt;&gt;&gt;     * sweep_parameter('y', range(5), record_as(get_random_number, dependent('data_2')))\n&gt;&gt;&gt; )\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(sweep.get_data_specs())\n&gt;&gt;&gt; print('----')\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in my_sweep:\n&gt;&gt;&gt;     print(data)\n(x, data_1(x), y, data_2(y))\n----\n{'x': 0, 'data_1': 0.3808452915069015, 'y': 0, 'data_2': 0.14309246334791337}\n{'x': 1, 'data_1': 0.6094608905204076, 'y': 1, 'data_2': 0.3560530722571186}\n{'x': 2, 'data_1': 0.15950240245080072, 'y': 2, 'data_2': 0.2477391943438858}\n</code></pre>"},{"location":"measurement/sweep/#nesting","title":"Nesting","text":"<p>Nesting two Sweeps runs the entire second Sweep for each point of the first Sweep. A basic example is if we have multiple Sweep parameters against each other and we want to perform a measurement at each point. To nest two Sweeps we use the <code>@</code> symbol:</p> <pre><code>&gt;&gt;&gt; def measure_something():\n&gt;&gt;&gt;     return np.random.rand()\n&gt;&gt;&gt;\n&gt;&gt;&gt; my_sweep = (\n&gt;&gt;&gt;     sweep_parameter('x', range(3))\n&gt;&gt;&gt;     @ sweep_parameter('y', np.linspace(0,1,3))\n&gt;&gt;&gt;     @ record_as(measure_something, 'my_data')\n&gt;&gt;&gt; )\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in my_sweep:\n&gt;&gt;&gt;     print(data)\n{'x': 0, 'y': 0.0, 'my_data': 0.727404046865409}\n{'x': 0, 'y': 0.5, 'my_data': 0.11112429412122715}\n{'x': 0, 'y': 1.0, 'my_data': 0.09081900115421426}\n{'x': 1, 'y': 0.0, 'my_data': 0.8160224024098803}\n{'x': 1, 'y': 0.5, 'my_data': 0.1517092154216605}\n{'x': 1, 'y': 1.0, 'my_data': 0.9253018251769569}\n{'x': 2, 'y': 0.0, 'my_data': 0.881089486629102}\n{'x': 2, 'y': 0.5, 'my_data': 0.3897577898200387}\n{'x': 2, 'y': 1.0, 'my_data': 0.6895312744116066}\n</code></pre> <p>Nested sweeps can be as complex as needed, with as many actions as they need. An example of this can be executing measurements on each nested level:</p> <pre><code>&gt;&gt;&gt; def measure_something():\n&gt;&gt;&gt;     return np.random.rand()\n&gt;&gt;&gt;\n&gt;&gt;&gt; sweep_1 = sweep_parameter('x', range(3), record_as(measure_something, 'a'))\n&gt;&gt;&gt; sweep_2 = sweep_parameter('y', range(2), record_as(measure_something, 'b'))\n&gt;&gt;&gt; my_sweep = sweep_1 @ sweep_2 @ record_as(get_random_number, 'more_data')\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in my_sweep:\n&gt;&gt;&gt;     print(data)\n{'x': 0, 'a': 0.09522178419462424, 'y': 0, 'b': 0.1821505218348034, 'more_data': 0.13257002268089835}\n{'x': 0, 'a': 0.09522178419462424, 'y': 1, 'b': 0.014940266372080457, 'more_data': 0.9460879863404558}\n{'x': 1, 'a': 0.13994892182170526, 'y': 0, 'b': 0.4708657480125388, 'more_data': 0.12792337523097086}\n{'x': 1, 'a': 0.13994892182170526, 'y': 1, 'b': 0.8209492135277935, 'more_data': 0.23270477191895111}\n{'x': 2, 'a': 0.06159208933324678, 'y': 0, 'b': 0.651545802505077, 'more_data': 0.8944257582518365}\n{'x': 2, 'a': 0.06159208933324678, 'y': 1, 'b': 0.9064557565446919, 'more_data': 0.8258102740474211}\n</code></pre> <p>Note</p> <p>All operators symbols are just there for syntactic brevity. All three of them have corresponding functions attached to them:</p> <ul> <li>Appending: <code>append_sweeps()</code></li> <li>Multiplying: <code>zip_sweeps()</code></li> <li>Nesting: <code>nest_sweeps()</code></li> </ul>"},{"location":"measurement/sweep/#passing-parameters-in-a-sweep","title":"Passing Parameters in a Sweep","text":"<p>Often times our measurement actions depend on the states of previous steps. Because of that, everything that is generated by pointers, actions or other Sweeps can be passed on subsequently executed elements.</p> <p>Note</p> <p>here are two different Sweep configuration related to passing arguments in Sweeps. For more information on them see the Configuring Sweeps.</p>"},{"location":"measurement/sweep/#positional-arguments","title":"Positional Arguments","text":"<p>When there are no record annotations, the values generated <code>only</code> by pointers are passed as positional arguments to all actions, but values generated by actions are not passed to other actions:</p> <pre><code>&gt;&gt;&gt; def test(*args, **kwargs):\n&gt;&gt;&gt;     print('test:', args, kwargs)\n&gt;&gt;&gt;     return 101\n&gt;&gt;&gt;\n&gt;&gt;&gt; def test_2(*args, **kwargs):\n&gt;&gt;&gt;     print('test_2:', args, kwargs)\n&gt;&gt;&gt;     return 102\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in Sweep(range(3), test, test_2):\n&gt;&gt;&gt;     print(data)\ntest: (0,) {}\ntest_2: (0,) {}\n{}\ntest: (1,) {}\ntest_2: (1,) {}\n{}\ntest: (2,) {}\ntest_2: (2,) {}\n{}\n</code></pre> <p>Because it would get too confusing otherwise, positional arguments only get passed when originating from a pointer to all actions in a single sweep. Meaning that if we combine two or more sweeps, positional arguments would only get to the actions of their respective Sweeps:</p> <pre><code>&gt;&gt;&gt; for data in Sweep(range(3), test) * Sweep(zip(['x', 'y'], [True, False]), test):\n&gt;&gt;&gt;    print(data)\n(0,) {}\n('x', True) {}\n{}\n(1,) {}\n('y', False) {}\n{}\n(2,) {}\n</code></pre> <p>As we can see the <code>test</code> function in the second sweep is only getting (<code>x</code>, <code>True</code>) or (<code>y</code>, <code>False</code>) but not any arguments from the first Sweep. It is also important to note that hte values generated by either <code>test</code> function are not being passed to any other object.</p> <p>In previous examples, the functions we used were accepting the arguments because their signature included variation positional arguments (<code>*args</code>). The situation changes when this is not the case. Actions only receive arguments that they can accept:</p> <pre><code>&gt;&gt;&gt; def test_3(x=10):\n&gt;&gt;&gt;     print(x)\n&gt;&gt;&gt;     return True\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in Sweep(zip([1,2], [3,4]), test_3):\n&gt;&gt;&gt;     pass\n1\n2\n</code></pre> <p>As we can see, <code>test_3</code> only accepted the first argument.</p>"},{"location":"measurement/sweep/#keyword-arguments","title":"Keyword Arguments","text":"<p>Passing keyword arguments is more flexible. Any record that gets produced is passed to all subsequent pointers or actions in the sweep that accept that keyword. This is true even across different sub-sweeps. If a pointer yields non-annotated values, these are still used as positional arguments, but only when accepted, and with higher priority given to keywords.</p> <p>In the following example we can see this in action:</p> <pre><code>&gt;&gt;&gt; def test(x, y, z=5):\n&gt;&gt;&gt;     print(f'my three arguments, x: {x}, y: {y}, z: {z}')\n&gt;&gt;&gt;     return x, y, z\n&gt;&gt;&gt;\n&gt;&gt;&gt; def print_all_args(*args, **kwargs):\n&gt;&gt;&gt;     print(f'arguments at the end of the line, args: {args}, kwargs: {kwargs}')\n&gt;&gt;&gt;\n&gt;&gt;&gt; sweep = sweep_parameter('x', range(3), record_as(test, dep('xx'), dep('yy'), dep('zz'))) * \\\n&gt;&gt;&gt;         Sweep(range(3), print_all_args)\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     pass\nmy three arguments, x: 0, y: None, z: 5\narguments at the end of the line, args:(0,), kwargs:{'x': 0, 'xx': 0, 'zz': 5}\nmy three arguments, x: 1, y: None, z: 5\narguments at the end of the line, args:(1,), kwargs:{'x': 1, 'xx': 1, 'zz': 5}\nmy three arguments, x: 2, y: None, z: 5\narguments at the end of the line, args:(2,), kwargs:{'x': 2, 'xx': 2, 'zz': 5}\n</code></pre> <p>In the example above we have two different sweeps. The pointer of the first one is producing records which is why we see its value in the test function for <code>x</code>. Since the first sweep is being multiplied to the second sweep we can see how all the records (both produced by the pointer and action) of the first sweep reach the second sweep as keyword arguments, and the non-annotated value of its own pointer reaches the action of the second sweep as a positional argument.</p> <p>Warning</p> <p>When creating records, it is very important that each record has a unique name. Having multiple variables create records with the same names, will make the passing of arguments behave in unpredictable ways.</p> <p>A simple way of renaming conflicting arguments and records is to use the combination of <code>lambda</code> and <code>record_as()</code>:</p> <pre><code>&gt;&gt;&gt; sweep = (\n&gt;&gt;&gt;     Sweep(record_as(zip(range(3), range(10,13)), independent('x'), independent('y')), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))\n&gt;&gt;&gt;     @ record_as(lambda xx, yy, zz: test(xx, yy, zz), dependent('some'), dependent('different'), dependent('names'))\n&gt;&gt;&gt;     @ print_all_args\n&gt;&gt;&gt;     + print_all_args)\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(sweep.get_data_specs())\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(\"data:\", data)\n(x, y, xx(x, y), yy(x, y), zz(x, y), some(x, y), different(x, y), names(x, y))\nmy three arguments: 0 10 5\nmy three arguments: 0 10 5\narguments at the end of the line: () {'x': 0, 'y': 10, 'xx': 0, 'yy': 10, 'zz': 5, 'some': 0, 'different': 10, 'names': 5}\ndata: {'x': 0, 'y': 10, 'xx': 0, 'yy': 10, 'zz': 5, 'some': 0, 'different': 10, 'names': 5}\nmy three arguments: 1 11 5\nmy three arguments: 1 11 5\narguments at the end of the line: () {'x': 1, 'y': 11, 'xx': 1, 'yy': 11, 'zz': 5, 'some': 1, 'different': 11, 'names': 5}\ndata: {'x': 1, 'y': 11, 'xx': 1, 'yy': 11, 'zz': 5, 'some': 1, 'different': 11, 'names': 5}\nmy three arguments: 2 12 5\nmy three arguments: 2 12 5\narguments at the end of the line: () {'x': 2, 'y': 12, 'xx': 2, 'yy': 12, 'zz': 5, 'some': 2, 'different': 12, 'names': 5}\ndata: {'x': 2, 'y': 12, 'xx': 2, 'yy': 12, 'zz': 5, 'some': 2, 'different': 12, 'names': 5}\narguments at the end of the line: () {'x': 2, 'y': 12, 'xx': 2, 'yy': 12, 'zz': 5, 'some': 2, 'different': 12, 'names': 5}\ndata: {}\n</code></pre>"},{"location":"measurement/sweep/#configuring-sweeps","title":"Configuring Sweeps","text":"<p>The class <code>Sweep</code> has three global parameters that are used to configure the behavior of it.</p>"},{"location":"measurement/sweep/#record_none","title":"record_none","text":"<p>`Sweep.record_none , <code>True</code> by default, adds <code>None</code> to any action or pointer that didn't generate any record that iteration. This is useful if we want every variable we are storing to be composed of arrays of the same number of items:</p> <pre><code>&gt;&gt;&gt; def get_random_number():\n&gt;&gt;&gt;     return np.random.rand()\n&gt;&gt;&gt;\n&gt;&gt;&gt; sweep_1 = sweep_parameter('x', range(3), record_as(get_random_number, dependent('y')))\n&gt;&gt;&gt; sweep_2 = sweep_parameter('a', range(4), record_as(get_random_number, dependent('b')))\n&gt;&gt;&gt; my_sweep = sweep_1 + sweep_2\n&gt;&gt;&gt;\n&gt;&gt;&gt; Sweep.record_none = False\n&gt;&gt;&gt; print(f'----record_none=False----')\n&gt;&gt;&gt; for data in my_sweep:\n&gt;&gt;&gt;     print(data)\n&gt;&gt;&gt;\n&gt;&gt;&gt; Sweep.record_none = True\n&gt;&gt;&gt; print(f'----record_none=True----')\n&gt;&gt;&gt; for data in my_sweep:\n&gt;&gt;&gt;     print(data)\n----record_none=False----\n{'x': 0, 'y': 0.804635124804199}\n{'x': 1, 'y': 0.24410055642545125}\n{'x': 2, 'y': 0.10828652013926787}\n{'a': 0, 'b': 0.4303128288315823}\n{'a': 1, 'b': 0.9498154942316515}\n{'a': 2, 'b': 0.7150406031589893}\n{'a': 3, 'b': 0.2012281139956017}\n----record_none=True----\n{'x': 0, 'y': 0.22753548379033073, 'a': None, 'b': None}\n{'x': 1, 'y': 0.9024597689210428, 'a': None, 'b': None}\n{'x': 2, 'y': 0.11393941613249503, 'a': None, 'b': None}\n{'x': None, 'y': None, 'a': 0, 'b': 0.8678669225696442}\n{'x': None, 'y': None, 'a': 1, 'b': 0.3537275760737344}\n{'x': None, 'y': None, 'a': 2, 'b': 0.23555393946522196}\n{'x': None, 'y': None, 'a': 3, 'b': 0.19388827122308672}\n</code></pre>"},{"location":"measurement/sweep/#pass_on_returns","title":"pass_on_returns","text":"<p>:class:<code>Sweep.pass_on_returns</code> , <code>True</code> by default, specifies if we want arguments to be passed between sweeps. When it is set to <code>False</code> no record will be passed either as positional arguments or as keyword arguments:</p> <pre><code>&gt;&gt;&gt; sweep = (\n&gt;&gt;&gt;     sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))\n&gt;&gt;&gt;     @ print_all_args)\n&gt;&gt;&gt;\n&gt;&gt;&gt; Sweep.pass_on_returns = False\n&gt;&gt;&gt; print(f'----pass_on_returns=False----')\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(\"data:\", data)\n&gt;&gt;&gt;\n&gt;&gt;&gt; Sweep.pass_on_returns = True\n&gt;&gt;&gt; print(f'----pass_on_returns=True----')\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(\"data:\", data)\n----pass_on_returns=False----\nmy three arguments: None None 5\narguments at the end of the line: () {}\ndata: {'y': 0, 'xx': None, 'yy': None, 'zz': 5}\nmy three arguments: None None 5\narguments at the end of the line: () {}\ndata: {'y': 1, 'xx': None, 'yy': None, 'zz': 5}\nmy three arguments: None None 5\narguments at the end of the line: () {}\ndata: {'y': 2, 'xx': None, 'yy': None, 'zz': 5}\n----pass_on_returns=True----\nmy three arguments: None 0 5\narguments at the end of the line: () {'zz': 5, 'y': 0, 'yy': 0}\ndata: {'y': 0, 'xx': None, 'yy': 0, 'zz': 5}\nmy three arguments: None 1 5\narguments at the end of the line: () {'zz': 5, 'y': 1, 'yy': 1}\ndata: {'y': 1, 'xx': None, 'yy': 1, 'zz': 5}\nmy three arguments: None 2 5\narguments at the end of the line: () {'zz': 5, 'y': 2, 'yy': 2}\ndata: {'y': 2, 'xx': None, 'yy': 2, 'zz': 5}\n</code></pre>"},{"location":"measurement/sweep/#pass_on_none","title":"pass_on_none","text":"<p><code>Sweep.pass_on_none</code>, <code>False</code> by default, specifies if variables that return <code>None</code> should be passed as arguments to other actions or Sweeps (Because <code>None</code> is typically indicating that function did not return anything as data even though a record was declared using <code>recording</code> or <code>record_as()</code>:</p> <pre><code>&gt;&gt;&gt; sweep = (\n&gt;&gt;&gt;     sweep_parameter('y', range(3), record_as(test, dependent('xx'), dependent('yy'), dependent('zz')))\n&gt;&gt;&gt;     @ print_all_args)\n&gt;&gt;&gt;\n&gt;&gt;&gt; Sweep.pass_on_none = False\n&gt;&gt;&gt; print(f'----pass_on_none=False----')\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(\"data:\", data)\n&gt;&gt;&gt;\n&gt;&gt;&gt; Sweep.pass_on_none = True\n&gt;&gt;&gt; print(f'----pass_on_returns=True----')\n&gt;&gt;&gt; for data in sweep:\n&gt;&gt;&gt;     print(\"data:\", data)\n----pass_on_none=False----\nmy three arguments: None 0 5\narguments at the end of the line: () {'y': 0, 'yy': 0, 'zz': 5}\ndata: {'y': 0, 'xx': None, 'yy': 0, 'zz': 5}\nmy three arguments: None 1 5\narguments at the end of the line: () {'y': 1, 'yy': 1, 'zz': 5}\ndata: {'y': 1, 'xx': None, 'yy': 1, 'zz': 5}\nmy three arguments: None 2 5\narguments at the end of the line: () {'y': 2, 'yy': 2, 'zz': 5}\ndata: {'y': 2, 'xx': None, 'yy': 2, 'zz': 5}\n----pass_on_returns=True----\nmy three arguments: None 0 5\narguments at the end of the line: (None,) {'y': 0, 'yy': 0, 'zz': 5, 'xx': None}\ndata: {'y': 0, 'xx': None, 'yy': 0, 'zz': 5}\nmy three arguments: None 1 5\narguments at the end of the line: (None,) {'y': 1, 'yy': 1, 'zz': 5, 'xx': None}\ndata: {'y': 1, 'xx': None, 'yy': 1, 'zz': 5}\nmy three arguments: None 2 5\narguments at the end of the line: (None,) {'y': 2, 'yy': 2, 'zz': 5, 'xx': None}\ndata: {'y': 2, 'xx': None, 'yy': 2, 'zz': 5}\n</code></pre>"},{"location":"measurement/sweep/#running-sweeps","title":"Running Sweeps","text":"<p>As seen in previous examples, the most basic way of running a Sweep is to just iterate through it. This is simple but does not do much else. If we only want to store the data generated by a Sweep in disk for later analysis we can use the function <code>run_and_save_sweep()</code>:</p> <pre><code>&gt;&gt;&gt; sweep = sweep_parameter('x', range(3), record_as(my_func, 'y'))\n&gt;&gt;&gt; run_and_save_sweep(sweep, './data', 'my_data')\nData location:  data/2022-12-05/2022-12-05T142539_fbfce3e4-my_data/data.ddh5\nThe measurement has finished successfully and all of the data has been saved.\n</code></pre> <p>Note</p> <p>Because this guide has been ported from an older page plottr is not being used anymore, a fix will come.</p> <p><code>run_and_save_sweep()</code> automatically runs the Sweep indicated, stores the records generated by it in a :class:<code>DataDict &lt;plottr.data.datadict.DataDict&gt;</code> in a ddh5 file with time tag followed by a random sequence followed by the third argument, in the directory passed by the second argument. Internally the function utilizes the :class:<code>DDH5Writer &lt;plottr.data.datadict_storage.DDH5Writer&gt;</code> from <code>plottr</code>. For more information on how <code>plottr</code> handles data please see: :doc:<code>../plottr/data</code>.</p> <p>Note</p> <p><code>run_and_save_sweep()</code> can save multiple objects to disk by accepting them as extra arguments. It is a good idea to read over its documentation if you want to be able to save things with it.</p> <p>Sometimes we have an action that we want to run a single time, some kind of setup function or maybe a closing function (or any single action in between sweeps). If we also need this action to be a Sweep, the function <code>once()</code> will create a Sweep with no pointer that runs an action a single time:</p> <pre><code>&gt;&gt;&gt; def startup_function():\n&gt;&gt;&gt;     print(f'starting an instrument')\n&gt;&gt;&gt;\n&gt;&gt;&gt; def closing_function():\n&gt;&gt;&gt;     print(f'closing an instrument')\n&gt;&gt;&gt;\n&gt;&gt;&gt; sweep = sweep_parameter('x', range(3), record_as(my_func, 'y'))\n&gt;&gt;&gt; starting_sweep = once(startup_function)\n&gt;&gt;&gt; closing_sweep = once(closing_function)\n&gt;&gt;&gt;\n&gt;&gt;&gt; for data in starting_sweep + sweep + closing_sweep:\n&gt;&gt;&gt;     print(data)\nstarting an instrument\n{}\n{'x': 0, 'y': 1}\n{'x': 1, 'y': 1}\n{'x': 2, 'y': 1}\nclosing an instrument\n{}\n</code></pre>"},{"location":"measurement/sweep/#reference","title":"Reference","text":""},{"location":"measurement/sweep/#sweep-module","title":"Sweep Module","text":""},{"location":"measurement/sweep/#labcore.measurement.sweep.AsyncRecord","title":"<code>AsyncRecord</code>","text":"<p>Base class decorator used to record asynchronous data from instrument. Use the decorator with create_background_sweep function to create Sweeps that collect asynchronous data from external devices running experiments independently of the measurement PC, e.i. the measuring happening is not being controlled by a Sweep but instead an external device (e.g. the OPX). Each instrument should have its own custom setup_wrapper (see setup_wrapper docstring for more info), and a custom collector. Auxiliary functions for the start_wrapper and collector should also be located in this class.</p> <p>Parameters:</p> Name Type Description Default <code>specs</code> <p>A list of the DataSpecs to record the data produced.</p> <code>()</code> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>class AsyncRecord:\n    \"\"\"\n    Base class decorator used to record asynchronous data from instrument.\n    Use the decorator with create_background_sweep function to create Sweeps that collect asynchronous data from\n    external devices running experiments independently of the measurement PC,\n    e.i. the measuring happening is not being controlled by a Sweep but instead an external device (e.g. the OPX).\n    Each instrument should have its own custom setup_wrapper (see setup_wrapper docstring for more info),\n    and a custom collector.\n    Auxiliary functions for the start_wrapper and collector should also be located in this class.\n\n    :param specs: A list of the DataSpecs to record the data produced.\n    \"\"\"\n\n    wrapped_setup: Callable\n\n    def __init__(self, *specs):\n        self.specs = specs\n        self.communicator = {}\n\n    def __call__(self, fun) -&gt; Callable:\n        \"\"\"\n        When the decorator is called the experiment function gets wrapped so that it returns an Sweep object composed\n        of 2 different Sweeps, the setup sweep and the collector Sweep.\n        \"\"\"\n\n        def sweep(collector_options={}, **setup_kwargs) -&gt; Sweep:\n            \"\"\"\n            Returns a Sweep comprised of 2 different Sweeps: start_sweep and collector_sweep.\n            start_sweep should perform any setup actions as well as starting the actual experiment. This sweep is only\n            executed once. collector_sweep is iterated multiple time to collect all the data generated from the\n            instrument.\n\n            :param collector_kwargs: Any arguments that the collector needs.\n            \"\"\"\n            start_sweep = once(self.wrap_setup(fun))\n            collector_sweep = Sweep(as_pointer(self.collect, *self.specs).using(**collector_options))\n            ret = start_sweep + collector_sweep\n            ret.set_options(**{fun.__name__: setup_kwargs})\n            return ret\n\n        return sweep\n\n    def wrap_setup(self, fun: Callable, *args: Any, **kwargs: Any) -&gt; Callable:\n        \"\"\"\n        Wraps the start function. setup_wrapper should consist of another function inside of it decorated with @wraps\n        with fun as its argument.\n        In this case the wrapped function is setup.\n        Setup should accept the \\*args and \\**kwargs of fun. It should also place any returns from fun\n        in the communicator. setup_wrapper needs to return the wrapped function (setup).\n\n        :param fun: The measurement function. In the case of the OPX this would be the function that returns the QUA\n                    code with any arguments that it might use.\n        \"\"\"\n        self.wrapped_setup = partial(self.setup, fun, *args, **kwargs)\n        update_wrapper(self.wrapped_setup, fun)\n        return self.wrapped_setup\n\n    def setup(self, fun, *args, **kwargs):\n        return fun(*args, **kwargs)\n\n    def collect(self, *args, **kwargs) -&gt; Generator[Dict, None, None]:\n        yield {}\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.AsyncRecord.__call__","title":"<code>__call__(fun)</code>","text":"<p>When the decorator is called the experiment function gets wrapped so that it returns an Sweep object composed of 2 different Sweeps, the setup sweep and the collector Sweep.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def __call__(self, fun) -&gt; Callable:\n    \"\"\"\n    When the decorator is called the experiment function gets wrapped so that it returns an Sweep object composed\n    of 2 different Sweeps, the setup sweep and the collector Sweep.\n    \"\"\"\n\n    def sweep(collector_options={}, **setup_kwargs) -&gt; Sweep:\n        \"\"\"\n        Returns a Sweep comprised of 2 different Sweeps: start_sweep and collector_sweep.\n        start_sweep should perform any setup actions as well as starting the actual experiment. This sweep is only\n        executed once. collector_sweep is iterated multiple time to collect all the data generated from the\n        instrument.\n\n        :param collector_kwargs: Any arguments that the collector needs.\n        \"\"\"\n        start_sweep = once(self.wrap_setup(fun))\n        collector_sweep = Sweep(as_pointer(self.collect, *self.specs).using(**collector_options))\n        ret = start_sweep + collector_sweep\n        ret.set_options(**{fun.__name__: setup_kwargs})\n        return ret\n\n    return sweep\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.AsyncRecord.wrap_setup","title":"<code>wrap_setup(fun, *args, **kwargs)</code>","text":"<p>Wraps the start function. setup_wrapper should consist of another function inside of it decorated with @wraps with fun as its argument. In this case the wrapped function is setup. Setup should accept the *args and **kwargs of fun. It should also place any returns from fun in the communicator. setup_wrapper needs to return the wrapped function (setup).</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <code>Callable</code> <p>The measurement function. In the case of the OPX this would be the function that returns the QUA code with any arguments that it might use.</p> required Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def wrap_setup(self, fun: Callable, *args: Any, **kwargs: Any) -&gt; Callable:\n    \"\"\"\n    Wraps the start function. setup_wrapper should consist of another function inside of it decorated with @wraps\n    with fun as its argument.\n    In this case the wrapped function is setup.\n    Setup should accept the \\*args and \\**kwargs of fun. It should also place any returns from fun\n    in the communicator. setup_wrapper needs to return the wrapped function (setup).\n\n    :param fun: The measurement function. In the case of the OPX this would be the function that returns the QUA\n                code with any arguments that it might use.\n    \"\"\"\n    self.wrapped_setup = partial(self.setup, fun, *args, **kwargs)\n    update_wrapper(self.wrapped_setup, fun)\n    return self.wrapped_setup\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.PointerFunction","title":"<code>PointerFunction</code>","text":"<p>             Bases: <code>FunctionToRecords</code></p> <p>A class that allows using a generator function as a pointer.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>class PointerFunction(FunctionToRecords):\n    \"\"\"A class that allows using a generator function as a pointer.\"\"\"\n\n    def _iterator2records(self, *args, **kwargs):\n        func_args, func_kwargs = map_input_to_signature(self.func_sig,\n                                                        *args, **kwargs)\n        ret = record_as(self.func(*func_args, **func_kwargs), *self.data_specs)\n        return ret\n\n    def __call__(self, *args, **kwargs):\n        args = tuple(self._args + list(args))\n        kwargs.update(self._kwargs)\n        return self._iterator2records(*args, **kwargs)\n\n    def __iter__(self):\n        return iter(self._iterator2records(*self._args, **self._kwargs))\n\n    def get_data_specs(self):\n        return self.data_specs\n\n    def using(self, *args, **kwargs) -&gt; \"PointerFunction\":\n        \"\"\"Set the default positional and keyword arguments that will be\n        used when the function is called.\n\n        :returns: A copy of the object. This is to allow setting different\n            defaults to multiple uses of the function.\n        \"\"\"\n        ret = copy.copy(self)\n        ret._args = list(args)\n        ret._kwargs = kwargs\n        return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.PointerFunction.using","title":"<code>using(*args, **kwargs)</code>","text":"<p>Set the default positional and keyword arguments that will be used when the function is called.</p> <p>Returns:</p> Type Description <code>PointerFunction</code> <p>A copy of the object. This is to allow setting different defaults to multiple uses of the function.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def using(self, *args, **kwargs) -&gt; \"PointerFunction\":\n    \"\"\"Set the default positional and keyword arguments that will be\n    used when the function is called.\n\n    :returns: A copy of the object. This is to allow setting different\n        defaults to multiple uses of the function.\n    \"\"\"\n    ret = copy.copy(self)\n    ret._args = list(args)\n    ret._kwargs = kwargs\n    return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.Sweep","title":"<code>Sweep</code>","text":"<p>Base class for sweeps.</p> <p>Can be iterated over; for each pointer value the associated actions are executed. Each iteration step produces a record, containing all values produced by pointer and actions that have been annotated as such. (see: :func:<code>.record_as</code>)</p> <p>Parameters:</p> Name Type Description Default <code>pointer</code> <code>Optional[Iterable]</code> <p>An iterable that defines the steps over which we iterate</p> required <code>actions</code> <code>Callable</code> <p>A variable number of functions. Each will be called for each iteration step, with the pointer value(s) as arguments, provided the function can accept it.</p> <code>()</code> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>class Sweep:\n    \"\"\"Base class for sweeps.\n\n    Can be iterated over; for each pointer value the associated actions are\n    executed. Each iteration step produces a record, containing all values\n    produced by pointer and actions that have been annotated as such.\n    (see: :func:`.record_as`)\n\n    :param pointer: An iterable that defines the steps over which we iterate\n    :param actions: A variable number of functions. Each will be called for\n        each iteration step, with the pointer value(s) as arguments, provided\n        the function can accept it.\n    \"\"\"\n\n    # TODO: (MAYBE?) should we check if there are conflicting record parameters?\n    # TODO: some way of passing meta-info around (about the sweep state)\n    #   probably nice to have some info on benchmarking, current indices, etc.\n    # TODO: need a way to look through all subsweeps, for example to find all\n    #   kw arguments of all actions recursively.\n    # TODO: support qcodes parameters as action directly.\n\n    # TODO: these flags should maybe be passed on to 'child' sweeps?\n    record_none = True\n    pass_on_returns = True\n    pass_on_none = False\n\n    # TODO: Add the rules.\n    @staticmethod\n    def update_option_dict(src: Dict[str, Any], target: Dict[str, Any], level: int) -&gt; None:\n        \"\"\"Rules: work in progress :).\n        \"\"\"\n        if not isinstance(src, dict) or not isinstance(target, dict):\n            raise ValueError('inputs need to be dictionaries.')\n\n        for k, v in src.items():\n            if k in target:\n                if isinstance(v, dict) and level &gt; 0:\n                    Sweep.update_option_dict(src[k], target[k], level=level-1)\n            else:\n                target[k] = v\n\n    @staticmethod\n    def propagate_sweep_options(sweep: \"Sweep\"):\n\n        try:\n            first = sweep.pointer.iterable.first\n            Sweep.copy_sweep_options(sweep, first)\n        except AttributeError:\n            pass\n\n        try:\n            second = sweep.pointer.iterable.second\n            Sweep.copy_sweep_options(sweep, second)\n        except AttributeError:\n            pass\n\n    @staticmethod\n    def copy_sweep_options(src: \"Sweep\", target: Optional[\"Sweep\"]):\n        if src is target:\n            return\n\n        Sweep.update_option_dict(src._action_kwargs, target._action_kwargs, level=2)\n        Sweep.propagate_sweep_options(target)\n\n    @staticmethod\n    def link_sweep_properties(src: \"Sweep\", target: \"Sweep\") -&gt; None:\n        \"\"\"Share state properties between sweeps.\"\"\"\n        for p in ['_state', '_pass_kwargs']:\n            if hasattr(src, p):\n                setattr(target, p, getattr(src, p))\n                iterable = getattr(target.pointer, 'iterable', None)\n                if iterable is not None and hasattr(iterable, 'first'):\n                    first = getattr(iterable, 'first')\n                    setattr(first, p, getattr(src, p))\n                if iterable is not None and hasattr(iterable, 'second'):\n                    second = getattr(iterable, 'second')\n                    setattr(second, p, getattr(src, p))\n\n        Sweep.copy_sweep_options(src, target)\n\n    def __init__(self, pointer: Optional[Iterable], *actions: Callable):\n        \"\"\"Constructor of :class:`.Sweep`.\"\"\"\n        self._state = {}\n        self._pass_kwargs = {}\n        self._action_kwargs = {}\n\n        if pointer is None:\n            self.pointer = null_pointer\n        elif isinstance(pointer, (collections.abc.Iterable, Sweep)):\n            self.pointer = pointer\n        else:\n            raise TypeError('pointer needs to be iterable.')\n\n        self.actions = []\n        for a in actions:\n            self.append_action(a)\n\n    @property\n    def state(self):\n        return self._state\n\n    @state.setter\n    def state(self, value: Dict[str, Any]):\n        for k, v in value.items():\n            self._state[k] = v\n\n    @property\n    def pass_kwargs(self):\n        return self._pass_kwargs\n\n    @pass_kwargs.setter\n    def pass_kwargs(self, value: Dict[str, Any]):\n        for k, v in value.items():\n            self._pass_kwargs[k] = v\n\n    @property\n    def action_kwargs(self):\n        return self._action_kwargs\n\n    @action_kwargs.setter\n    def action_kwargs(self, value: Dict[str, Any]):\n        for k, v in value.items():\n            self._action_kwargs[k] = v\n\n    def __iter__(self):\n        return self.run()\n\n    def __add__(self, other: Union[Callable, \"Sweep\"]) -&gt; \"Sweep\":\n        if isinstance(other, Sweep):\n            sweep2 = other\n        elif callable(other):\n            sweep2 = Sweep(None, other)\n        else:\n            raise TypeError(f'can only combine with Sweep or callable, '\n                            f'not {type(other)}')\n\n        Sweep.link_sweep_properties(self, sweep2)\n        return append_sweeps(self, sweep2)\n\n    def __mul__(self, other: Union[Callable, \"Sweep\"]) -&gt; \"Sweep\":\n        if isinstance(other, Sweep):\n            sweep2 = other\n        elif callable(other):\n            sweep2 = Sweep(self.pointer, other)\n        else:\n            raise TypeError(f'can only combine with Sweep or callable, '\n                            f'not {type(other)}')\n\n        Sweep.link_sweep_properties(self, sweep2)\n        return zip_sweeps(self, sweep2)\n\n    def __matmul__(self, other: Union[Callable, \"Sweep\"]) -&gt; \"Sweep\":\n        if isinstance(other, Sweep):\n            sweep2 = other\n        elif callable(other):\n            sweep2 = Sweep(None, other)\n        else:\n            raise TypeError(f'can only combine with Sweep or callable, '\n                            f'not {type(other)}')\n\n        Sweep.link_sweep_properties(self, sweep2)\n        return nest_sweeps(self, sweep2)\n\n    def append_action(self, action: Callable):\n        \"\"\"Add an action to the sweep.\"\"\"\n        if callable(action):\n            if produces_record(action):\n                self.actions.append(action)\n            else:\n                self.actions.append(record_as(action))\n        else:\n            raise TypeError('action must be a callable.')\n\n    def run(self) -&gt; \"SweepIterator\":\n        \"\"\"Create the iterator for the sweep.\"\"\"\n        return SweepIterator(\n            self,\n            state=self.state,\n            pass_kwargs=self.pass_kwargs,\n            action_kwargs=self.action_kwargs)\n\n    # FIXME: currently this only works for actions -- should be used also\n    #   for pointer funcs?\n    def set_options(self, **action_kwargs: Dict[str, Any]):\n        \"\"\"Configure the sweep actions.\n\n        :param action_kwargs: Keyword arguments to pass to action functions\n            format: {'&lt;action_name&gt;': {'key': 'value'}\n            &lt;action_name&gt; is what action_function.__name__ returns.\n        \"\"\"\n        for func, val in action_kwargs.items():\n            self.action_kwargs[func] = val\n            Sweep.propagate_sweep_options(self)\n\n    def get_data_specs(self) -&gt; Tuple[DataSpec, ...]:\n        \"\"\"Return the data specs of the sweep.\"\"\"\n        specs = []\n        pointer_specs = []\n        if produces_record(self.pointer):\n            pointer_specs = self.pointer.get_data_specs()\n            specs = combine_data_specs(*(list(specs) + list(pointer_specs)))\n\n        for a in self.actions:\n            if produces_record(a):\n                action_specs = a.get_data_specs()\n                pointer_independents = [ds.name for ds in pointer_specs\n                                        if ds.depends_on is None]\n                for aspec in action_specs:\n                    aspec_ = aspec.copy()\n                    if aspec_.depends_on is not None:\n                        aspec_.depends_on = pointer_independents + aspec_.depends_on\n\n                    specs = combine_data_specs(*(list(specs) + [aspec_]))\n\n        return tuple(specs)\n\n    def __repr__(self):\n        ret = self.pointer.__repr__()\n        for a in self.actions:\n            ret += f\" &gt;&gt; {a.__repr__()}\"\n        ret += f\"\\n==&gt; {data_specs_label(*self.get_data_specs())}\"\n        return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.Sweep.__init__","title":"<code>__init__(pointer, *actions)</code>","text":"<p>Constructor of :class:<code>.Sweep</code>.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def __init__(self, pointer: Optional[Iterable], *actions: Callable):\n    \"\"\"Constructor of :class:`.Sweep`.\"\"\"\n    self._state = {}\n    self._pass_kwargs = {}\n    self._action_kwargs = {}\n\n    if pointer is None:\n        self.pointer = null_pointer\n    elif isinstance(pointer, (collections.abc.Iterable, Sweep)):\n        self.pointer = pointer\n    else:\n        raise TypeError('pointer needs to be iterable.')\n\n    self.actions = []\n    for a in actions:\n        self.append_action(a)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.Sweep.append_action","title":"<code>append_action(action)</code>","text":"<p>Add an action to the sweep.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def append_action(self, action: Callable):\n    \"\"\"Add an action to the sweep.\"\"\"\n    if callable(action):\n        if produces_record(action):\n            self.actions.append(action)\n        else:\n            self.actions.append(record_as(action))\n    else:\n        raise TypeError('action must be a callable.')\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.Sweep.get_data_specs","title":"<code>get_data_specs()</code>","text":"<p>Return the data specs of the sweep.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def get_data_specs(self) -&gt; Tuple[DataSpec, ...]:\n    \"\"\"Return the data specs of the sweep.\"\"\"\n    specs = []\n    pointer_specs = []\n    if produces_record(self.pointer):\n        pointer_specs = self.pointer.get_data_specs()\n        specs = combine_data_specs(*(list(specs) + list(pointer_specs)))\n\n    for a in self.actions:\n        if produces_record(a):\n            action_specs = a.get_data_specs()\n            pointer_independents = [ds.name for ds in pointer_specs\n                                    if ds.depends_on is None]\n            for aspec in action_specs:\n                aspec_ = aspec.copy()\n                if aspec_.depends_on is not None:\n                    aspec_.depends_on = pointer_independents + aspec_.depends_on\n\n                specs = combine_data_specs(*(list(specs) + [aspec_]))\n\n    return tuple(specs)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.Sweep.link_sweep_properties","title":"<code>link_sweep_properties(src, target)</code>  <code>staticmethod</code>","text":"<p>Share state properties between sweeps.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>@staticmethod\ndef link_sweep_properties(src: \"Sweep\", target: \"Sweep\") -&gt; None:\n    \"\"\"Share state properties between sweeps.\"\"\"\n    for p in ['_state', '_pass_kwargs']:\n        if hasattr(src, p):\n            setattr(target, p, getattr(src, p))\n            iterable = getattr(target.pointer, 'iterable', None)\n            if iterable is not None and hasattr(iterable, 'first'):\n                first = getattr(iterable, 'first')\n                setattr(first, p, getattr(src, p))\n            if iterable is not None and hasattr(iterable, 'second'):\n                second = getattr(iterable, 'second')\n                setattr(second, p, getattr(src, p))\n\n    Sweep.copy_sweep_options(src, target)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.Sweep.run","title":"<code>run()</code>","text":"<p>Create the iterator for the sweep.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def run(self) -&gt; \"SweepIterator\":\n    \"\"\"Create the iterator for the sweep.\"\"\"\n    return SweepIterator(\n        self,\n        state=self.state,\n        pass_kwargs=self.pass_kwargs,\n        action_kwargs=self.action_kwargs)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.Sweep.set_options","title":"<code>set_options(**action_kwargs)</code>","text":"<p>Configure the sweep actions.</p> <p>Parameters:</p> Name Type Description Default <code>action_kwargs</code> <code>Dict[str, Any]</code> <p>Keyword arguments to pass to action functions format: {'': {'key': 'value'}  is what action_function.name returns. <code>{}</code> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def set_options(self, **action_kwargs: Dict[str, Any]):\n    \"\"\"Configure the sweep actions.\n\n    :param action_kwargs: Keyword arguments to pass to action functions\n        format: {'&lt;action_name&gt;': {'key': 'value'}\n        &lt;action_name&gt; is what action_function.__name__ returns.\n    \"\"\"\n    for func, val in action_kwargs.items():\n        self.action_kwargs[func] = val\n        Sweep.propagate_sweep_options(self)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.Sweep.update_option_dict","title":"<code>update_option_dict(src, target, level)</code>  <code>staticmethod</code>","text":"<p>Rules: work in progress :).</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>@staticmethod\ndef update_option_dict(src: Dict[str, Any], target: Dict[str, Any], level: int) -&gt; None:\n    \"\"\"Rules: work in progress :).\n    \"\"\"\n    if not isinstance(src, dict) or not isinstance(target, dict):\n        raise ValueError('inputs need to be dictionaries.')\n\n    for k, v in src.items():\n        if k in target:\n            if isinstance(v, dict) and level &gt; 0:\n                Sweep.update_option_dict(src[k], target[k], level=level-1)\n        else:\n            target[k] = v\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.SweepIterator","title":"<code>SweepIterator</code>","text":"<p>Iterator for the :class:<code>.Sweep</code> class.</p> <p>Manages the actual iteration of the pointer, and the execution of action functions. Manages and updates the state of the sweep.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>class SweepIterator:\n    \"\"\"Iterator for the :class:`.Sweep` class.\n\n    Manages the actual iteration of the pointer, and the execution of action\n    functions. Manages and updates the state of the sweep.\n    \"\"\"\n\n    def __init__(self, sweep: Sweep,\n                 state: Dict[str, Any],\n                 pass_kwargs=Dict[str, Any],\n                 action_kwargs=Dict[str, Dict[str, Any]]):\n\n        self.sweep = sweep\n        self.state = state\n        self.pass_kwargs = pass_kwargs\n        self.action_kwargs = action_kwargs\n\n        if isinstance(self.sweep.pointer, Sweep):\n            self.pointer = iter(self.sweep.pointer)\n        elif isinstance(self.sweep.pointer, collections.abc.Iterator):\n            self.pointer = self.sweep.pointer\n        elif isinstance(self.sweep.pointer, collections.abc.Iterable):\n            self.pointer = iter(self.sweep.pointer)\n        else:\n            raise TypeError('pointer needs to be iterable.')\n\n    def __next__(self):\n        ret = {}\n        next_point = next(self.pointer)\n        if produces_record(self.sweep.pointer):\n            ret.update(next_point)\n\n        pass_args = []\n        if self.sweep.pass_on_returns:\n            if isinstance(next_point, (tuple, list)):\n                if not self.sweep.pass_on_none:\n                    pass_args = [r for r in next_point if r is not None]\n                else:\n                    pass_args = list(next_point)\n            elif isinstance(next_point, dict):\n                if not self.sweep.pass_on_none:\n                    self.pass_kwargs.update({k: v for k, v in next_point.items()\n                                             if v is not None})\n                else:\n                    self.pass_kwargs.update(next_point)\n            else:\n                if self.sweep.pass_on_none or next_point is not None:\n                    pass_args.append(next_point)\n\n        for a in self.sweep.actions:\n            this_action_kwargs = {}\n            if self.sweep.pass_on_returns:\n                this_action_kwargs.update(self.pass_kwargs)\n            this_action_kwargs.update(\n                self.action_kwargs.get(a.__name__, {}))\n\n            action_return = a(*pass_args, **this_action_kwargs)\n            if produces_record(a):\n                ret.update(action_return)\n\n            # actions always return records, so no need to worry about args\n            if not self.sweep.pass_on_none:\n                self.pass_kwargs.update({k: v for k, v in action_return.items()\n                                         if v is not None})\n            else:\n                self.pass_kwargs.update(action_return)\n\n        if self.sweep.record_none is False:\n            for k in list(ret.keys()):\n                if ret[k] is None:\n                    ret.pop(k)\n\n        return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.append_sweeps","title":"<code>append_sweeps(first, second)</code>","text":"<p>Append two sweeps.</p> <p>Iteration over the combined sweep will first complete the first sweep, then the second sweep.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def append_sweeps(first: Sweep, second: Sweep) -&gt; Sweep:\n    \"\"\"Append two sweeps.\n\n    Iteration over the combined sweep will first complete the first sweep, then\n    the second sweep.\n    \"\"\"\n    both = IteratorToRecords(\n        AppendSweeps(first, second),\n        *combine_data_specs(*(list(first.get_data_specs())\n                            + list(second.get_data_specs())))\n    )\n    sweep = Sweep(both)\n    Sweep.link_sweep_properties(first, sweep)\n    return sweep\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.as_pointer","title":"<code>as_pointer(fun, *data_specs)</code>","text":"<p>Convenient in-line creation of a pointer function.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def as_pointer(fun: Callable, *data_specs: DataSpecCreationType) -&gt; PointerFunction:\n    \"\"\"Convenient in-line creation of a pointer function.\"\"\"\n    return pointer(*data_specs)(fun)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.nest_sweeps","title":"<code>nest_sweeps(outer, inner)</code>","text":"<p>Nest two sweeps.</p> <p>Iteration over the combined sweep will execute the full inner sweep for each iteration step of the outer sweep.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def nest_sweeps(outer: Sweep, inner: Sweep) -&gt; Sweep:\n    \"\"\"Nest two sweeps.\n\n    Iteration over the combined sweep will execute the full inner sweep for each\n    iteration step of the outer sweep.\n    \"\"\"\n    outer_specs = outer.get_data_specs()\n    outer_indeps = [s.name for s in outer_specs if s.depends_on is None]\n\n    inner_specs = [s.copy() for s in inner.get_data_specs()]\n    for s in inner_specs:\n        if s.depends_on is not None:\n            s.depends_on = outer_indeps + s.depends_on\n\n    nested = IteratorToRecords(\n        NestSweeps(outer, inner),\n        *combine_data_specs(*(list(outer_specs) + inner_specs))\n    )\n    sweep = Sweep(nested)\n    Sweep.link_sweep_properties(outer, sweep)\n    return sweep\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.once","title":"<code>once(action)</code>","text":"<p>Return a sweep that executes the action once.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def once(action: Callable) -&gt; \"Sweep\":\n    \"\"\"Return a sweep that executes the action once.\"\"\"\n    return Sweep(null_pointer, action)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.pointer","title":"<code>pointer(*data_specs)</code>","text":"<p>Create a decorator for functions that return pointer generators.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def pointer(*data_specs: DataSpecCreationType) -&gt; Callable:\n    \"\"\"Create a decorator for functions that return pointer generators.\"\"\"\n    def decorator(func: Callable) -&gt; PointerFunction:\n        return PointerFunction(func, *data_specs)\n    return decorator\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.sweep_parameter","title":"<code>sweep_parameter(param, sweep_iterable, *actions)</code>","text":"<p>Create a sweep over a parameter.</p> <p>Parameters:</p> Name Type Description Default <code>param</code> <code>ParamSpecType</code> <p>One of:  * A string: Generates an independent, scalar data parameter. * A tuple or list: will be passed to the constructor of :class:<code>.DataSpec</code>; see :func:<code>.make_data_spec</code>. * A :class:<code>.DataSpec</code> instance. * A qcodes parameter. In this case the parameter's <code>set</code> method is called for each value during the iteration.</p> required <code>sweep_iterable</code> <code>Iterable</code> <p>An iterable that generates the values the parameter will be set to.</p> required <code>actions</code> <code>Callable</code> <p>An arbitrary number of action functions.</p> <code>()</code> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def sweep_parameter(param: ParamSpecType, sweep_iterable: Iterable,\n                    *actions: Callable) -&gt; \"Sweep\":\n    \"\"\"Create a sweep over a parameter.\n\n    :param param: One of:\n\n        * A string: Generates an independent, scalar data parameter.\n        * A tuple or list: will be passed to the constructor of :class:`.DataSpec`; see :func:`.make_data_spec`.\n        * A :class:`.DataSpec` instance.\n        * A qcodes parameter. In this case the parameter's ``set`` method is called for each value during the iteration.\n\n    :param sweep_iterable: An iterable that generates the values the parameter\n        will be set to.\n    :param actions: An arbitrary number of action functions.\n    \"\"\"\n\n    if isinstance(param, str):\n        param_ds = independent(param)\n    elif isinstance(param, (tuple, list)):\n        param_ds = make_data_spec(*param)\n    elif isinstance(param, DataSpec):\n        param_ds = param\n    elif QCODES_PRESENT and isinstance(param, QCParameter):\n        param_ds = independent(param.name, unit=param.unit)\n\n        def setfunc(*args, **kwargs):\n            param.set(kwargs.get(param.name))\n\n        actions = list(actions)\n        actions.insert(0, setfunc)\n    else:\n        raise TypeError(f\"Cannot make parameter from type {type(param)}\")\n\n    record_iterator = IteratorToRecords(sweep_iterable, param_ds)\n    return Sweep(record_iterator, *actions)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.sweep.zip_sweeps","title":"<code>zip_sweeps(first, second)</code>","text":"<p>Zip two sweeps.</p> <p>Iteration over the combined sweep will elementwise advance the two sweeps together.</p> Source code in <code>labcore/measurement/sweep.py</code> <pre><code>def zip_sweeps(first: Sweep, second: Sweep) -&gt; Sweep:\n    \"\"\"Zip two sweeps.\n\n    Iteration over the combined sweep will elementwise advance the two sweeps\n    together.\n    \"\"\"\n    both = IteratorToRecords(\n        ZipSweeps(first, second),\n        *combine_data_specs(*(list(first.get_data_specs())\n                            + list(second.get_data_specs())))\n    )\n    sweep = Sweep(both)\n    Sweep.link_sweep_properties(first, sweep)\n    return sweep\n</code></pre>"},{"location":"measurement/sweep/#record-module","title":"Record Module","text":""},{"location":"measurement/sweep/#labcore.measurement.record.DataSpec","title":"<code>DataSpec</code>  <code>dataclass</code>","text":"<p>Specification for data parameters to be recorded.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>@dataclass\nclass DataSpec:\n    \"\"\"Specification for data parameters to be recorded.\"\"\"\n    #: name of the parameter\n    name: str\n    #: dependencies. if ``None``, it is independent.\n    depends_on: Union[None, List[str], Tuple[str]] = None\n    #: information about data format\n    type: Union[str, DataType] = 'scalar'\n    #: physical unit of the data\n    unit: str = ''\n\n    def __post_init__(self):\n        if isinstance(self.type, str):\n            self.type = DataType(self.type)\n\n    def copy(self) -&gt; \"DataSpec\":\n        \"\"\"return a deep copy of the DataSpec instance.\"\"\"\n        return copy.deepcopy(self)\n\n    def __repr__(self) -&gt; str:\n        ret = self.name\n        if self.depends_on is not None and len(self.depends_on) &gt; 0:\n            ret += f\"({', '.join(list(self.depends_on))})\"\n        return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.DataSpec.copy","title":"<code>copy()</code>","text":"<p>return a deep copy of the DataSpec instance.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>def copy(self) -&gt; \"DataSpec\":\n    \"\"\"return a deep copy of the DataSpec instance.\"\"\"\n    return copy.deepcopy(self)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.DataType","title":"<code>DataType</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Valid options for data types used in :class:<code>DataSpec</code></p> Source code in <code>labcore/measurement/record.py</code> <pre><code>class DataType(Enum):\n    \"\"\"Valid options for data types used in :class:`DataSpec`\"\"\"\n    #: scalar (single-valued) data. typically numeric, but also bool, etc.\n    scalar = 'scalar'\n    #: multi-valued data. typically numpy-arrays.\n    array = 'array'\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.FunctionToRecords","title":"<code>FunctionToRecords</code>","text":"<p>A wrapper that converts a function return to a record.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>class FunctionToRecords:\n    \"\"\"A wrapper that converts a function return to a record.\"\"\"\n\n    def __init__(self, func, *data_specs):\n        self.func = func\n        self.func_sig = inspect.signature(self.func)\n        self.data_specs = make_data_specs(*data_specs)\n        update_wrapper(self, func)\n\n        self._args: List[Any] = []\n        self._kwargs: Dict[str, Any] = {}\n\n    def get_data_specs(self):\n        return self.data_specs\n\n    def __call__(self, *args, **kwargs):\n        args = tuple(self._args + list(args))\n        kwargs.update(self._kwargs)\n        func_args, func_kwargs = map_input_to_signature(self.func_sig,\n                                                        *args, **kwargs)\n        ret = self.func(*func_args, **func_kwargs)\n        return _to_record(ret, self.get_data_specs())\n\n    def __repr__(self):\n        dnames = data_specs_label(*self.data_specs)\n        ret = self.func.__name__ + str(self.func_sig)\n        ret += f\" as {dnames}\"\n        return ret\n\n    def using(self, *args, **kwargs) -&gt; \"FunctionToRecords\":\n        \"\"\"Set the default positional and keyword arguments that will be\n        used when the function is called.\n\n        :returns: a copy of the object. This is to allow setting different\n            defaults to multiple uses of the function.\n        \"\"\"\n        ret = copy.copy(self)\n        ret._args = list(args)\n        ret._kwargs = kwargs\n        return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.FunctionToRecords.using","title":"<code>using(*args, **kwargs)</code>","text":"<p>Set the default positional and keyword arguments that will be used when the function is called.</p> <p>Returns:</p> Type Description <code>FunctionToRecords</code> <p>a copy of the object. This is to allow setting different defaults to multiple uses of the function.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>def using(self, *args, **kwargs) -&gt; \"FunctionToRecords\":\n    \"\"\"Set the default positional and keyword arguments that will be\n    used when the function is called.\n\n    :returns: a copy of the object. This is to allow setting different\n        defaults to multiple uses of the function.\n    \"\"\"\n    ret = copy.copy(self)\n    ret._args = list(args)\n    ret._kwargs = kwargs\n    return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.IteratorToRecords","title":"<code>IteratorToRecords</code>","text":"<p>A wrapper that converts the iteration values to records.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>class IteratorToRecords:\n    \"\"\"A wrapper that converts the iteration values to records.\"\"\"\n\n    def __init__(self, iterable: Iterable,\n                 *data_specs: DataSpecCreationType):\n        self.iterable = iterable\n        self.data_specs = make_data_specs(*data_specs)\n\n    def get_data_specs(self):\n        return self.data_specs\n\n    def __iter__(self):\n        for val in self.iterable:\n            yield _to_record(val, self.data_specs)\n\n    def __repr__(self):\n        from .sweep import CombineSweeps\n\n        ret = self.iterable.__repr__()\n        if not isinstance(self.iterable, CombineSweeps):\n            dnames = data_specs_label(*self.get_data_specs())\n            ret += f\" as {dnames}\"\n\n        return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.combine_data_specs","title":"<code>combine_data_specs(*specs)</code>","text":"<p>Create a tuple of DataSpecs from the inputs. Removes duplicates.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>def combine_data_specs(*specs: DataSpec) -&gt; Tuple[DataSpec, ...]:\n    \"\"\"Create a tuple of DataSpecs from the inputs. Removes duplicates.\"\"\"\n    ret = []\n    spec_names = []\n    for s in specs:\n        if s.name not in spec_names:\n            ret.append(s)\n            spec_names.append(s.name)\n\n    return tuple(ret)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.data_specs_label","title":"<code>data_specs_label(*dspecs)</code>","text":"<p>Create a readable label for multiple data specs.</p> <p>Format:</p> <p>Parameters:</p> Name Type Description Default <code>dspecs</code> <code>DataSpec</code> <p>data specs as positional arguments.</p> <code>()</code> <p>Returns:</p> Type Description <code>str</code> <p>label as string.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>def data_specs_label(*dspecs: DataSpec) -&gt; str:\n    \"\"\"Create a readable label for multiple data specs.\n\n    Format:\n        {data_name_1 (dep_1, dep_2), data_name_2 (dep_3), etc.}\n\n    :param dspecs: data specs as positional arguments.\n    :return: label as string.\n    \"\"\"\n    return r\"{\" + f\"{', '.join([d.__repr__() for d in dspecs])}\" + r\"}\"\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.dependent","title":"<code>dependent(name, depends_on=[], unit='', type='scalar')</code>","text":"<p>Create a the spec for a dependent parameter. All arguments are forwarded to the :class:<code>.DataSpec</code> constructor. <code>depends_on</code> may not be set to <code>None</code>.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>def dependent(name: str, depends_on: List[str] = [], unit: str = \"\",\n              type: str = 'scalar'):\n    \"\"\"Create a the spec for a dependent parameter.\n    All arguments are forwarded to the :class:`.DataSpec` constructor.\n    ``depends_on`` may not be set to ``None``.\"\"\"\n    if depends_on is None:\n        raise TypeError(\"'depends_on' may not be None for a dependent.\")\n    return DataSpec(name, unit=unit, type=type, depends_on=depends_on)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.independent","title":"<code>independent(name, unit='', type='scalar')</code>","text":"<p>Create a the spec for an independent parameter. All arguments are forwarded to the :class:<code>.DataSpec</code> constructor. <code>depends_on</code> is set to <code>None</code>.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>def independent(name: str, unit: str = '', type: str = 'scalar') -&gt; DataSpec:\n    \"\"\"Create a the spec for an independent parameter.\n    All arguments are forwarded to the :class:`.DataSpec` constructor.\n    ``depends_on`` is set to ``None``.\"\"\"\n    return DataSpec(name, unit=unit, type=type, depends_on=None)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.make_data_spec","title":"<code>make_data_spec(value)</code>","text":"<p>Instantiate a DataSpec object.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>DataSpecCreationType</code> <p>May be one of the following with the following behavior:  - A string create a dependent with name given by the string - A tuple of values that can be used to pass to the constructor of :class:<code>.DataSpec</code> - A dictionary entries of which will be passed as keyword arguments to the constructor of :class:<code>.DataSpec</code> - A :class:<code>.DataSpec</code> instance</p> required Source code in <code>labcore/measurement/record.py</code> <pre><code>def make_data_spec(value: DataSpecCreationType) -&gt; DataSpec:\n    \"\"\"Instantiate a DataSpec object.\n\n    :param value:\n        May be one of the following with the following behavior:\n\n            - A string create a dependent with name given by the string\n            - A tuple of values that can be used to pass to the constructor of :class:`.DataSpec`\n            - A dictionary entries of which will be passed as keyword arguments to the constructor of :class:`.DataSpec`\n            - A :class:`.DataSpec` instance\n\n    \"\"\"\n    if isinstance(value, str):\n        return dependent(value)\n    elif isinstance(value, (tuple, list)):\n        return DataSpec(*value)\n    elif isinstance(value, dict):\n        return DataSpec(**value)\n    elif isinstance(value, DataSpec):\n        return value\n    else:\n        raise TypeError(f\"Cannot create DataSpec from {type(value)}\")\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.make_data_specs","title":"<code>make_data_specs(*specs)</code>","text":"<p>Create a tuple of DataSpec instances.</p> <p>Parameters:</p> Name Type Description Default <code>specs</code> <code>DataSpecCreationType</code> <p>will be passed individually to :func:<code>.make_data_spec</code></p> <code>()</code> Source code in <code>labcore/measurement/record.py</code> <pre><code>def make_data_specs(*specs: DataSpecCreationType) -&gt; Tuple[DataSpec, ...]:\n    \"\"\"Create a tuple of DataSpec instances.\n\n    :param specs: will be passed individually to :func:`.make_data_spec`\n    \"\"\"\n    ret = []\n    for spec in specs:\n        ret.append(make_data_spec(spec))\n    ret = tuple(ret)\n    return ret\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.produces_record","title":"<code>produces_record(obj)</code>","text":"<p>Check if <code>obj</code> is annotated to generate records.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>def produces_record(obj: Any) -&gt; bool:\n    \"\"\"Check if `obj` is annotated to generate records.\"\"\"\n    if hasattr(obj, 'get_data_specs'):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.record_as","title":"<code>record_as(obj, *specs)</code>","text":"<p>Annotate produced data as records.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[Callable, Iterable, Iterator]</code> <p>a function that returns data or an iterable/iterator that produces data at each iteration step</p> required <code>specs</code> <code>DataSpecCreationType</code> <p>specs for the data produced (see :func:<code>.make_data_specs</code>)</p> <code>()</code> Source code in <code>labcore/measurement/record.py</code> <pre><code>def record_as(obj: Union[Callable, Iterable, Iterator],\n              *specs: DataSpecCreationType):\n    \"\"\"Annotate produced data as records.\n\n    :param obj: a function that returns data or an iterable/iterator that\n        produces data at each iteration step\n    :param specs: specs for the data produced (see :func:`.make_data_specs`)\n    \"\"\"\n    specs = make_data_specs(*specs)\n    if isinstance(obj, Callable):\n        return recording(*specs)(obj)\n    elif isinstance(obj, collections.abc.Iterable):\n        return IteratorToRecords(obj, *specs)\n</code></pre>"},{"location":"measurement/sweep/#labcore.measurement.record.recording","title":"<code>recording(*data_specs)</code>","text":"<p>Returns a decorator that allows adding data parameter specs to a function.</p> Source code in <code>labcore/measurement/record.py</code> <pre><code>def recording(*data_specs: DataSpecCreationType) -&gt; Callable:\n    \"\"\"Returns a decorator that allows adding data parameter specs to a\n    function.\n    \"\"\"\n    def decorator(func):\n        return FunctionToRecords(func, *make_data_specs(*data_specs))\n    return decorator\n</code></pre>"},{"location":"measurement/sweep/#storage-module","title":"Storage Module","text":"<p>plottr.data.datadict_storage</p> <p>Provides file-storage tools for the DataDict class.</p>"},{"location":"measurement/sweep/#labcore.measurement.storage--description-of-the-hdf5-storage-format","title":"Description of the HDF5 storage format","text":"<p>We use a simple mapping from DataDict to the HDF5 file. Within the file, a single DataDict is stored in a (top-level) group of the file. The data fields are datasets within that group.</p> <p>Global meta data of the DataDict are attributes of the group; field meta data are attributes of the dataset (incl., the <code>unit</code> and <code>axes</code> values). The meta data keys are given exactly like in the DataDict, i.e., incl the double underscore pre- and suffix.</p>"},{"location":"measurement/sweep/#labcore.measurement.storage.run_and_save_sweep","title":"<code>run_and_save_sweep(sweep, data_dir, name, ignore_all_None_results=True, save_action_kwargs=False, add_timestamps=False, archive_files=None, return_data=False, safe_write_mode=False, **extra_saving_items)</code>","text":"<p>Iterates through a sweep, saving the data coming through it into a file called  at  directory. <p>Parameters:</p> Name Type Description Default <code>sweep</code> <code>Sweep</code> <p>Sweep object to iterate through.</p> required <code>data_dir</code> <code>str</code> <p>Directory of file location.</p> required <code>name</code> <code>str</code> <p>Name of the file.</p> required <code>ignore_all_None_results</code> <code>bool</code> <p>if <code>True</code>, don't save any records that contain a <code>None</code>. if <code>False</code>, only do not save records that are all-<code>None</code>.</p> <code>True</code> <code>save_action_kwargs</code> <p>If <code>True</code>, the action_kwargs of the sweep will be saved as a json file named after the first key of the kwargs dctionary followed by '_action_kwargs' in the same directory as the data.</p> <code>False</code> <code>archive_files</code> <code>Optional[List[str]]</code> <p>List of files to copy into a folder called 'archived_files' in the same directory that the data is saved. It should be a list of paths (str), regular expressions are supported. If a folder is passed, it will copy the entire folder and all of its subdirectories and files into the archived_files folder. If one of the arguments could not be found, a message will be printed and the measurement will be performed without the file being archived. An exception is raised if the type is invalid.  e.g. archive_files=['.txt', 'calibration_files', '../test_file.py'].  '.txt' will copy every txt file located in the working directory. 'calibration_files' will copy the entire folder called calibration_files from the working directory into the archived_files folder. '../test_file.py' will copy the script test_file.py from one directory above the working directory.</p> <code>None</code> <code>extra_saving_items</code> <p>Kwargs for extra objects that should be saved. If the kwarg is a dictionary, the function will try and save it as a JSON file. If the dictionary contains objects that are not JSON serializable it will be pickled. Any other kind of object will be pickled too. The files will have their keys as names.</p> <code>{}</code> <code>safe_write_mode</code> <code>bool</code> <p>Indicates if the data should be written in safe mode or not. Look into ddh5 writer for more info.</p> <code>False</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>A Typerror is raised if the object passed for archive_files is not correct</p> Source code in <code>labcore/measurement/storage.py</code> <pre><code>def run_and_save_sweep(sweep: Sweep,\n                       data_dir: str,\n                       name: str,\n                       ignore_all_None_results: bool = True,\n                       save_action_kwargs: bool = False,\n                       add_timestamps = False,\n                       archive_files: Optional[List[str]] = None,\n                       return_data: bool = False,\n                       safe_write_mode: bool = False,\n                       **extra_saving_items) -&gt; Tuple[Union[str, Path], Optional[DataDict]]:\n    \"\"\"\n    Iterates through a sweep, saving the data coming through it into a file called &lt;name&gt; at &lt;data_dir&gt; directory.\n\n    :param sweep: Sweep object to iterate through.\n    :param data_dir: Directory of file location.\n    :param name: Name of the file.\n    :param ignore_all_None_results: if ``True``, don't save any records that contain a ``None``.\n        if ``False``, only do not save records that are all-``None``.\n    :param  save_action_kwargs: If ``True``, the action_kwargs of the sweep will be saved as a json file named after\n        the first key of the kwargs dctionary followed by '_action_kwargs' in the same directory as the data.\n    :param archive_files: List of files to copy into a folder called 'archived_files' in\n        the same directory that the data is saved. It should be a list of paths (str), regular expressions are supported.\n        If a folder is passed, it will copy the entire folder and all of its subdirectories and files into the\n        archived_files folder. If one of the arguments could not be found, a message will be printed and the measurement\n        will be performed without the file being archived. An exception is raised if the type is invalid.\n\n        e.g. archive_files=['*.txt', 'calibration_files', '../test_file.py'].  '*.txt' will copy every txt file\n        located in the working directory. 'calibration_files' will copy the entire folder called calibration_files from\n        the working directory into the archived_files folder. '../test_file.py' will copy the script test_file.py from\n        one directory above the working directory.\n    :param extra_saving_items: Kwargs for extra objects that should be saved. If the kwarg is a dictionary, the function\n        will try and save it as a JSON file. If the dictionary contains objects that are not JSON serializable it will\n        be pickled. Any other kind of object will be pickled too. The files will have their keys as names.\n    :param safe_write_mode: Indicates if the data should be written in safe mode or not. Look into ddh5 writer for more\n        info.\n\n    :raises TypeError: A Typerror is raised if the object passed for archive_files is not correct\n    \"\"\"\n    data_dict = _create_datadict_structure(sweep)\n\n    # Creates a file even when it fails.\n    with DDH5Writer(data_dict, data_dir, name=name, safe_write_mode=safe_write_mode) as writer:\n\n        # Saving meta-data\n        dir: Path = writer.filepath.parent\n        if add_timestamps:\n            t = time.localtime()\n            time_stamp = time.strftime(TIMESTRFORMAT, t) + '_'\n\n        for key, val in extra_saving_items.items():\n            if callable(val):\n                value = val()\n            else:\n                value = val\n\n            if add_timestamps:\n                pickle_path_file = os.path.join(dir, time_stamp + key + '.pickle')\n                json_path_file = os.path.join(dir, time_stamp + key + '.json')\n            else:\n                pickle_path_file = os.path.join(dir, key + '.pickle')\n                json_path_file = os.path.join(dir, key + '.json')\n\n            if isinstance(value, dict):\n                try:\n                    _save_dictionary(value, json_path_file)\n                except TypeError as error:\n                    # Delete the file created by _save_dictionary. This file does not contain the complete dictionary.\n                    if os.path.isfile(json_path_file):\n                        os.remove(json_path_file)\n\n                    logging.info(f'{key} has not been able to save to json: {error.args}.'\n                                 f' The item will be pickled instead.')\n                    _pickle_and_save(value, pickle_path_file)\n            else:\n                _pickle_and_save(value, pickle_path_file)\n\n        # Save the kwargs\n        if save_action_kwargs:\n            if add_timestamps:\n                json_path_file = os.path.join(dir, time_stamp + 'sweep_action_kwargs.json')\n            else:\n                json_path_file = os.path.join(dir, 'sweep_action_kwargs.json')\n            _save_dictionary(sweep.action_kwargs, json_path_file)\n\n        # Save archive_files\n        if archive_files is not None:\n            archive_files_dir = os.path.join(dir, 'archive_files')\n            os.mkdir(archive_files_dir)\n            if not isinstance(archive_files, list) and not isinstance(archive_files, tuple):\n                if isinstance(archive_files, str):\n                    archive_files = [archive_files]\n                else:\n                    raise TypeError(f'{type(archive_files)} is not a list.')\n            for path in archive_files:\n                if os.path.isdir(path):\n                    folder_name = os.path.basename(path)\n                    if folder_name == '':\n                        folder_name = os.path.basename(os.path.dirname(path))\n\n                    shutil.copytree(path, os.path.join(archive_files_dir, folder_name), dirs_exist_ok=True)\n                elif os.path.isfile(path):\n                    shutil.copy(path, archive_files_dir)\n                else:\n                    matches = glob.glob(path, recursive=True)\n                    if len(matches) == 0:\n                        logging.info(f'{path} could not be found. Measurement will continue without archiving {path}')\n                    for file in matches:\n                        shutil.copy(file, archive_files_dir)\n\n        # Save data.\n        try:\n            for line in sweep:\n                if not _check_none(line, all=ignore_all_None_results):\n                    writer.add_data(**line)\n        except KeyboardInterrupt:\n            logger.warning('Sweep stopped by Keyboard interrupt. Data completed before interrupt should be saved.')\n            ret = (dir, data_dict) if return_data else (dir, None)\n            return ret\n\n    logger.info('The measurement has finished successfully and all of the data has been saved.')\n    ret = (dir, data_dict) if return_data else (dir, None)\n    return ret\n</code></pre>"}]}